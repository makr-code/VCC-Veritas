#!/usr/bin/env python3
"""
VERITAS Stage Reflection Service
=================================
LLM-gest√ºtztes Meta-Reflection System f√ºr Pipeline-Stages

Dual-Prompt-System:
1. User Query Prompt ‚Üí Prim√§re Verarbeitung
2. Meta-Reflection Prompt ‚Üí Fortschritts-Analyse pro Stage

Features:
- Erf√ºllungsgrad-Analyse (0-100%)
- Gap-Identifikation (Was fehlt noch?)
- Konfidenz-Tracking
- N√§chste Schritte Empfehlungen
- Strukturierte Progress-Messages

Created: 2025-10-15
"""

import logging
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
from enum import Enum

logger = logging.getLogger(__name__)


class ReflectionStage(str, Enum):
    """Pipeline-Stages f√ºr Reflection"""
    HYPOTHESIS = "hypothesis"
    AGENT_SELECTION = "agent_selection"
    RETRIEVAL = "retrieval"
    SYNTHESIS = "synthesis"
    VALIDATION = "validation"


@dataclass
class StageReflection:
    """Strukturierte Stage-Reflection"""
    stage: ReflectionStage
    completion_percent: float  # 0-100
    fulfillment_status: str    # "incomplete", "partial", "complete"
    identified_gaps: List[str]  # Was fehlt noch?
    gathered_info: List[str]    # Was wurde gefunden?
    confidence: float           # 0-1
    next_actions: List[str]     # Empfohlene n√§chste Schritte
    llm_reasoning: str          # LLM Begr√ºndung
    timestamp: str


class StageReflectionService:
    """
    LLM-Service f√ºr Meta-Reflections zu Pipeline-Stages
    
    Generiert strukturierte Analysen zu:
    - Informations-Erf√ºllungsgrad
    - Identifizierte L√ºcken
    - Qualit√§t der Zwischenergebnisse
    - Empfohlene n√§chste Schritte
    """
    
    def __init__(self, ollama_client=None):
        """
        Args:
            ollama_client: VeritasOllamaClient Instanz f√ºr LLM-Calls
        """
        self.ollama_client = ollama_client
        self.reflection_enabled = ollama_client is not None
        
        # Prompt-Templates f√ºr verschiedene Stages
        self.reflection_prompts = {
            ReflectionStage.HYPOTHESIS: self._build_hypothesis_reflection_prompt,
            ReflectionStage.AGENT_SELECTION: self._build_agent_selection_reflection_prompt,
            ReflectionStage.RETRIEVAL: self._build_retrieval_reflection_prompt,
            ReflectionStage.SYNTHESIS: self._build_synthesis_reflection_prompt,
            ReflectionStage.VALIDATION: self._build_validation_reflection_prompt,
        }
        
        logger.info(f"üîç StageReflectionService initialized (LLM: {self.reflection_enabled})")
    
    async def reflect_on_stage(
        self,
        stage: ReflectionStage,
        user_query: str,
        stage_data: Dict[str, Any],
        context: Optional[Dict[str, Any]] = None
    ) -> StageReflection:
        """
        F√ºhrt LLM-gest√ºtzte Reflection f√ºr Stage aus
        
        Args:
            stage: Aktuelle Pipeline-Stage
            user_query: Original User-Query
            stage_data: Ergebnisse/Daten der aktuellen Stage
            context: Zus√§tzlicher Kontext (vorherige Stages etc.)
            
        Returns:
            StageReflection mit strukturierter Analyse
        """
        if not self.reflection_enabled:
            return self._create_fallback_reflection(stage, stage_data)
        
        try:
            # Baue Stage-spezifischen Reflection-Prompt
            prompt_builder = self.reflection_prompts.get(stage)
            if not prompt_builder:
                logger.warning(f"‚ö†Ô∏è Kein Reflection-Prompt f√ºr Stage: {stage}")
                return self._create_fallback_reflection(stage, stage_data)
            
            reflection_prompt = prompt_builder(user_query, stage_data, context or {})
            
            # LLM-Call f√ºr Meta-Reflection
            reflection_response = await self._call_llm_reflection(reflection_prompt, stage)
            
            # Parse LLM-Response zu strukturiertem Format
            reflection = self._parse_reflection_response(stage, reflection_response, stage_data)
            
            logger.info(f"‚úÖ Stage Reflection: {stage} | Erf√ºllung: {reflection.completion_percent}%")
            return reflection
            
        except Exception as e:
            logger.error(f"‚ùå Reflection Error ({stage}): {e}")
            return self._create_fallback_reflection(stage, stage_data)
    
    def _build_hypothesis_reflection_prompt(
        self,
        user_query: str,
        stage_data: Dict[str, Any],
        context: Dict[str, Any]
    ) -> str:
        """Prompt f√ºr Hypothesen-Generierungs-Reflection"""
        hypotheses = stage_data.get('hypotheses', [])
        query_complexity = stage_data.get('complexity', 'unknown')
        
        return f"""
Du bist ein Meta-Analyst der die Qualit√§t von generierten Hypothesen bewertet.

USER QUERY:
{user_query}

GENERIERTE HYPOTHESEN:
{chr(10).join(f"- {h}" for h in hypotheses) if hypotheses else "Keine Hypothesen generiert"}

QUERY KOMPLEXIT√ÑT: {query_complexity}

DEINE AUFGABE:
Analysiere den Fortschritt der Hypothesen-Generierung:

1. ERF√úLLUNGSGRAD (0-100%):
   - Sind die Hypothesen relevant f√ºr die User-Query?
   - Decken sie verschiedene Aspekte ab?
   - Ist die Komplexit√§t angemessen erfasst?

2. IDENTIFIZIERTE L√úCKEN:
   - Welche wichtigen Aspekte fehlen?
   - Welche Hypothesen sollten noch erg√§nzt werden?

3. GESAMMELTE INFORMATIONEN:
   - Was wurde bereits gut erfasst?
   - Welche Hypothesen sind besonders wertvoll?

4. N√ÑCHSTE SCHRITTE:
   - Welche Agents sollten basierend auf den Hypothesen aktiviert werden?
   - Welche Datenquellen sind relevant?

5. KONFIDENZ (0-1):
   - Wie sicher bist du, dass die Hypothesen zielf√ºhrend sind?

Antworte in folgendem Format:
ERF√úLLUNG: <0-100>
STATUS: <incomplete|partial|complete>
L√úCKEN:
- <L√ºcke 1>
- <L√ºcke 2>
GESAMMELT:
- <Info 1>
- <Info 2>
N√ÑCHSTE_SCHRITTE:
- <Schritt 1>
- <Schritt 2>
KONFIDENZ: <0.0-1.0>
BEGR√úNDUNG: <Deine Reasoning>
"""
    
    def _build_agent_selection_reflection_prompt(
        self,
        user_query: str,
        stage_data: Dict[str, Any],
        context: Dict[str, Any]
    ) -> str:
        """Prompt f√ºr Agent-Auswahl-Reflection"""
        selected_agents = stage_data.get('selected_agents', [])
        available_agents = stage_data.get('available_agents', [])
        
        return f"""
Du bist ein Meta-Analyst der die Qualit√§t der Agent-Auswahl bewertet.

USER QUERY:
{user_query}

AUSGEW√ÑHLTE AGENTS:
{chr(10).join(f"- {a}" for a in selected_agents)}

VERF√úGBARE AGENTS:
{chr(10).join(f"- {a}" for a in available_agents)}

DEINE AUFGABE:
Analysiere die Agent-Auswahl:

1. ERF√úLLUNGSGRAD (0-100%):
   - Sind die richtigen Agents f√ºr die Query ausgew√§hlt?
   - Fehlen wichtige Agents?
   - Gibt es redundante Agents?

2. IDENTIFIZIERTE L√úCKEN:
   - Welche Informations-Dom√§nen fehlen?
   - Welche zus√§tzlichen Agents k√∂nnten hilfreich sein?

3. GESAMMELTE INFORMATIONEN:
   - Welche Aspekte werden durch die Agents abgedeckt?
   - Welche Agent-Kombination ist besonders sinnvoll?

4. N√ÑCHSTE SCHRITTE:
   - Sollten weitere Agents hinzugef√ºgt werden?
   - Welche Priorisierung ist sinnvoll?

5. KONFIDENZ (0-1):
   - Wie sicher bist du, dass die Agents die Query erf√ºllen k√∂nnen?

Antworte in folgendem Format:
ERF√úLLUNG: <0-100>
STATUS: <incomplete|partial|complete>
L√úCKEN:
- <L√ºcke 1>
GESAMMELT:
- <Info 1>
N√ÑCHSTE_SCHRITTE:
- <Schritt 1>
KONFIDENZ: <0.0-1.0>
BEGR√úNDUNG: <Deine Reasoning>
"""
    
    def _build_retrieval_reflection_prompt(
        self,
        user_query: str,
        stage_data: Dict[str, Any],
        context: Dict[str, Any]
    ) -> str:
        """Prompt f√ºr Retrieval-Reflection"""
        agent_results = stage_data.get('agent_results', {})
        total_sources = sum(len(r.get('sources', [])) for r in agent_results.values())
        
        return f"""
Du bist ein Meta-Analyst der die Qualit√§t der Information-Retrieval bewertet.

USER QUERY:
{user_query}

AGENT ERGEBNISSE:
{chr(10).join(f"- {agent}: {len(result.get('sources', []))} Quellen, Konfidenz: {result.get('confidence', 0):.2f}" 
              for agent, result in agent_results.items())}

GESAMT: {total_sources} Quellen gefunden

DEINE AUFGABE:
Analysiere die Information-Retrieval:

1. ERF√úLLUNGSGRAD (0-100%):
   - Wurden ausreichend Informationen gefunden?
   - Ist die Qualit√§t der Quellen hoch?
   - Decken die Informationen alle Aspekte der Query ab?

2. IDENTIFIZIERTE L√úCKEN:
   - Welche Informationen fehlen noch?
   - Welche Aspekte sind unterrepr√§sentiert?
   - Welche zus√§tzlichen Datenquellen k√∂nnten hilfreich sein?

3. GESAMMELTE INFORMATIONEN:
   - Was wurde bereits erfolgreich gefunden?
   - Welche Quellen sind besonders wertvoll?
   - Welche Agent-Ergebnisse sind am relevantesten?

4. N√ÑCHSTE SCHRITTE:
   - Sollte weiteres Retrieval durchgef√ºhrt werden?
   - Welche Informationen sollten priorisiert werden?
   - Ist genug f√ºr eine Synthese vorhanden?

5. KONFIDENZ (0-1):
   - Wie sicher bist du, dass die Informationen ausreichen?

Antworte in folgendem Format:
ERF√úLLUNG: <0-100>
STATUS: <incomplete|partial|complete>
L√úCKEN:
- <L√ºcke 1>
GESAMMELT:
- <Info 1>
N√ÑCHSTE_SCHRITTE:
- <Schritt 1>
KONFIDENZ: <0.0-1.0>
BEGR√úNDUNG: <Deine Reasoning>
"""
    
    def _build_synthesis_reflection_prompt(
        self,
        user_query: str,
        stage_data: Dict[str, Any],
        context: Dict[str, Any]
    ) -> str:
        """Prompt f√ºr Synthese-Reflection"""
        synthesis_result = stage_data.get('synthesis', {})
        response_text = synthesis_result.get('response_text', '')[:500]  # Erste 500 chars
        
        return f"""
Du bist ein Meta-Analyst der die Qualit√§t der finalen Synthese bewertet.

USER QUERY:
{user_query}

GENERIERTE ANTWORT (Auszug):
{response_text}...

SYNTHESE METADATA:
- Konfidenz: {synthesis_result.get('confidence_score', 0):.2f}
- Quellen: {len(synthesis_result.get('sources', []))}
- Agent-Ergebnisse: {len(synthesis_result.get('agent_results', {}))}

DEINE AUFGABE:
Analysiere die finale Synthese:

1. ERF√úLLUNGSGRAD (0-100%):
   - Beantwortet die Synthese die User-Query vollst√§ndig?
   - Sind alle wichtigen Aspekte enthalten?
   - Ist die Antwort strukturiert und verst√§ndlich?

2. IDENTIFIZIERTE L√úCKEN:
   - Welche Informationen fehlen in der Antwort?
   - Welche Aspekte sollten erg√§nzt werden?
   - Gibt es offene Fragen?

3. GESAMMELTE INFORMATIONEN:
   - Was wurde gut synthetisiert?
   - Welche St√§rken hat die Antwort?
   - Welche Informationen sind besonders wertvoll?

4. N√ÑCHSTE SCHRITTE:
   - Sollte die Synthese erweitert werden?
   - Welche Validierungen sind empfohlen?
   - Gibt es Follow-up-Fragen?

5. KONFIDENZ (0-1):
   - Wie sicher bist du, dass die Antwort den Nutzer zufriedenstellt?

Antworte in folgendem Format:
ERF√úLLUNG: <0-100>
STATUS: <incomplete|partial|complete>
L√úCKEN:
- <L√ºcke 1>
GESAMMELT:
- <Info 1>
N√ÑCHSTE_SCHRITTE:
- <Schritt 1>
KONFIDENZ: <0.0-1.0>
BEGR√úNDUNG: <Deine Reasoning>
"""
    
    def _build_validation_reflection_prompt(
        self,
        user_query: str,
        stage_data: Dict[str, Any],
        context: Dict[str, Any]
    ) -> str:
        """Prompt f√ºr Validierungs-Reflection"""
        validation_checks = stage_data.get('validation_checks', {})
        
        return f"""
Du bist ein Meta-Analyst der die Qualit√§t der Validierung bewertet.

USER QUERY:
{user_query}

VALIDIERUNGS-CHECKS:
{chr(10).join(f"- {check}: {result}" for check, result in validation_checks.items())}

DEINE AUFGABE:
Analysiere die Validierung:

1. ERF√úLLUNGSGRAD (0-100%):
   - Sind alle wichtigen Checks durchgef√ºhrt?
   - Ist die Antwort qualit√§tsgesichert?

2. IDENTIFIZIERTE L√úCKEN:
   - Welche Validierungen fehlen?
   - Welche zus√§tzlichen Checks w√§ren sinnvoll?

3. GESAMMELTE INFORMATIONEN:
   - Welche Validierungen waren erfolgreich?
   - Welche Qualit√§ts-Kriterien sind erf√ºllt?

4. N√ÑCHSTE SCHRITTE:
   - Sollten weitere Validierungen durchgef√ºhrt werden?
   - Ist die Antwort bereit f√ºr den Nutzer?

5. KONFIDENZ (0-1):
   - Wie sicher bist du, dass die Qualit√§t ausreichend ist?

Antworte in folgendem Format:
ERF√úLLUNG: <0-100>
STATUS: <incomplete|partial|complete>
L√úCKEN:
- <L√ºcke 1>
GESAMMELT:
- <Info 1>
N√ÑCHSTE_SCHRITTE:
- <Schritt 1>
KONFIDENZ: <0.0-1.0>
BEGR√úNDUNG: <Deine Reasoning>
"""
    
    async def _call_llm_reflection(self, prompt: str, stage: ReflectionStage) -> str:
        """
        Ruft LLM mit Reflection-Prompt auf
        
        Args:
            prompt: Reflection-Prompt
            stage: Aktuelle Stage
            
        Returns:
            LLM Response-Text
        """
        try:
            if not self.ollama_client:
                logger.debug(f"‚ö†Ô∏è Kein Ollama-Client verf√ºgbar f√ºr {stage}")
                return ""
            
            # Import OllamaRequest
            from backend.agents.veritas_ollama_client import OllamaRequest
            
            # Erstelle OllamaRequest
            request = OllamaRequest(
                model="llama3.2:latest",
                prompt=prompt,
                temperature=0.3,  # Niedrig f√ºr konsistente Analyse
                max_tokens=800,
                stream=False
            )
            
            # Async Call √ºber Ollama-Client
            response = await self.ollama_client.generate_response(
                request=request,
                stream=False
            )
            
            # Response-Text extrahieren
            if hasattr(response, 'response'):
                return response.response
            elif isinstance(response, dict):
                return response.get('response', response.get('response_text', ''))
            else:
                logger.warning(f"‚ö†Ô∏è Unerwartetes Response-Format: {type(response)}")
                return str(response)
            
        except Exception as e:
            logger.error(f"‚ùå LLM Reflection Call Error ({stage}): {e}")
            import traceback
            traceback.print_exc()
            return ""
    
    def _parse_reflection_response(
        self,
        stage: ReflectionStage,
        llm_response: str,
        stage_data: Dict[str, Any]
    ) -> StageReflection:
        """
        Parsed LLM-Response zu strukturiertem StageReflection
        
        Format erwartet:
        ERF√úLLUNG: 75
        STATUS: partial
        L√úCKEN:
        - L√ºcke 1
        ...
        """
        from datetime import datetime
        
        try:
            lines = llm_response.strip().split('\n')
            
            completion_percent = 50.0
            fulfillment_status = "partial"
            identified_gaps = []
            gathered_info = []
            next_actions = []
            confidence = 0.7
            llm_reasoning = ""
            
            current_section = None
            
            for line in lines:
                line = line.strip()
                
                if line.startswith('ERF√úLLUNG:'):
                    try:
                        completion_percent = float(line.split(':')[1].strip())
                    except:
                        pass
                elif line.startswith('STATUS:'):
                    fulfillment_status = line.split(':')[1].strip().lower()
                elif line.startswith('KONFIDENZ:'):
                    try:
                        confidence = float(line.split(':')[1].strip())
                    except:
                        pass
                elif line.startswith('BEGR√úNDUNG:'):
                    llm_reasoning = line.split(':', 1)[1].strip()
                elif line.startswith('L√úCKEN:'):
                    current_section = 'gaps'
                elif line.startswith('GESAMMELT:'):
                    current_section = 'gathered'
                elif line.startswith('N√ÑCHSTE_SCHRITTE:'):
                    current_section = 'actions'
                elif line.startswith('- ') and current_section:
                    item = line[2:].strip()
                    if current_section == 'gaps':
                        identified_gaps.append(item)
                    elif current_section == 'gathered':
                        gathered_info.append(item)
                    elif current_section == 'actions':
                        next_actions.append(item)
            
            return StageReflection(
                stage=stage,
                completion_percent=completion_percent,
                fulfillment_status=fulfillment_status,
                identified_gaps=identified_gaps,
                gathered_info=gathered_info,
                confidence=confidence,
                next_actions=next_actions,
                llm_reasoning=llm_reasoning,
                timestamp=datetime.now().isoformat()
            )
            
        except Exception as e:
            logger.error(f"‚ùå Parse Reflection Error: {e}")
            return self._create_fallback_reflection(stage, stage_data)
    
    def _create_fallback_reflection(
        self,
        stage: ReflectionStage,
        stage_data: Dict[str, Any]
    ) -> StageReflection:
        """Erstellt Fallback-Reflection ohne LLM"""
        from datetime import datetime
        
        return StageReflection(
            stage=stage,
            completion_percent=70.0,
            fulfillment_status="partial",
            identified_gaps=["LLM-Reflection nicht verf√ºgbar"],
            gathered_info=[f"Stage {stage} abgeschlossen"],
            confidence=0.6,
            next_actions=["Fortfahren mit n√§chster Stage"],
            llm_reasoning="Fallback ohne LLM-Analyse",
            timestamp=datetime.now().isoformat()
        )
    
    def format_reflection_for_display(self, reflection: StageReflection) -> str:
        """
        Formatiert Reflection f√ºr Frontend-Display
        
        Returns:
            Markdown-formatierte Reflection
        """
        status_emoji = {
            "incomplete": "üî¥",
            "partial": "üü°",
            "complete": "üü¢"
        }
        
        emoji = status_emoji.get(reflection.fulfillment_status, "‚ö™")
        
        output = f"""
### {emoji} Stage: {reflection.stage.value.title()}
**Erf√ºllungsgrad:** {reflection.completion_percent:.0f}% | **Status:** {reflection.fulfillment_status}  
**Konfidenz:** {reflection.confidence:.2f}

#### ‚úÖ Gesammelte Informationen:
{chr(10).join(f"- {info}" for info in reflection.gathered_info) if reflection.gathered_info else "- Keine"}

#### ‚ö†Ô∏è Identifizierte L√ºcken:
{chr(10).join(f"- {gap}" for gap in reflection.identified_gaps) if reflection.identified_gaps else "- Keine"}

#### üîú N√§chste Schritte:
{chr(10).join(f"- {action}" for action in reflection.next_actions) if reflection.next_actions else "- Keine"}

**LLM Reasoning:** {reflection.llm_reasoning}
"""
        return output.strip()


# Singleton-Instanz
_reflection_service: Optional[StageReflectionService] = None


def get_reflection_service(ollama_client=None) -> StageReflectionService:
    """
    Holt/erstellt Singleton StageReflectionService
    
    Args:
        ollama_client: Optional VeritasOllamaClient
        
    Returns:
        StageReflectionService Instanz
    """
    global _reflection_service
    
    if _reflection_service is None:
        _reflection_service = StageReflectionService(ollama_client)
    
    return _reflection_service
