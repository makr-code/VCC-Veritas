"""
VERITAS v5.0 - Hypothesis Data Models
=====================================

Data structures for hypothesis generation and analysis.

Features:
- QuestionType enum (8 types)
- ConfidenceLevel enum (4 levels)
- InformationGap dataclass
- Hypothesis dataclass with validation

Usage:
    from backend.models.hypothesis import Hypothesis, QuestionType, ConfidenceLevel

    hypothesis = Hypothesis(
        query="Bauantrag für Stuttgart",
        question_type=QuestionType.PROCEDURAL,
        primary_intent="Explain building permit process",
        confidence=ConfidenceLevel.HIGH
    )

    print(hypothesis.to_dict())
    print(f"Has critical gaps: {hypothesis.has_critical_gaps()}")

Created: 2025-10-14
Author: VERITAS AI
"""

from dataclasses import asdict, dataclass, field
from datetime import datetime, timezone
from enum import Enum
from typing import Any, Dict, List, Optional


class QuestionType(Enum):
    """Types of questions that can be asked."""

    FACT_RETRIEVAL = "fact_retrieval"  # "What is X?"
    COMPARISON = "comparison"  # "What's the difference between X and Y?"
    PROCEDURAL = "procedural"  # "How do I do X?"
    CALCULATION = "calculation"  # "How much does X cost?"
    OPINION = "opinion"  # "What's best for X?"
    TIMELINE = "timeline"  # "When does X happen?"
    CAUSAL = "causal"  # "Why does X happen?"
    HYPOTHETICAL = "hypothetical"  # "What if X?"


class ConfidenceLevel(Enum):
    """Confidence levels for hypothesis."""

    HIGH = "high"  # >80% confidence, clear intent
    MEDIUM = "medium"  # 50-80% confidence, some ambiguity
    LOW = "low"  # <50% confidence, unclear intent
    UNKNOWN = "unknown"  # Unable to determine


class GapSeverity(Enum):
    """Severity of information gaps."""

    CRITICAL = "critical"  # Cannot answer without this
    IMPORTANT = "important"  # Answer quality reduced without this
    OPTIONAL = "optional"  # Nice to have, not essential


@dataclass
class InformationGap:
    """
    Represents missing information needed to answer query.

    Information gaps are detected when the query lacks specific
    details needed to provide a complete answer. The service
    can request clarification or make reasonable assumptions.

    Attributes:
        gap_type: Type of missing information (e.g., "location", "timeframe")
        severity: How critical is this gap (critical, important, optional)
        suggested_query: Suggested clarification question for user
        examples: Example values that could fill this gap

    Example:
        InformationGap(
            gap_type="location",
            severity="critical",
            suggested_query="In welcher Stadt soll das Haus gebaut werden?",
            examples=["Stuttgart", "München", "Berlin"]
        )
    """

    gap_type: str
    severity: str
    suggested_query: str
    examples: List[str] = field(default_factory=list)

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for JSON serialization."""
        return asdict(self)

    def is_critical(self) -> bool:
        """Check if gap is critical."""
        return self.severity == GapSeverity.CRITICAL.value


@dataclass
class Hypothesis:
    """
    Hypothesis about user query and required information.

    Generated by analyzing the query with LLM to understand:
    - What type of question is being asked
    - What information is needed to answer
    - What information is missing
    - What assumptions are being made

    The hypothesis guides the response generation process by
    determining which ProcessSteps to execute and in what order.

    Attributes:
        query: Original user query
        question_type: Type of question (fact, comparison, procedural, etc.)
        primary_intent: Main intent/goal of query (human-readable)
        confidence: Confidence level of hypothesis (high, medium, low)
        required_information: List of information needed to answer
        information_gaps: List of missing information that needs clarification
        assumptions: List of assumptions made about the query
        suggested_steps: Suggested ProcessSteps to execute
        expected_response_type: Expected format of response (text, table, etc.)
        metadata: Additional metadata (LLM model, execution time, etc.)
        timestamp: When hypothesis was created (ISO 8601)

    Example:
        hypothesis = Hypothesis(
            query="Bauantrag für Einfamilienhaus in Stuttgart",
            question_type=QuestionType.PROCEDURAL,
            primary_intent="Explain building permit process for single-family home",
            confidence=ConfidenceLevel.HIGH,
            required_information=[
                "Building permit process",
                "Required documents",
                "Costs and fees",
                "Processing time"
            ],
            information_gaps=[],  # No gaps - location is specified
            assumptions=[
                "User wants to build in Stuttgart, Baden-Württemberg",
                "Standard single-family home (not special construction)"
            ]
        )
    """

    query: str
    question_type: QuestionType
    primary_intent: str
    confidence: ConfidenceLevel
    required_information: List[str] = field(default_factory=list)
    information_gaps: List[InformationGap] = field(default_factory=list)
    assumptions: List[str] = field(default_factory=list)
    suggested_steps: List[str] = field(default_factory=list)
    expected_response_type: str = "text"
    metadata: Dict[str, Any] = field(default_factory=dict)
    timestamp: str = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())

    def to_dict(self) -> Dict[str, Any]:
        """
        Convert to dictionary for JSON serialization.

        Returns:
            Dictionary representation of hypothesis
        """
        return {
            "query": self.query,
            "question_type": self.question_type.value,
            "primary_intent": self.primary_intent,
            "confidence": self.confidence.value,
            "required_information": self.required_information,
            "information_gaps": [gap.to_dict() for gap in self.information_gaps],
            "assumptions": self.assumptions,
            "suggested_steps": self.suggested_steps,
            "expected_response_type": self.expected_response_type,
            "metadata": self.metadata,
            "timestamp": self.timestamp,
        }

    def has_critical_gaps(self) -> bool:
        """
        Check if hypothesis has critical information gaps.

        Critical gaps prevent the system from answering the query
        accurately and require user clarification.

        Returns:
            True if any gap has severity="critical"
        """
        return any(gap.severity == GapSeverity.CRITICAL for gap in self.information_gaps)

    def get_gap_count(self, severity: str = None) -> int:
        """
        Get count of information gaps, optionally filtered by severity.

        Args:
            severity: Optional severity filter (critical, important, optional)

        Returns:
            Number of gaps matching the filter (or total if no filter)

        Example:
            critical_count = hypothesis.get_gap_count("critical")
            total_count = hypothesis.get_gap_count()
        """
        if severity is None:
            return len(self.information_gaps)
        return sum(1 for gap in self.information_gaps if gap.severity == severity)

    def is_high_confidence(self) -> bool:
        """
        Check if hypothesis has high confidence.

        High confidence hypotheses can proceed with execution
        without requesting additional clarification.

        Returns:
            True if confidence level is HIGH
        """
        return self.confidence == ConfidenceLevel.HIGH

    def requires_clarification(self) -> bool:
        """
        Check if hypothesis requires user clarification.

        Clarification is needed when:
        - Confidence is LOW
        - Critical information gaps exist

        Returns:
            True if clarification should be requested
        """
        return self.confidence == ConfidenceLevel.LOW or self.has_critical_gaps()

    def get_clarification_questions(self) -> List[str]:
        """
        Get list of clarification questions for user.

        Returns suggested questions for all information gaps,
        prioritizing critical gaps first.

        Returns:
            List of clarification questions
        """
        # Sort gaps by severity (critical first)
        severity_order = {GapSeverity.CRITICAL.value: 0, GapSeverity.IMPORTANT.value: 1, GapSeverity.OPTIONAL.value: 2}

        sorted_gaps = sorted(self.information_gaps, key=lambda g: severity_order.get(g.severity, 3))

        return [gap.suggested_query for gap in sorted_gaps]


# ========================================
# Example Usage
# ========================================

if __name__ == "__main__":
    print("=" * 70)
    print("HYPOTHESIS DATA MODELS - EXAMPLE USAGE")
    print("=" * 70)

    # Example 1: High confidence hypothesis (clear query)
    print("\n1. High Confidence Hypothesis:")
    hypothesis1 = Hypothesis(
        query="Bauantrag für Einfamilienhaus in Stuttgart",
        question_type=QuestionType.PROCEDURAL,
        primary_intent="Explain building permit process for single-family home in Stuttgart",
        confidence=ConfidenceLevel.HIGH,
        required_information=["Building permit process", "Required documents", "Costs and fees", "Processing time"],
        information_gaps=[],
        assumptions=["User wants to build in Stuttgart, Baden-Württemberg", "Standard single-family home"],
    )

    print(f"  Query: {hypothesis1.query}")
    print(f"  Type: {hypothesis1.question_type.value}")
    print(f"  Confidence: {hypothesis1.confidence.value}")
    print(f"  Requires clarification: {hypothesis1.requires_clarification()}")
    print(f"  Critical gaps: {hypothesis1.has_critical_gaps()}")

    # Example 2: Low confidence hypothesis (ambiguous query)
    print("\n2. Low Confidence Hypothesis (with gaps):")
    hypothesis2 = Hypothesis(
        query="Wie viel kostet ein Bauantrag?",
        question_type=QuestionType.CALCULATION,
        primary_intent="Calculate building permit costs",
        confidence=ConfidenceLevel.LOW,
        required_information=["Building type", "Location", "Building size"],
        information_gaps=[
            InformationGap(
                gap_type="location",
                severity=GapSeverity.CRITICAL.value,
                suggested_query="In welcher Stadt soll gebaut werden?",
                examples=["Stuttgart", "München", "Berlin"],
            ),
            InformationGap(
                gap_type="building_type",
                severity=GapSeverity.IMPORTANT.value,
                suggested_query="Um welche Art von Gebäude handelt es sich?",
                examples=["Einfamilienhaus", "Mehrfamilienhaus", "Gewerbe"],
            ),
        ],
        assumptions=["User is asking about German building permit costs"],
    )

    print(f"  Query: {hypothesis2.query}")
    print(f"  Type: {hypothesis2.question_type.value}")
    print(f"  Confidence: {hypothesis2.confidence.value}")
    print(f"  Requires clarification: {hypothesis2.requires_clarification()}")
    print(f"  Critical gaps: {hypothesis2.get_gap_count('critical')}")
    print(f"  Total gaps: {hypothesis2.get_gap_count()}")

    if hypothesis2.requires_clarification():
        print("\n  Clarification questions:")
        for i, question in enumerate(hypothesis2.get_clarification_questions(), 1):
            print(f"    {i}. {question}")

    # Example 3: Serialization
    print("\n3. JSON Serialization:")
    data = hypothesis1.to_dict()
    print(f"  Keys: {list(data.keys())}")
    print(f"  JSON-serializable: ✅")

    print("\n" + "=" * 70)
    print("✅ All examples completed successfully!")
    print("=" * 70)
