"""
VERITAS v5.0 - Hypothesis Data Models
=====================================

Data structures for hypothesis generation and analysis.

Features:
- QuestionType enum (8 types)
- ConfidenceLevel enum (4 levels)
- InformationGap dataclass
- Hypothesis dataclass with validation

Usage:
    from backend.models.hypothesis import Hypothesis, QuestionType, ConfidenceLevel
    
    hypothesis = Hypothesis(
        query="Bauantrag für Stuttgart",
        question_type=QuestionType.PROCEDURAL,
        primary_intent="Explain building permit process",
        confidence=ConfidenceLevel.HIGH
    )
    
    print(hypothesis.to_dict())
    print(f"Has critical gaps: {hypothesis.has_critical_gaps()}")

Created: 2025-10-14
Author: VERITAS AI
"""

from dataclasses import dataclass, field, asdict
from datetime import datetime, timezone
from enum import Enum
from typing import List, Dict, Any, Optional


class QuestionType(Enum):
    """Types of questions that can be asked."""
    FACT_RETRIEVAL = "fact_retrieval"        # "What is X?"
    COMPARISON = "comparison"                # "What's the difference between X and Y?"
    PROCEDURAL = "procedural"                # "How do I do X?"
    CALCULATION = "calculation"              # "How much does X cost?"
    OPINION = "opinion"                      # "What's best for X?"
    TIMELINE = "timeline"                    # "When does X happen?"
    CAUSAL = "causal"                        # "Why does X happen?"
    HYPOTHETICAL = "hypothetical"            # "What if X?"


class ConfidenceLevel(Enum):
    """Confidence levels for hypothesis."""
    HIGH = "high"          # >80% confidence, clear intent
    MEDIUM = "medium"      # 50-80% confidence, some ambiguity
    LOW = "low"            # <50% confidence, unclear intent
    UNKNOWN = "unknown"    # Unable to determine


class GapSeverity(Enum):
    """Severity of information gaps."""
    CRITICAL = "critical"      # Cannot answer without this
    IMPORTANT = "important"    # Answer quality reduced without this
    OPTIONAL = "optional"      # Nice to have, not essential


@dataclass
class InformationGap:
    """
    Represents missing information needed to answer query.
    
    Information gaps are detected when the query lacks specific
    details needed to provide a complete answer. The service
    can request clarification or make reasonable assumptions.
    
    Attributes:
        gap_type: Type of missing information (e.g., "location", "timeframe")
        severity: How critical is this gap (critical, important, optional)
        suggested_query: Suggested clarification question for user
        examples: Example values that could fill this gap
    
    Example:
        InformationGap(
            gap_type="location",
            severity="critical",
            suggested_query="In welcher Stadt soll das Haus gebaut werden?",
            examples=["Stuttgart", "München", "Berlin"]
        )
    """
    gap_type: str
    severity: str
    suggested_query: str
    examples: List[str] = field(default_factory=list)
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for JSON serialization."""
        return asdict(self)
    
    def is_critical(self) -> bool:
        """Check if gap is critical."""
        return self.severity == GapSeverity.CRITICAL.value


@dataclass
class Hypothesis:
    """
    Hypothesis about user query and required information.
    
    Generated by analyzing the query with LLM to understand:
    - What type of question is being asked
    - What information is needed to answer
    - What information is missing
    - What assumptions are being made
    
    The hypothesis guides the response generation process by
    determining which ProcessSteps to execute and in what order.
    
    Attributes:
        query: Original user query
        question_type: Type of question (fact, comparison, procedural, etc.)
        primary_intent: Main intent/goal of query (human-readable)
        confidence: Confidence level of hypothesis (high, medium, low)
        required_information: List of information needed to answer
        information_gaps: List of missing information that needs clarification
        assumptions: List of assumptions made about the query
        suggested_steps: Suggested ProcessSteps to execute
        expected_response_type: Expected format of response (text, table, etc.)
        metadata: Additional metadata (LLM model, execution time, etc.)
        timestamp: When hypothesis was created (ISO 8601)
    
    Example:
        hypothesis = Hypothesis(
            query="Bauantrag für Einfamilienhaus in Stuttgart",
            question_type=QuestionType.PROCEDURAL,
            primary_intent="Explain building permit process for single-family home",
            confidence=ConfidenceLevel.HIGH,
            required_information=[
                "Building permit process",
                "Required documents",
                "Costs and fees",
                "Processing time"
            ],
            information_gaps=[],  # No gaps - location is specified
            assumptions=[
                "User wants to build in Stuttgart, Baden-Württemberg",
                "Standard single-family home (not special construction)"
            ]
        )
    """
    query: str
    question_type: QuestionType
    primary_intent: str
    confidence: ConfidenceLevel
    required_information: List[str] = field(default_factory=list)
    information_gaps: List[InformationGap] = field(default_factory=list)
    assumptions: List[str] = field(default_factory=list)
    suggested_steps: List[str] = field(default_factory=list)
    expected_response_type: str = "text"
    metadata: Dict[str, Any] = field(default_factory=dict)
    timestamp: str = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
    
    def to_dict(self) -> Dict[str, Any]:
        """
        Convert to dictionary for JSON serialization.
        
        Returns:
            Dictionary representation of hypothesis
        """
        return {
            'query': self.query,
            'question_type': self.question_type.value,
            'primary_intent': self.primary_intent,
            'confidence': self.confidence.value,
            'required_information': self.required_information,
            'information_gaps': [gap.to_dict() for gap in self.information_gaps],
            'assumptions': self.assumptions,
            'suggested_steps': self.suggested_steps,
            'expected_response_type': self.expected_response_type,
            'metadata': self.metadata,
            'timestamp': self.timestamp
        }
    
    def has_critical_gaps(self) -> bool:
        """
        Check if hypothesis has critical information gaps.
        
        Critical gaps prevent the system from answering the query
        accurately and require user clarification.
        
        Returns:
            True if any gap has severity="critical"
        """
        return any(
            gap.severity == GapSeverity.CRITICAL 
            for gap in self.information_gaps
        )
    
    def get_gap_count(self, severity: str = None) -> int:
        """
        Get count of information gaps, optionally filtered by severity.
        
        Args:
            severity: Optional severity filter (critical, important, optional)
        
        Returns:
            Number of gaps matching the filter (or total if no filter)
        
        Example:
            critical_count = hypothesis.get_gap_count("critical")
            total_count = hypothesis.get_gap_count()
        """
        if severity is None:
            return len(self.information_gaps)
        return sum(1 for gap in self.information_gaps if gap.severity == severity)
    
    def is_high_confidence(self) -> bool:
        """
        Check if hypothesis has high confidence.
        
        High confidence hypotheses can proceed with execution
        without requesting additional clarification.
        
        Returns:
            True if confidence level is HIGH
        """
        return self.confidence == ConfidenceLevel.HIGH
    
    def requires_clarification(self) -> bool:
        """
        Check if hypothesis requires user clarification.
        
        Clarification is needed when:
        - Confidence is LOW
        - Critical information gaps exist
        
        Returns:
            True if clarification should be requested
        """
        return (
            self.confidence == ConfidenceLevel.LOW or
            self.has_critical_gaps()
        )
    
    def get_clarification_questions(self) -> List[str]:
        """
        Get list of clarification questions for user.
        
        Returns suggested questions for all information gaps,
        prioritizing critical gaps first.
        
        Returns:
            List of clarification questions
        """
        # Sort gaps by severity (critical first)
        severity_order = {
            GapSeverity.CRITICAL.value: 0,
            GapSeverity.IMPORTANT.value: 1,
            GapSeverity.OPTIONAL.value: 2
        }
        
        sorted_gaps = sorted(
            self.information_gaps,
            key=lambda g: severity_order.get(g.severity, 3)
        )
        
        return [gap.suggested_query for gap in sorted_gaps]


# ========================================
# Example Usage
# ========================================

if __name__ == "__main__":
    print("=" * 70)
    print("HYPOTHESIS DATA MODELS - EXAMPLE USAGE")
    print("=" * 70)
    
    # Example 1: High confidence hypothesis (clear query)
    print("\n1. High Confidence Hypothesis:")
    hypothesis1 = Hypothesis(
        query="Bauantrag für Einfamilienhaus in Stuttgart",
        question_type=QuestionType.PROCEDURAL,
        primary_intent="Explain building permit process for single-family home in Stuttgart",
        confidence=ConfidenceLevel.HIGH,
        required_information=[
            "Building permit process",
            "Required documents",
            "Costs and fees",
            "Processing time"
        ],
        information_gaps=[],
        assumptions=[
            "User wants to build in Stuttgart, Baden-Württemberg",
            "Standard single-family home"
        ]
    )
    
    print(f"  Query: {hypothesis1.query}")
    print(f"  Type: {hypothesis1.question_type.value}")
    print(f"  Confidence: {hypothesis1.confidence.value}")
    print(f"  Requires clarification: {hypothesis1.requires_clarification()}")
    print(f"  Critical gaps: {hypothesis1.has_critical_gaps()}")
    
    # Example 2: Low confidence hypothesis (ambiguous query)
    print("\n2. Low Confidence Hypothesis (with gaps):")
    hypothesis2 = Hypothesis(
        query="Wie viel kostet ein Bauantrag?",
        question_type=QuestionType.CALCULATION,
        primary_intent="Calculate building permit costs",
        confidence=ConfidenceLevel.LOW,
        required_information=[
            "Building type",
            "Location",
            "Building size"
        ],
        information_gaps=[
            InformationGap(
                gap_type="location",
                severity=GapSeverity.CRITICAL.value,
                suggested_query="In welcher Stadt soll gebaut werden?",
                examples=["Stuttgart", "München", "Berlin"]
            ),
            InformationGap(
                gap_type="building_type",
                severity=GapSeverity.IMPORTANT.value,
                suggested_query="Um welche Art von Gebäude handelt es sich?",
                examples=["Einfamilienhaus", "Mehrfamilienhaus", "Gewerbe"]
            )
        ],
        assumptions=[
            "User is asking about German building permit costs"
        ]
    )
    
    print(f"  Query: {hypothesis2.query}")
    print(f"  Type: {hypothesis2.question_type.value}")
    print(f"  Confidence: {hypothesis2.confidence.value}")
    print(f"  Requires clarification: {hypothesis2.requires_clarification()}")
    print(f"  Critical gaps: {hypothesis2.get_gap_count('critical')}")
    print(f"  Total gaps: {hypothesis2.get_gap_count()}")
    
    if hypothesis2.requires_clarification():
        print("\n  Clarification questions:")
        for i, question in enumerate(hypothesis2.get_clarification_questions(), 1):
            print(f"    {i}. {question}")
    
    # Example 3: Serialization
    print("\n3. JSON Serialization:")
    data = hypothesis1.to_dict()
    print(f"  Keys: {list(data.keys())}")
    print(f"  JSON-serializable: ✅")
    
    print("\n" + "=" * 70)
    print("✅ All examples completed successfully!")
    print("=" * 70)
