#!/usr/bin/env python3
"""
VERITAS SPARSE RETRIEVAL SERVICE
=================================

BM25-basierte Sparse Retrieval f√ºr lexikalisches Matching.
Komplement√§r zum Dense Retrieval (Embeddings) f√ºr Hybrid Search.

BM25 Vorteile:
- Exakte Begriffe (¬ß 242 BGB, DIN 18040-1)
- Akronyme & Abk√ºrzungen (UVP, VOB, BGB)
- Zahlen & Daten (2024, 50.000 EUR)
- Terminologie-Matching

Use-Case:
---------
Dense Retrieval: "Bauvorhaben Umweltauflagen" ‚Üí semantisch √§hnliche Docs
Sparse Retrieval: "UVP ¬ß3a UVPG" ‚Üí exakte terminologische Matches

Hybrid: Kombiniert beides f√ºr optimale Recall + Precision

Author: VERITAS System
Date: 2025-10-06
Version: 1.0
"""

from __future__ import annotations

import logging
import time
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional

import numpy as np

logger = logging.getLogger(__name__)

# BM25 Import (optional - graceful degradation)
try:
    from rank_bm25 import BM25Okapi

    BM25_AVAILABLE = True
    logger.info("‚úÖ rank_bm25 verf√ºgbar - Sparse Retrieval aktiv")
except ImportError:
    BM25_AVAILABLE = False
    BM25Okapi = None
    logger.warning("‚ö†Ô∏è rank_bm25 nicht installiert - Sparse Retrieval deaktiviert")
    logger.warning("   Installation: pip install rank-bm25")


@dataclass
class SparseRetrievalConfig:
    """Konfiguration f√ºr BM25 Sparse Retrieval"""

    # BM25-Parameter
    k1: float = 1.5  # Term frequency saturation (default: 1.5, range: 1.2-2.0)
    b: float = 0.75  # Document length normalization (default: 0.75, range: 0-1)

    # Retrieval-Parameter
    top_k: int = 50  # Top-K Dokumente

    # Tokenization
    lowercase: bool = True  # Kleinschreibung
    remove_punctuation: bool = False  # Satzzeichen NICHT entfernen (wichtig f√ºr ¬ß etc.)
    min_token_length: int = 2  # Minimale Token-L√§nge

    # Cache
    enable_cache: bool = True  # Query-Cache
    cache_ttl: int = 3600  # Cache Time-To-Live (Sekunden)


@dataclass
class ScoredDocument:
    """Dokument mit BM25-Score"""

    doc_id: str
    content: str
    score: float
    metadata: Dict[str, Any] = field(default_factory=dict)
    source: str = "bm25"  # Retrieval-Source


class SparseRetriever:
    """
    BM25-basierte Sparse Retrieval f√ºr lexikalisches Matching.

    BM25 (Best Matching 25) ist ein probabilistisches Retrieval-Modell,
    das auf Bag-of-Words und TF-IDF basiert. Es bewertet Dokumente nach:

    1. Term Frequency (TF): Wie oft kommt Query-Term im Dokument vor?
    2. Inverse Document Frequency (IDF): Wie selten ist Term im Corpus?
    3. Document Length Normalization: L√§ngere Docs nicht bevorzugen

    BM25 Formula:
    ------------
    score(D,Q) = Œ£ IDF(q_i) * (f(q_i,D) * (k1+1)) / (f(q_i,D) + k1 * (1-b + b * |D|/avgdl))

    Wobei:
    - D = Dokument
    - Q = Query
    - q_i = Query-Term
    - f(q_i,D) = Frequenz von q_i in D
    - |D| = L√§nge von D
    - avgdl = Durchschnittliche Dokumentl√§nge im Corpus
    - k1, b = Tuning-Parameter

    Performance:
    -----------
    - Indexing: O(N * M) wobei N=Docs, M=Avg-Tokens
    - Retrieval: O(N) (linear scan, kann mit Inverted Index optimiert werden)
    - Memory: ~100-200 bytes pro Dokument (tokenized)
    """

    def __init__(self, config: Optional[SparseRetrievalConfig] = None):
        """
        Initialisiert BM25 Sparse Retriever.

        Args:
            config: BM25-Konfiguration (optional)
        """
        self.config = config or SparseRetrievalConfig()
        self.bm25: Optional[BM25Okapi] = None
        self.corpus: List[str] = []
        self.doc_ids: List[str] = []
        self.tokenized_corpus: List[List[str]] = []
        self._indexed = False
        self._cache: Dict[str, List[ScoredDocument]] = {}
        self._empty_index_warning_shown = False  # Flag f√ºr one-time warning

        if not BM25_AVAILABLE:
            logger.error("‚ùå BM25 nicht verf√ºgbar - SparseRetriever funktioniert nicht!")

    def is_available(self) -> bool:
        """Pr√ºft ob BM25 verf√ºgbar ist (unabh√§ngig vom Index-Status)."""
        return BM25_AVAILABLE

    def is_indexed(self) -> bool:
        """Pr√ºft ob Dokumente indexiert sind."""
        return self._indexed

    def _tokenize(self, text: str) -> List[str]:
        """
        Tokenisiert Text f√ºr BM25.

        Args:
            text: Zu tokenisierender Text

        Returns:
            Liste von Tokens
        """
        # Lowercase
        if self.config.lowercase:
            text = text.lower()

        # Simple Whitespace-Tokenization
        tokens = text.split()

        # Filter: Minimale Token-L√§nge
        tokens = [token for token in tokens if len(token) >= self.config.min_token_length]

        return tokens

    def index_documents(self, documents: List[Dict[str, Any]], content_field: str = "content", id_field: str = "id") -> None:
        """
        Indexiert Dokumente f√ºr BM25-Suche.

        Args:
            documents: Liste von Dokumenten mit 'id' und 'content'
            content_field: Name des Content-Felds (default: 'content')
            id_field: Name des ID-Felds (default: 'id')

        Raises:
            RuntimeError: Wenn BM25 nicht verf√ºgbar
        """
        if not BM25_AVAILABLE:
            raise RuntimeError("BM25 nicht verf√ºgbar - installiere rank-bm25: pip install rank-bm25")

        logger.info(f"üì• Indexiere {len(documents)} Dokumente f√ºr BM25...")
        start_time = time.time()

        # Extract Content & IDs
        self.corpus = [doc.get(content_field, "") for doc in documents]
        self.doc_ids = [documents[i].get(id_field, f"doc_{i}") for i in range(len(documents))]

        # Tokenize Corpus
        self.tokenized_corpus = [self._tokenize(doc) for doc in self.corpus]

        # Create BM25 Index
        self.bm25 = BM25Okapi(self.tokenized_corpus, k1=self.config.k1, b=self.config.b)

        self._indexed = True
        index_time = time.time() - start_time

        logger.info(
            f"‚úÖ BM25-Index erstellt in {index_time:.2f}s "
            f"({len(documents)} Docs, {sum(len(t) for t in self.tokenized_corpus)} Tokens)"
        )

    async def retrieve(self, query: str, top_k: Optional[int] = None, min_score: float = 0.0) -> List[ScoredDocument]:
        """
        BM25-Suche f√ºr eine Query.

        Args:
            query: Suchanfrage
            top_k: Anzahl Top-Dokumente (default: config.top_k)
            min_score: Minimaler BM25-Score (default: 0.0)

        Returns:
            Liste der Top-K Dokumente mit BM25-Scores

        Raises:
            RuntimeError: Wenn BM25 nicht indexiert
        """
        if not self.is_available():
            logger.warning("‚ö†Ô∏è BM25 nicht verf√ºgbar - leere Results")
            return []

        # Pr√ºfen ob BM25 indexiert ist
        if not self.is_indexed() or self.bm25 is None:
            # Log warning only once (first time empty index is detected)
            if not self._empty_index_warning_shown:
                logger.warning("‚ö†Ô∏è BM25 Index ist leer - keine Dokumente indexiert")
                self._empty_index_warning_shown = True
            return []

        top_k = top_k or self.config.top_k

        # Cache-Check
        cache_key = f"{query}:{top_k}:{min_score}"
        if self.config.enable_cache and cache_key in self._cache:
            logger.debug(f"üíæ Cache-Hit f√ºr Query: {query[:50]}...")
            return self._cache[cache_key]

        # Tokenize Query
        tokenized_query = self._tokenize(query)

        if not tokenized_query:
            logger.warning(f"‚ö†Ô∏è Query '{query}' hat keine Tokens nach Tokenization")
            return []

        # BM25 Scoring
        scores = self.bm25.get_scores(tokenized_query)

        # Top-K Indizes (sortiert nach Score, absteigend)
        top_indices = np.argsort(scores)[-top_k:][::-1]

        # Erstelle ScoredDocuments
        results = []
        for idx in top_indices:
            score = float(scores[idx])

            # Filter: Minimaler Score
            if score < min_score:
                continue

            results.append(ScoredDocument(doc_id=self.doc_ids[idx], content=self.corpus[idx], score=score, source="bm25"))

        # Cache
        if self.config.enable_cache:
            self._cache[cache_key] = results

        top_score = results[0].score if results else 0.0
        logger.debug(f"üîç BM25 Retrieval: {len(results)} Docs f√ºr Query '{query[:50]}...' " f"(Top-Score: {top_score:.2f})")

        return results

    async def retrieve_multi_query(
        self, queries: List[str], top_k: Optional[int] = None, aggregation: str = "max"  # "max", "sum", "avg"
    ) -> List[ScoredDocument]:
        """
        BM25-Suche f√ºr multiple Queries mit Score-Aggregation.

        Args:
            queries: Liste von Suchanfragen
            top_k: Anzahl Top-Dokumente
            aggregation: Score-Aggregation ("max", "sum", "avg")

        Returns:
            Liste der Top-K Dokumente mit aggregierten Scores
        """
        if not self.is_available():
            return []

        top_k = top_k or self.config.top_k

        # Retrieve f√ºr jede Query
        all_scores = []
        for query in queries:
            tokenized_query = self._tokenize(query)
            if tokenized_query:
                scores = self.bm25.get_scores(tokenized_query)
                all_scores.append(scores)

        if not all_scores:
            return []

        # Score-Aggregation
        all_scores = np.array(all_scores)

        if aggregation == "max":
            aggregated_scores = np.max(all_scores, axis=0)
        elif aggregation == "sum":
            aggregated_scores = np.sum(all_scores, axis=0)
        elif aggregation == "avg":
            aggregated_scores = np.mean(all_scores, axis=0)
        else:
            raise ValueError(f"Unknown aggregation: {aggregation}")

        # Top-K
        top_indices = np.argsort(aggregated_scores)[-top_k:][::-1]

        results = []
        for idx in top_indices:
            score = float(aggregated_scores[idx])
            results.append(
                ScoredDocument(
                    doc_id=self.doc_ids[idx],
                    content=self.corpus[idx],
                    score=score,
                    metadata={"aggregation": aggregation, "num_queries": len(queries)},
                    source="bm25_multi",
                )
            )

        logger.debug(f"üîç BM25 Multi-Query: {len(results)} Docs f√ºr {len(queries)} Queries " f"(Aggregation: {aggregation})")

        return results

    def get_stats(self) -> Dict[str, Any]:
        """
        Gibt BM25-Statistiken zur√ºck.

        Returns:
            Dict mit Stats (num_docs, avg_doc_length, cache_size, etc.)
        """
        if not self._indexed:
            return {"indexed": False, "available": False}

        return {
            "indexed": True,
            "available": BM25_AVAILABLE,
            "num_documents": len(self.corpus),
            "num_tokens": sum(len(tokens) for tokens in self.tokenized_corpus),
            "avg_doc_length": np.mean([len(tokens) for tokens in self.tokenized_corpus]),
            "cache_size": len(self._cache),
            "config": {"k1": self.config.k1, "b": self.config.b, "top_k": self.config.top_k},
        }

    def clear_cache(self) -> None:
        """Leert den Query-Cache."""
        cache_size = len(self._cache)
        self._cache.clear()
        logger.info(f"üóëÔ∏è BM25-Cache geleert ({cache_size} Eintr√§ge)")


# Singleton Pattern f√ºr globalen Sparse Retriever
_sparse_retriever_instance: Optional[SparseRetriever] = None


def get_sparse_retriever(config: Optional[SparseRetrievalConfig] = None) -> SparseRetriever:
    """
    Gibt Singleton-Instanz des SparseRetrievers zur√ºck.

    Args:
        config: BM25-Konfiguration (nur beim ersten Aufruf)

    Returns:
        SparseRetriever-Instanz
    """
    global _sparse_retriever_instance

    if _sparse_retriever_instance is None:
        _sparse_retriever_instance = SparseRetriever(config)

    return _sparse_retriever_instance
