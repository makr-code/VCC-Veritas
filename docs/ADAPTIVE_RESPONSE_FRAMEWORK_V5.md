# ğŸ§  VERITAS Adaptive Response Framework - Konzept v5.0

**Version:** v5.0.0 (LLM-Generierte Adaptive Templates)  
**Created:** 12. Oktober 2025, 18:30 Uhr  
**Status:** ğŸ“‹ KONZEPTPHASE - Paradigmenwechsel

---

## ğŸ¯ Paradigmenwechsel: Von Fix zu Adaptiv

### âŒ **ALT (v4.1): Feste Template-Bibliothek**
```python
# 5 vordefinierte Templates (zustaendigkeit_behoerde, formale_pruefung, ...)
# Problem: Starr, kann nicht auf unerwartete Fragen reagieren
template = PromptTemplateLibrary.get_template('rechtliche_pruefung')
```

### âœ… **NEU (v5.0): LLM-Generierte Adaptive Templates**
```python
# LLM erstellt Template basierend auf Frage + RAG Kontext
# Vorteil: Flexibel, passt sich jeder Frage an
template = await AdaptiveTemplateGenerator.generate_from_query(
    user_query="Ist eine Baugenehmigung fÃ¼r mein Carport nÃ¶tig?",
    rag_context=semantic_search_results + process_graph_results
)
```

---

## ğŸ—ï¸ Neue Architektur: 3-Phasen-System

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 1: RAG-BASED HYPOTHESIS GENERATION                           â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ User Query: "Ist eine Baugenehmigung fÃ¼r mein Carport nÃ¶tig?"      â”‚
â”‚                                    â†“                                â”‚
â”‚ RAG System (Parallel):                                             â”‚
â”‚  1. Semantic Search (ChromaDB) â†’ Relevante Paragraphen             â”‚
â”‚  2. Process Graph (Neo4j) â†’ Verwaltungsprozess-Schritte            â”‚
â”‚                                    â†“                                â”‚
â”‚ LLM Hypothesis Generation (SCHNELL, ~500 Tokens):                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ System Prompt:                                                â”‚ â”‚
â”‚  â”‚ "Basierend auf der Frage und dem RAG-Kontext, erstelle eine  â”‚ â”‚
â”‚  â”‚  Hypothese: Welche Informationen brauchst du noch?           â”‚ â”‚
â”‚  â”‚  Output als JSON mit:                                        â”‚ â”‚
â”‚  â”‚  - required_criteria: [Liste von PrÃ¼fkriterien]             â”‚ â”‚
â”‚  â”‚  - missing_information: [Was fehlt noch?]                   â”‚ â”‚
â”‚  â”‚  - suggested_structure: [Antwort-Struktur]                  â”‚ â”‚
â”‚  â”‚  - confidence_estimate: float (0.0-1.0)"                    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                    â†“                                â”‚
â”‚ Output (JSON):                                                     â”‚
â”‚  {                                                                 â”‚
â”‚    "required_criteria": [                                          â”‚
â”‚      "GebÃ¤udeklasse (Carport = GebÃ¤ude?)",                        â”‚
â”‚      "GrundstÃ¼ckslage (AuÃŸenbereich vs. Bebauungsplan)",          â”‚
â”‚      "Bundesland-spezifische Verfahrensfreiheit",                 â”‚
â”‚      "AbstandsflÃ¤chen zu NachbargrundstÃ¼cken"                     â”‚
â”‚    ],                                                             â”‚
â”‚    "missing_information": [                                        â”‚
â”‚      "Bundesland nicht angegeben â†’ LBO unklar",                   â”‚
â”‚      "Carport-GrÃ¶ÃŸe/HÃ¶he nicht angegeben â†’ Verfahrensfreiheit?"   â”‚
â”‚    ],                                                             â”‚
â”‚    "suggested_structure": {                                        â”‚
â”‚      "sections": [                                                â”‚
â”‚        {"type": "question_clarification", "priority": 1},         â”‚
â”‚        {"type": "legal_assessment", "priority": 2},               â”‚
â”‚        {"type": "process_steps", "priority": 3},                  â”‚
â”‚        {"type": "conditions_table", "priority": 4}                â”‚
â”‚      ]                                                            â”‚
â”‚    },                                                             â”‚
â”‚    "confidence_estimate": 0.65,  # Mittel (Info fehlt)           â”‚
â”‚    "estimated_complexity": "medium",                              â”‚
â”‚    "recommended_token_budget": 3500                               â”‚
â”‚  }                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 2: TEMPLATE CONSTRUCTION FROM HYPOTHESIS                     â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ Input: Hypothesis JSON + Basic Template Frameworks                 â”‚
â”‚                                    â†“                                â”‚
â”‚ Template Generator:                                                â”‚
â”‚  1. WÃ¤hle Basic Framework (z.B. "verwaltungsrechtliche_frage")    â”‚
â”‚  2. FÃ¼ge Hypothesis-basierte Sections hinzu                       â”‚
â”‚  3. Generiere Widget-Specs basierend auf required_criteria        â”‚
â”‚  4. Setze Token-Budget (aus Hypothesis.recommended_token_budget)  â”‚
â”‚                                    â†“                                â”‚
â”‚ Generated Template (Adaptive):                                     â”‚
â”‚  {                                                                 â”‚
â”‚    "template_id": "adaptive_carport_genehmigung_2025-10-12",     â”‚
â”‚    "base_framework": "verwaltungsrechtliche_frage",               â”‚
â”‚    "system_prompt": "[AUTO-GENERIERT basierend auf Hypothesis]",  â”‚
â”‚    "required_tokens": 3500,  # Aus Hypothesis                     â”‚
â”‚    "response_structure": {                                         â”‚
â”‚      "sections": [                                                â”‚
â”‚        {                                                          â”‚
â”‚          "id": "question_clarification",                          â”‚
â”‚          "title": "Fehlende Informationen",                      â”‚
â”‚          "widget": {                                              â”‚
â”‚            "type": "interactive_form",                            â”‚
â”‚            "fields": [                                            â”‚
â”‚              {"name": "bundesland", "type": "dropdown",           â”‚
â”‚               "options": ["Baden-WÃ¼rttemberg", "Bayern", ...]},  â”‚
â”‚              {"name": "carport_groesse", "type": "text",          â”‚
â”‚               "placeholder": "z.B. 20mÂ²"},                        â”‚
â”‚              {"name": "carport_hoehe", "type": "text",            â”‚
â”‚               "placeholder": "z.B. 2.5m"}                         â”‚
â”‚            ]                                                      â”‚
â”‚          }                                                        â”‚
â”‚        },                                                         â”‚
â”‚        {                                                          â”‚
â”‚          "id": "legal_assessment",                                â”‚
â”‚          "title": "Rechtliche Einordnung",                       â”‚
â”‚          "content_type": "markdown"                               â”‚
â”‚        },                                                         â”‚
â”‚        {                                                          â”‚
â”‚          "id": "process_steps",                                   â”‚
â”‚          "title": "Verfahrensschritte",                          â”‚
â”‚          "widget": {                                              â”‚
â”‚            "type": "process_graph",                               â”‚
â”‚            "data_source": "neo4j_query",                          â”‚
â”‚            "query": "MATCH (p:Process {type:'Baugenehmigung'})..." â”‚
â”‚          }                                                        â”‚
â”‚        },                                                         â”‚
â”‚        {                                                          â”‚
â”‚          "id": "conditions_table",                                â”‚
â”‚          "title": "Verfahrensfreiheit nach Bundesland",          â”‚
â”‚          "widget": {                                              â”‚
â”‚            "type": "table",                                       â”‚
â”‚            "headers": ["Bundesland", "Max. GrÃ¶ÃŸe", "Max. HÃ¶he",  â”‚
â”‚                        "Genehmigungsfrei?"],                      â”‚
â”‚            "rows": "[AUTO-POPULATED from RAG]"                    â”‚
â”‚          }                                                        â”‚
â”‚        }                                                          â”‚
â”‚      ]                                                            â”‚
â”‚    }                                                              â”‚
â”‚  }                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 3: ITERATIVE RESPONSE GENERATION WITH QUALITY CHECKS         â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ LLM Response Generation (mit adaptivem Template):                  â”‚
â”‚                                    â†“                                â”‚
â”‚ STREAMING (NDJSON):                                                â”‚
â”‚  {"type":"response_start","metadata":{"template":"adaptive_..."}} â”‚
â”‚  {"type":"section_start","section_id":"question_clarification"}   â”‚
â”‚  {"type":"text_chunk","content":"FÃ¼r eine prÃ¤zise Antwort..."}    â”‚
â”‚  {"type":"widget","widget":{"type":"interactive_form",...}}       â”‚
â”‚  {"type":"section_end","section_id":"question_clarification"}     â”‚
â”‚                                    â†“                                â”‚
â”‚ QUALITY CHECKS (wÃ¤hrend Streaming):                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Backend Quality Monitor:                                      â”‚ â”‚
â”‚  â”‚  1. VollstÃ¤ndigkeit: Alle required_criteria behandelt?       â”‚ â”‚
â”‚  â”‚  2. Accuracy: RAG-Quellen korrekt zitiert?                   â”‚ â”‚
â”‚  â”‚  3. Konsistenz: WidersprÃ¼che in Antwort?                     â”‚ â”‚
â”‚  â”‚  4. Token-Budget: Innerhalb estimated_tokens?                â”‚ â”‚
â”‚  â”‚                                                               â”‚ â”‚
â”‚  â”‚ Bei Problemen:                                                â”‚ â”‚
â”‚  â”‚  â†’ Streaming pausieren                                        â”‚ â”‚
â”‚  â”‚  â†’ LLM-Nachfrage (Self-Correction)                           â”‚ â”‚
â”‚  â”‚  â†’ Streaming fortsetzen mit Korrektur                        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                    â†“                                â”‚
â”‚ FINAL METADATA (response_end):                                     â”‚
â”‚  {                                                                 â”‚
â”‚    "quality_metrics": {                                            â”‚
â”‚      "completeness": 0.95,  # 95% der Kriterien behandelt        â”‚
â”‚      "accuracy": 0.92,      # 92% RAG-Quellen korrekt            â”‚
â”‚      "consistency": 0.88,   # 88% konsistent                     â”‚
â”‚      "token_efficiency": 0.91  # 3200/3500 Tokens genutzt        â”‚
â”‚    },                                                             â”‚
â”‚    "confidence": 0.89,  # Finale Confidence                       â”‚
â”‚    "sources": [...],                                              â”‚
â”‚    "suggestions": [                                                â”‚
â”‚      "Bitte gib dein Bundesland an fÃ¼r prÃ¤zise Antwort",         â”‚
â”‚      "MÃ¶chtest du wissen welche Unterlagen du brauchst?"          â”‚
â”‚    ]                                                              â”‚
â”‚  }                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ Basic Template Frameworks (Handvoll Basis-Strukturen)

### Framework 1: **Verwaltungsrechtliche Frage** (Default)
```json
{
  "framework_id": "verwaltungsrechtliche_frage",
  "description": "Standard-Framework fÃ¼r verwaltungsrechtliche Fragen",
  "structure": {
    "required_sections": [
      {"id": "legal_basis", "title": "Rechtsgrundlage", "type": "markdown"},
      {"id": "assessment", "title": "Rechtliche Bewertung", "type": "markdown"},
      {"id": "sources", "title": "Quellen", "type": "source_list"}
    ],
    "optional_sections": [
      {"id": "clarification", "title": "RÃ¼ckfragen", "type": "interactive_form"},
      {"id": "process", "title": "Verfahren", "type": "process_graph"},
      {"id": "comparison", "title": "Vergleichstabelle", "type": "table"},
      {"id": "visualization", "title": "Visualisierung", "type": "canvas"}
    ]
  },
  "default_token_budget": 2500,
  "quality_criteria": {
    "min_rag_sources": 2,
    "min_confidence": 0.7,
    "required_legal_citations": true
  }
}
```

### Framework 2: **VollstÃ¤ndigkeitsprÃ¼fung** (Checklist-basiert)
```json
{
  "framework_id": "vollstaendigkeitspruefung",
  "description": "Framework fÃ¼r formale VollstÃ¤ndigkeitsprÃ¼fungen",
  "structure": {
    "required_sections": [
      {"id": "checklist", "title": "PrÃ¼fkriterien", "type": "checklist"},
      {"id": "missing_items", "title": "Fehlende Elemente", "type": "table"},
      {"id": "recommendations", "title": "Handlungsempfehlungen", "type": "markdown"}
    ]
  },
  "default_token_budget": 3000,
  "quality_criteria": {
    "completeness": 1.0,  # MUSS alle Kriterien prÃ¼fen
    "min_confidence": 0.8
  }
}
```

### Framework 3: **Prozess-Navigation** (Graph-basiert)
```json
{
  "framework_id": "prozess_navigation",
  "description": "Framework fÃ¼r Verwaltungsprozess-Anleitungen",
  "structure": {
    "required_sections": [
      {"id": "current_step", "title": "Aktueller Schritt", "type": "markdown"},
      {"id": "process_graph", "title": "Prozessablauf", "type": "neo4j_graph"},
      {"id": "next_steps", "title": "NÃ¤chste Schritte", "type": "ordered_list"}
    ]
  },
  "default_token_budget": 2000,
  "quality_criteria": {
    "process_graph_required": true,
    "min_steps_shown": 3
  }
}
```

### Framework 4: **Vergleichsanalyse** (Multi-Option)
```json
{
  "framework_id": "vergleichsanalyse",
  "description": "Framework fÃ¼r Vergleiche (z.B. BundeslÃ¤nder, Verfahren)",
  "structure": {
    "required_sections": [
      {"id": "comparison_table", "title": "Vergleichstabelle", "type": "table"},
      {"id": "recommendation", "title": "Empfehlung", "type": "markdown"}
    ]
  },
  "default_token_budget": 2500
}
```

### Framework 5: **Detaillierte Rechtsanalyse** (Umfassend)
```json
{
  "framework_id": "detaillierte_rechtsanalyse",
  "description": "Framework fÃ¼r komplexe rechtliche Analysen",
  "structure": {
    "required_sections": [
      {"id": "executive_summary", "title": "Executive Summary", "type": "markdown"},
      {"id": "legal_basis", "title": "Rechtsgrundlagen", "type": "markdown"},
      {"id": "legal_assessment", "title": "Rechtliche Bewertung", "type": "markdown"},
      {"id": "case_law", "title": "Rechtsprechung", "type": "table"},
      {"id": "conclusion", "title": "Fazit", "type": "markdown"}
    ]
  },
  "default_token_budget": 8000,  # SEHR HOCH
  "quality_criteria": {
    "min_rag_sources": 5,
    "min_confidence": 0.85,
    "legal_citations_required": true
  }
}
```

---

## ğŸ§  LLM Hypothesis Generation - Prompt

```python
HYPOTHESIS_GENERATION_PROMPT = """
Du bist VERITAS Hypothesis Generator.

AUFGABE: Analysiere die User-Frage und den RAG-Kontext (semantisch + Prozess-Graph).
Erstelle eine Hypothese: Welche Informationen brauchst du noch fÃ¼r eine vollstÃ¤ndige Antwort?

INPUT:
- User Query: "{user_query}"
- RAG Semantic Results: {rag_semantic_results}
- RAG Process Graph: {rag_process_graph}

OUTPUT (JSON):
{{
  "required_criteria": [
    "Liste von PrÃ¼fkriterien, die beantwortet werden mÃ¼ssen",
    "z.B. 'GebÃ¤udeklasse bestimmen', 'Bundesland-Regelung prÃ¼fen'"
  ],
  "missing_information": [
    "Informationen, die in der Frage NICHT angegeben wurden",
    "z.B. 'Bundesland nicht genannt', 'GrundstÃ¼cksgrÃ¶ÃŸe fehlt'"
  ],
  "available_information": [
    "Informationen, die aus RAG-Kontext VERFÃœGBAR sind",
    "z.B. 'BauGB Â§35 gefunden', 'Prozess-Graph fÃ¼r Baugenehmigung vorhanden'"
  ],
  "suggested_structure": {{
    "base_framework": "verwaltungsrechtliche_frage",  # WÃ¤hle aus: {framework_ids}
    "sections": [
      {{"id": "section_id", "type": "markdown|table|canvas|interactive_form|process_graph", "priority": 1-10}},
      ...
    ]
  }},
  "confidence_estimate": 0.0-1.0,  # Wie sicher bist du, die Frage VOLLSTÃ„NDIG beantworten zu kÃ¶nnen?
  "estimated_complexity": "simple|medium|complex|very_complex",
  "recommended_token_budget": 1000-16000,  # GeschÃ¤tzte Token-Anzahl
  "quality_checks_required": [
    "completeness",  # Alle Kriterien behandelt?
    "accuracy",      # RAG-Quellen korrekt?
    "consistency"    # Keine WidersprÃ¼che?
  ]
}}

REGELN:
1. Sei EHRLICH: Wenn Info fehlt â†’ in missing_information listen
2. Nutze RAG-Kontext: available_information basiert NUR auf RAG-Results
3. WÃ¤hle Framework weise: Einfache Frage â†’ verwaltungsrechtliche_frage, Checkliste â†’ vollstaendigkeitspruefung
4. Token-Budget: Simple: 1000-2500, Medium: 2500-5000, Complex: 5000-10000, Very Complex: 10000-16000
5. Confidence: Hoch (>0.8) nur wenn ALLE Infos verfÃ¼gbar, sonst Medium (0.5-0.8) oder Niedrig (<0.5)

Erstelle jetzt die Hypothese fÃ¼r die User-Frage.
"""
```

---

## ğŸ”„ Adaptive Template Generator - Pseudocode

```python
class AdaptiveTemplateGenerator:
    """
    Generiert Templates dynamisch basierend auf:
    1. User Query
    2. RAG Kontext (Semantic + Process Graph)
    3. LLM Hypothesis
    """
    
    BASIC_FRAMEWORKS = {
        'verwaltungsrechtliche_frage': Framework(...),
        'vollstaendigkeitspruefung': Framework(...),
        'prozess_navigation': Framework(...),
        'vergleichsanalyse': Framework(...),
        'detaillierte_rechtsanalyse': Framework(...)
    }
    
    async def generate_from_query(
        self,
        user_query: str,
        rag_context: Dict[str, Any]
    ) -> AdaptiveTemplate:
        """
        Generiert adaptives Template in 3 Schritten
        """
        
        # STEP 1: Hypothesis Generation (LLM Call 1 - SCHNELL ~500 Tokens)
        hypothesis = await self._generate_hypothesis(user_query, rag_context)
        
        # STEP 2: Framework Selection
        base_framework = self.BASIC_FRAMEWORKS[hypothesis['suggested_structure']['base_framework']]
        
        # STEP 3: Template Construction
        adaptive_template = self._construct_template(
            hypothesis=hypothesis,
            base_framework=base_framework,
            rag_context=rag_context
        )
        
        return adaptive_template
    
    async def _generate_hypothesis(
        self,
        user_query: str,
        rag_context: Dict
    ) -> Dict:
        """
        LLM Call 1: Hypothesis Generation
        """
        
        # Format RAG results
        rag_semantic = self._format_semantic_results(rag_context.get('semantic', []))
        rag_graph = self._format_graph_results(rag_context.get('graph', []))
        
        # LLM Prompt
        prompt = HYPOTHESIS_GENERATION_PROMPT.format(
            user_query=user_query,
            rag_semantic_results=rag_semantic,
            rag_process_graph=rag_graph,
            framework_ids=list(self.BASIC_FRAMEWORKS.keys())
        )
        
        # Call Ollama (FAST, nur ~500 Tokens)
        response = await ollama_client.generate_response(
            OllamaRequest(
                model="llama3.2:latest",
                prompt=prompt,
                system="Du bist VERITAS Hypothesis Generator. Output NUR JSON.",
                temperature=0.3,
                max_tokens=1000  # Hypothesis ist kurz
            ),
            stream=False  # Kein Streaming fÃ¼r Hypothesis
        )
        
        # Parse JSON
        hypothesis = json.loads(response.response)
        
        logger.info(f"ğŸ“Š Hypothesis: Confidence={hypothesis['confidence_estimate']}, "
                    f"Complexity={hypothesis['estimated_complexity']}, "
                    f"Tokens={hypothesis['recommended_token_budget']}")
        
        return hypothesis
    
    def _construct_template(
        self,
        hypothesis: Dict,
        base_framework: Framework,
        rag_context: Dict
    ) -> AdaptiveTemplate:
        """
        Konstruiert adaptives Template aus Hypothesis + Framework
        """
        
        # Start mit Base Framework
        sections = base_framework.structure['required_sections'].copy()
        
        # FÃ¼ge Hypothesis-basierte Sections hinzu
        for suggested_section in hypothesis['suggested_structure']['sections']:
            section_id = suggested_section['id']
            section_type = suggested_section['type']
            
            # Konstruiere Section-Spec
            if section_type == 'interactive_form':
                # Auto-generiere Form basierend auf missing_information
                section_spec = self._create_interactive_form(
                    hypothesis['missing_information']
                )
            elif section_type == 'process_graph':
                # Neo4j Query aus RAG Graph
                section_spec = self._create_process_graph(
                    rag_context['graph']
                )
            elif section_type == 'table':
                # Table aus required_criteria
                section_spec = self._create_comparison_table(
                    hypothesis['required_criteria'],
                    rag_context['semantic']
                )
            elif section_type == 'canvas':
                # Canvas-Visualisierung (z.B. AbstandsflÃ¤chen)
                section_spec = self._create_visualization(
                    hypothesis['required_criteria']
                )
            else:  # markdown
                section_spec = {
                    'type': 'markdown',
                    'id': section_id
                }
            
            sections.append(section_spec)
        
        # Sortiere nach Priority
        sections.sort(key=lambda s: suggested_section.get('priority', 999))
        
        # Konstruiere System Prompt
        system_prompt = self._generate_system_prompt(
            hypothesis=hypothesis,
            sections=sections,
            base_framework=base_framework
        )
        
        # Return Adaptive Template
        return AdaptiveTemplate(
            template_id=f"adaptive_{hash(user_query)}_{datetime.now().isoformat()}",
            base_framework=base_framework.framework_id,
            system_prompt=system_prompt,
            required_tokens=hypothesis['recommended_token_budget'],
            response_structure=sections,
            quality_checks=hypothesis['quality_checks_required'],
            confidence_estimate=hypothesis['confidence_estimate']
        )
    
    def _create_interactive_form(self, missing_info: List[str]) -> Dict:
        """
        Auto-generiert Interactive Form aus fehlenden Informationen
        
        Beispiel:
        missing_info = ["Bundesland nicht angegeben", "Carport-GrÃ¶ÃŸe fehlt"]
        
        â†’
        {
          "type": "interactive_form",
          "fields": [
            {"name": "bundesland", "type": "dropdown", "options": [...]},
            {"name": "carport_groesse", "type": "text", "placeholder": "z.B. 20mÂ²"}
          ]
        }
        """
        
        fields = []
        
        for info in missing_info:
            # Einfaches Keyword-Matching (spÃ¤ter NLP)
            if 'bundesland' in info.lower():
                fields.append({
                    'name': 'bundesland',
                    'type': 'dropdown',
                    'label': 'Bundesland',
                    'options': ['Baden-WÃ¼rttemberg', 'Bayern', 'Berlin', ...]
                })
            elif 'grÃ¶ÃŸe' in info.lower() or 'flÃ¤che' in info.lower():
                fields.append({
                    'name': 'groesse',
                    'type': 'text',
                    'label': 'GrÃ¶ÃŸe/FlÃ¤che',
                    'placeholder': 'z.B. 20mÂ²'
                })
            elif 'hÃ¶he' in info.lower():
                fields.append({
                    'name': 'hoehe',
                    'type': 'text',
                    'label': 'HÃ¶he',
                    'placeholder': 'z.B. 2.5m'
                })
            # ... weitere Muster
        
        return {
            'type': 'interactive_form',
            'title': 'Fehlende Informationen',
            'description': 'Bitte ergÃ¤nze folgende Angaben fÃ¼r eine prÃ¤zise Antwort:',
            'fields': fields
        }
    
    def _generate_system_prompt(
        self,
        hypothesis: Dict,
        sections: List[Dict],
        base_framework: Framework
    ) -> str:
        """
        Generiert System Prompt aus Hypothesis + Sections
        """
        
        prompt = f"""
Du bist VERITAS, ein Experte fÃ¼r deutsches Verwaltungsrecht.

AUFGABE: Beantworte die User-Frage basierend auf dem RAG-Kontext.

WICHTIG - HYPOTHESE-BASIERTE STRUKTUR:
- Required Criteria: {', '.join(hypothesis['required_criteria'])}
- Fehlende Informationen: {', '.join(hypothesis['missing_information'])}
- VerfÃ¼gbare Informationen: {', '.join(hypothesis['available_information'])}

ANTWORT-STRUKTUR (ZWINGEND):
"""
        
        for i, section in enumerate(sections, 1):
            prompt += f"\n{i}. {section.get('title', section['id'])} ({section['type']})"
            
            if section['type'] == 'interactive_form':
                prompt += "\n   â†’ Erstelle interaktives Formular fÃ¼r fehlende Infos"
            elif section['type'] == 'process_graph':
                prompt += "\n   â†’ Zeige Prozess-Graph aus Neo4j RAG"
            elif section['type'] == 'table':
                prompt += "\n   â†’ Erstelle Vergleichstabelle"
        
        prompt += f"""

QUALITÃ„TS-CHECKS (wÃ¤hrend Generation):
{', '.join(hypothesis['quality_checks_required'])}

TOKEN-BUDGET: {hypothesis['recommended_token_budget']} Tokens

OUTPUT-FORMAT (NDJSON Streaming):
{{"type":"response_start","metadata":{{"template":"adaptive_..."}}}}
{{"type":"section_start","section_id":"..."}}
{{"type":"text_chunk","content":"..."}}
{{"type":"widget","widget":{{...}}}}
{{"type":"section_end","section_id":"..."}}
{{"type":"response_end","metadata":{{"quality_metrics":{{...}}}}}}

Beantworte jetzt die User-Frage.
"""
        
        return prompt
```

---

## ğŸ¯ Quality Checks wÃ¤hrend Streaming

```python
class ResponseQualityMonitor:
    """
    Ãœberwacht LLM-Response wÃ¤hrend Streaming
    PrÃ¼ft: VollstÃ¤ndigkeit, Accuracy, Konsistenz
    """
    
    def __init__(self, hypothesis: Dict, rag_context: Dict):
        self.hypothesis = hypothesis
        self.rag_context = rag_context
        self.sections_completed = set()
        self.criteria_addressed = set()
        self.sources_cited = set()
    
    async def check_chunk(self, chunk: Dict) -> QualityCheckResult:
        """
        PrÃ¼ft einzelnen NDJSON-Chunk wÃ¤hrend Streaming
        """
        
        chunk_type = chunk.get('type')
        
        if chunk_type == 'section_end':
            section_id = chunk.get('section_id')
            self.sections_completed.add(section_id)
            
        elif chunk_type == 'text_chunk':
            # PrÃ¼fe ob required_criteria erwÃ¤hnt werden
            content = chunk.get('content', '')
            for criterion in self.hypothesis['required_criteria']:
                if self._criterion_mentioned(criterion, content):
                    self.criteria_addressed.add(criterion)
            
            # PrÃ¼fe RAG-Source-Citations
            sources = self._extract_sources(content)
            for source in sources:
                if self._source_valid(source, self.rag_context):
                    self.sources_cited.add(source)
                else:
                    # WARNUNG: UngÃ¼ltige Quelle zitiert (Hallucination!)
                    return QualityCheckResult(
                        passed=False,
                        issue="invalid_source_citation",
                        details=f"Quelle '{source}' nicht in RAG-Kontext gefunden",
                        action="request_correction"
                    )
        
        # VollstÃ¤ndigkeits-Check (am Ende)
        if chunk_type == 'response_end':
            completeness = len(self.criteria_addressed) / len(self.hypothesis['required_criteria'])
            
            if completeness < 0.8:  # Weniger als 80% der Kriterien behandelt
                return QualityCheckResult(
                    passed=False,
                    issue="incomplete_response",
                    details=f"Nur {completeness*100:.0f}% der Kriterien behandelt",
                    missing_criteria=set(self.hypothesis['required_criteria']) - self.criteria_addressed,
                    action="request_completion"
                )
        
        # Alles OK
        return QualityCheckResult(passed=True)
    
    def get_final_quality_metrics(self) -> Dict:
        """
        Berechnet finale QualitÃ¤ts-Metriken
        """
        
        return {
            'completeness': len(self.criteria_addressed) / len(self.hypothesis['required_criteria']),
            'accuracy': len(self.sources_cited) / max(1, len(self._extract_all_citations())),
            'consistency': self._check_consistency(),  # TODO: Widerspruchs-Detektion
            'sections_completed': len(self.sections_completed),
            'criteria_addressed': list(self.criteria_addressed),
            'sources_cited': list(self.sources_cited)
        }
```

---

## ğŸ“Š Beispiel: Adaptive Response Generation

### User Query:
```
"Ist fÃ¼r meinen Carport eine Baugenehmigung nÃ¶tig?"
```

### Phase 1: RAG + Hypothesis

**RAG Results (Semantic):**
```json
{
  "semantic": [
    {"text": "BauGB Â§35 Abs. 2: AuÃŸenbereich - Baugenehmigungspflicht", "score": 0.92},
    {"text": "LBO BW Â§50: Verfahrensfreie Vorhaben - Garagen bis 30mÂ²", "score": 0.88}
  ],
  "graph": [
    {"process": "Baugenehmigung", "steps": ["Antrag", "PrÃ¼fung", "Bescheid"]}
  ]
}
```

**LLM Hypothesis:**
```json
{
  "required_criteria": [
    "Bundesland bestimmen (LBO variiert!)",
    "Carport-GrÃ¶ÃŸe/HÃ¶he prÃ¼fen (Verfahrensfreiheit?)",
    "GrundstÃ¼ckslage prÃ¼fen (AuÃŸenbereich vs. Bebauungsplan)",
    "Carport als 'Garage' oder 'GebÃ¤ude' klassifizieren"
  ],
  "missing_information": [
    "Bundesland nicht angegeben",
    "Carport-GrÃ¶ÃŸe nicht angegeben",
    "Carport-HÃ¶he nicht angegeben",
    "GrundstÃ¼ckslage unklar"
  ],
  "available_information": [
    "BauGB Â§35 Abs. 2 gefunden (AuÃŸenbereich)",
    "LBO BW Â§50 gefunden (Verfahrensfreiheit bis 30mÂ²)",
    "Prozess-Graph fÃ¼r Baugenehmigung vorhanden"
  ],
  "suggested_structure": {
    "base_framework": "verwaltungsrechtliche_frage",
    "sections": [
      {"id": "missing_info_form", "type": "interactive_form", "priority": 1},
      {"id": "legal_assessment", "type": "markdown", "priority": 2},
      {"id": "bundesland_comparison", "type": "table", "priority": 3},
      {"id": "process_steps", "type": "process_graph", "priority": 4}
    ]
  },
  "confidence_estimate": 0.55,  # NIEDRIG (viele Infos fehlen)
  "estimated_complexity": "medium",
  "recommended_token_budget": 3500
}
```

### Phase 2: Template Construction

**Generated Adaptive Template:**
```json
{
  "template_id": "adaptive_carport_genehmigung_2025-10-12-18-30-45",
  "base_framework": "verwaltungsrechtliche_frage",
  "system_prompt": "[AUTO-GENERIERT, siehe oben]",
  "required_tokens": 3500,
  "response_structure": {
    "sections": [
      {
        "id": "missing_info_form",
        "title": "Fehlende Informationen",
        "type": "interactive_form",
        "widget": {
          "type": "interactive_form",
          "fields": [
            {"name": "bundesland", "type": "dropdown", "options": ["Baden-WÃ¼rttemberg", ...]},
            {"name": "carport_groesse", "type": "text", "placeholder": "z.B. 20mÂ²"},
            {"name": "carport_hoehe", "type": "text", "placeholder": "z.B. 2.5m"},
            {"name": "grundstueckslage", "type": "dropdown", "options": ["Bebauungsplan", "AuÃŸenbereich"]}
          ]
        }
      },
      {
        "id": "legal_assessment",
        "title": "Rechtliche Einordnung (vorlÃ¤ufig)",
        "type": "markdown"
      },
      {
        "id": "bundesland_comparison",
        "title": "Verfahrensfreiheit nach Bundesland",
        "type": "table",
        "widget": {
          "type": "table",
          "headers": ["Bundesland", "Max. GrÃ¶ÃŸe", "Max. HÃ¶he", "Genehmigungsfrei?"],
          "rows": [
            ["Baden-WÃ¼rttemberg", "30mÂ²", "3m", "Ja (LBO Â§50)"],
            ["Bayern", "30mÂ²", "3m", "Ja (BayBO Art. 57)"],
            ["..."]
          ]
        }
      },
      {
        "id": "process_steps",
        "title": "Falls genehmigungspflichtig: Verfahrensschritte",
        "type": "process_graph"
      }
    ]
  }
}
```

### Phase 3: Response Generation (NDJSON Streaming)

```ndjson
{"type":"response_start","metadata":{"template":"adaptive_carport_genehmigung_2025-10-12-18-30-45","confidence_estimate":0.55}}
{"type":"section_start","section_id":"missing_info_form"}
{"type":"text_chunk","content":"FÃ¼r eine prÃ¤zise Antwort benÃ¶tige ich noch folgende Informationen:"}
{"type":"widget","widget":{"type":"interactive_form","fields":[{"name":"bundesland","type":"dropdown",...}]}}
{"type":"section_end","section_id":"missing_info_form"}
{"type":"section_start","section_id":"legal_assessment"}
{"type":"text_chunk","content":"## Rechtliche Einordnung (vorlÃ¤ufig)\n\nGemÃ¤ÃŸ **BauGB Â§35 Abs. 2** sind im **AuÃŸenbereich** grundsÃ¤tzlich Bauvorhaben genehmigungspflichtig..."}
{"type":"text_chunk","content":"ABER: Viele BundeslÃ¤nder haben **Verfahrensfreiheit** fÃ¼r kleinere Garagen/Carports (siehe Tabelle)..."}
{"type":"section_end","section_id":"legal_assessment"}
{"type":"section_start","section_id":"bundesland_comparison"}
{"type":"widget","widget":{"type":"table","headers":["Bundesland","Max. GrÃ¶ÃŸe",...],"rows":[...]}}
{"type":"section_end","section_id":"bundesland_comparison"}
{"type":"section_start","section_id":"process_steps"}
{"type":"text_chunk","content":"Falls Ihr Carport **nicht** unter Verfahrensfreiheit fÃ¤llt:"}
{"type":"widget","widget":{"type":"process_graph","nodes":[...],"edges":[...]}}
{"type":"section_end","section_id":"process_steps"}
{"type":"response_end","metadata":{"quality_metrics":{"completeness":0.95,"accuracy":0.92,"consistency":0.88},"confidence":0.78,"sources":[...],"suggestions":["Bitte gib dein Bundesland an","MÃ¶chtest du wissen welche Unterlagen du brauchst?"]}}
```

---

## âœ… Vorteile des Adaptive-Template-Ansatzes

| Aspekt | Fix Templates (v4.1) | Adaptive Templates (v5.0) |
|--------|---------------------|---------------------------|
| **FlexibilitÃ¤t** | âŒ 5 feste Templates | âœ… Unbegrenzt (LLM-generiert) |
| **Unerwartete Fragen** | âŒ Fallback auf Default | âœ… Passt sich an |
| **Fehlende Informationen** | âŒ Keine RÃ¼ckfrage | âœ… Auto-generiertes Formular |
| **KomplexitÃ¤t** | âŒ Manuell kategorisieren | âœ… LLM schÃ¤tzt automatisch |
| **Token-Effizienz** | âš ï¸ Feste Limits | âœ… Dynamisch basierend auf Bedarf |
| **Quality Checks** | âŒ Keine | âœ… WÃ¤hrend Streaming |
| **RAG-Integration** | âš ï¸ NachtrÃ¤glich | âœ… Von Anfang an (Hypothesis) |
| **Wartung** | âŒ 5 Templates pflegen | âœ… Nur 5 Basic Frameworks |

---

## ğŸš€ Implementation Roadmap (AKTUALISIERT fÃ¼r v5.0)

### Phase 1: Hypothesis Generation (2-3 Tage)
- [ ] `HYPOTHESIS_GENERATION_PROMPT` erstellen
- [ ] `AdaptiveTemplateGenerator._generate_hypothesis()` implementieren
- [ ] 5 Basic Frameworks definieren (JSON-Specs)
- [ ] Ollama-Integration fÃ¼r Hypothesis (fast, ~500 tokens)
- [ ] Test mit Mock-RAG-Results

### Phase 2: Template Construction (2-3 Tage)
- [ ] `AdaptiveTemplateGenerator._construct_template()` implementieren
- [ ] Auto-Form-Generator (`_create_interactive_form()`)
- [ ] Auto-Table-Generator (`_create_comparison_table()`)
- [ ] Auto-Graph-Integration (`_create_process_graph()`)
- [ ] System-Prompt-Generator (`_generate_system_prompt()`)

### Phase 3: Quality Monitoring (2-3 Tage)
- [ ] `ResponseQualityMonitor` implementieren
- [ ] Completeness-Check (Kriterien-Abdeckung)
- [ ] Accuracy-Check (RAG-Source-Validation)
- [ ] Consistency-Check (Widerspruchs-Detektion)
- [ ] Self-Correction-Mechanismus (bei Quality-Fails)

### Phase 4: Frontend Integration (2-3 Tage)
- [ ] Interactive Form Widget (`_render_interactive_form()`)
- [ ] Process Graph Widget (`_render_neo4j_graph()`)
- [ ] Quality Metrics Display (Completeness, Accuracy, Consistency)
- [ ] Template Badge (zeigt Framework + Confidence)

### Phase 5: End-to-End Testing (2-3 Tage)
- [ ] Test mit realen verwaltungsrechtlichen Fragen
- [ ] Hypothesis Quality (sind Kriterien korrekt?)
- [ ] Template Quality (ist Struktur sinnvoll?)
- [ ] Response Quality (Completeness, Accuracy, Consistency)
- [ ] Performance (Hypothesis-Zeit + Response-Zeit)

### Phase 6: Optimization (1-2 Tage)
- [ ] Hypothesis-Caching (gleiche Frage â†’ gleiche Hypothesis)
- [ ] Framework-Selection-Tuning (bessere Auto-Selection)
- [ ] Quality-Threshold-Tuning (wann Self-Correction?)
- [ ] Documentation

**Total:** 11-17 Tage (gleich wie v4.1, aber VIEL flexibler!)

---

## ğŸ¯ Success Metrics (v5.0)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ METRIC 1: Hypothesis Quality                                   â”‚
â”‚  - Required Criteria Accuracy: > 90% (vom User bestÃ¤tigt)     â”‚
â”‚  - Missing Information Detection: > 95%                        â”‚
â”‚  - Framework Selection Accuracy: > 85%                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ METRIC 2: Response Quality (Auto-Checked)                      â”‚
â”‚  - Completeness: > 0.90 (90% der Kriterien behandelt)         â”‚
â”‚  - Accuracy: > 0.92 (92% der Quellen korrekt)                 â”‚
â”‚  - Consistency: > 0.88 (88% konsistent)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ METRIC 3: Performance                                          â”‚
â”‚  - Hypothesis Generation: < 500ms                             â”‚
â”‚  - Template Construction: < 200ms                             â”‚
â”‚  - Response Streaming: Same as v4.1 (1-3s)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ METRIC 4: User Satisfaction                                    â”‚
â”‚  - Fragen ohne fehlende Info: Confidence > 0.8 (80%)          â”‚
â”‚  - Fragen mit fehlender Info: Interactive Form erscheint 95%  â”‚
â”‚  - Quality Metrics transparent (User versteht Confidence)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

**END OF ADAPTIVE RESPONSE FRAMEWORK CONCEPT (v5.0)**

**Hauptunterschied zu v4.1:**
- v4.1: 5 **feste** Templates (manuell definiert)
- v5.0: **LLM-generierte** Templates (adaptiv, unbegrenzt)
- v5.0: **Hypothesis-basiert** (LLM entscheidet selbst was es braucht)
- v5.0: **Quality Checks** wÃ¤hrend Streaming (Self-Correction)
