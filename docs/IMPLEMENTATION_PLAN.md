# VERITAS/VCC Deep Research System - Gap Analysis & Implementation Plan

**Datum:** 11. Oktober 2025  
**Version:** 1.0  
**Status:** üî¥ CRITICAL - Architektur-Refactoring erforderlich

---

## üìä Executive Summary

### Konzept vs. Realit√§t

| Aspekt | Konzept (Soll) | Implementierung (Ist) | Gap | Priorit√§t |
|--------|----------------|----------------------|-----|-----------|
| **Macro-Orchestrierung** | Prefect (langlebige Workflows) | ‚ùå Nicht vorhanden | NIEDRIG | ÔøΩ P3 |
| **Micro-Orchestrierung** | ~~LangGraph~~ Custom StateGraph | ‚úÖ SupervisorAgent vorhanden | NIEDRIG | ‚úÖ OK |
| **Agenten-Architektur** | Spezialisierte Tool-Agenten | ‚úÖ Vorhanden (9+ Agenten) | NIEDRIG | ‚úÖ OK |
| **Zustandsverwaltung** | Persistentes JSON Framework | ‚ùå Nur In-Memory | HOCH | üî¥ P0 |
| **Reflexion/Selbstkorrektur** | LLM-as-a-Judge, RAG-Triade | ‚ùå Nicht vorhanden | HOCH | üî¥ P0 |
| **Kryptograph. Integrit√§t** | Hash-Kette, Signaturen, QET | ‚ùå Nicht vorhanden | MITTEL | üü° P2 |
| **Rich Media** | Nicht im Konzept | ‚úÖ **NEU: Implementiert!** | BONUS | ‚úÖ ++ |
| **On-Premise LLM** | Ollama/vLLM | ‚úÖ Ollama integriert | NIEDRIG | ‚úÖ OK |
| **Datenquellen** | Neo4j, ChromaDB, SQL, SearxNG | Teilweise (ChromaDB, SQL) | MITTEL | üü° P1 |

**üîß ARCHITEKTUR-ENTSCHEIDUNG:** Wir verzichten auf LangGraph und bauen stattdessen eine **Custom State Machine** in SupervisorAgent ein. Vorteil: Keine neue Dependency, volle Kontrolle, evolution√§re Erweiterung.

### Kritische Erkenntnisse

**‚úÖ ST√ÑRKEN (bereits implementiert):**
1. **Agenten-√ñkosystem:** 9+ spezialisierte Agenten (Environmental, Financial, Social, Traffic, Wikipedia, Building, Atmospheric)
2. **JSON Citation System:** Revolution√§rer Ansatz - NICHT im Konzept, aber BESSER als urspr√ºnglich geplant!
3. **Rich Media Support:** Maps, Charts, Tables, Images - Geht √ºber Konzept hinaus!
4. **SupervisorAgent:** Grundlegende Multi-Agent-Koordination vorhanden
5. **Ollama Integration:** On-Premise LLM funktioniert

**üî¥ KRITISCHE L√úCKEN:**
1. **Keine Zustandspersistenz:** Kein progressives JSON Framework ‚Üí Recherchen nicht wiederaufsetzbar
2. **Keine Reflexionsschleife:** Kein Evaluator-Agent ‚Üí Keine Selbstkorrektur
3. **Fehlende Datenquellen:** Neo4j, SearxNG nicht integriert

**‚úÖ NICHT KRITISCH (bereits gut gel√∂st):**
- ~~LangGraph~~ ‚Üí SupervisorAgent reicht f√ºr Micro-Orchestrierung
- ~~Prefect~~ ‚Üí FastAPI reicht f√ºr kurze Workflows (optional sp√§ter)

**üéØ STRATEGISCHE EMPFEHLUNG:**

Das System hat eine **hervorragende Basis** (Agenten, Rich Media, JSON Citations). Wir brauchen **KEINE** neuen Libraries (LangGraph, Prefect), sondern nur **evolution√§re Erweiterung** der bestehenden Architektur.

**Empfehlung: Evolution√§rer Ansatz (OHNE neue Dependencies!)**
- ‚úÖ **Behalten:** SupervisorAgent, Agenten, JSON Citations, Rich Media
- üîÑ **Erweitern:** Custom State Machine in SupervisorAgent, Persistentes JSON Framework
- ‚ûï **Hinzuf√ºgen:** Evaluator-Agent, Neo4j, SearxNG
- üöÄ **Kein Prefect/LangGraph:** Zu komplex f√ºr unsere Anwendung

---

## üèóÔ∏è Architektur-Abgleich

### Konzept: 4-Layer Deep Research Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Layer 4: Macro-Orchestrierung (OPTIONAL)   ‚îÇ
‚îÇ  ‚ùå VERZICHTET: Prefect zu komplex         ‚îÇ
‚îÇ  ‚Üí FastAPI Endpoints reichen f√ºr MVP      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Layer 3: Micro-Orchestrierung (CUSTOM)     ‚îÇ
‚îÇ  ‚úÖ L√ñSUNG: SupervisorAgent + State Machine‚îÇ
‚îÇ  - Custom Reflexions-Loop (kein LangGraph) ‚îÇ
‚îÇ  - Bedingte Verzweigungen                  ‚îÇ
‚îÇ  - Iterative Zyklen                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Layer 2: Spezialisierte Agenten            ‚îÇ
‚îÇ  ‚úÖ BEREITS VORHANDEN (9+ Agenten)         ‚îÇ
‚îÇ  + Evaluator Agent (NEU)                   ‚îÇ
‚îÇ  + Neo4j Agent (NEU)                       ‚îÇ
‚îÇ  + SearxNG Agent (NEU)                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Layer 1: Persistente Zustandsverwaltung    ‚îÇ
‚îÇ  ‚úÖ L√ñSUNG: PostgreSQL + JSON Framework    ‚îÇ
‚îÇ  - Execution Trace (unver√§nderlich)        ‚îÇ
‚îÇ  - Hash-Kette (Blockchain-√§hnlich)         ‚îÇ
‚îÇ  - Digitale Signaturen (optional)          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Ist-Zustand: VERITAS Current Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ‚úÖ Layer 4: FastAPI Endpoints (AUSREICHEND)‚îÇ
‚îÇ    Direkte Endpoints reichen f√ºr MVP      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ üü° Layer 3: SupervisorAgent (GUT)          ‚îÇ
‚îÇ    ‚úÖ Agent Selection                      ‚îÇ
‚îÇ    ‚úÖ Multi-Agent Coordination             ‚îÇ
‚îÇ    ‚ùå FEHLT: Reflexions-Schleife           ‚îÇ
‚îÇ    ‚Üí L√ñSUNG: Custom State Machine bauen   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ‚úÖ Layer 2: GUT IMPLEMENTIERT              ‚îÇ
‚îÇ    ‚úÖ EnvironmentalAgent                   ‚îÇ
‚îÇ    ‚úÖ FinancialAgent                       ‚îÇ
‚îÇ    ‚úÖ SocialAgent                          ‚îÇ
‚îÇ    ‚úÖ TrafficAgent                         ‚îÇ
‚îÇ    ‚úÖ WikipediaAgent                       ‚îÇ
‚îÇ    ‚úÖ BuildingAgent                        ‚îÇ
‚îÇ    ‚úÖ AtmosphericFlowAgent                 ‚îÇ
‚îÇ    ‚ùå Graph DB Agent (Neo4j) - FEHLT       ‚îÇ
‚îÇ    ‚ùå Web Search Agent (SearxNG) - FEHLT   ‚îÇ
‚îÇ    ‚ùå Evaluator Agent - FEHLT              ‚îÇ
‚îÇ    ‚úÖ **BONUS: JSON Citation Formatter**   ‚îÇ
‚îÇ    ‚úÖ **BONUS: Rich Media Schema**         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ‚ùå Layer 1: KRITISCH FEHLEND               ‚îÇ
‚îÇ    ‚ùå Kein persistentes JSON Framework     ‚îÇ
‚îÇ    ‚ùå Kein Execution Trace                 ‚îÇ
‚îÇ    ‚ùå Keine Hash-Kette                     ‚îÇ
‚îÇ    ‚ùå Keine Signaturen                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîç Detaillierte Gap-Analyse

### 1. Macro-Orchestrierung (Prefect)

**Konzept:**
- Prefect verwaltet langlebige Workflows (Stunden/Tage)
- Intelligent Retries bei tempor√§ren Fehlern
- Human-in-the-Loop Checkpoints
- Zentrales Observability Dashboard

**Ist-Zustand:** ‚ùå Nicht vorhanden

**Auswirkungen:**
- ‚ùå Workflows k√∂nnen nicht √ºber Stunden/Tage laufen
- ‚ùå Keine automatischen Retries bei Fehlern
- ‚ùå Keine Human-Validierung m√∂glich
- ‚ùå Keine zentrale Workflow-√úberwachung

**Empfehlung:** üü° **Phase 2 (Optional)**
- F√ºr Prototyp NICHT kritisch
- Erst relevant bei Multi-Stunden-Recherchen
- Kann sp√§ter hinzugef√ºgt werden ohne Architektur-√Ñnderung

---

### 2. Micro-Orchestrierung (LangGraph)

**Konzept:**
```python
# LangGraph StateGraph mit bedingten Verzweigungen
from langgraph.graph import StateGraph

workflow = StateGraph(AgentState)

# Nodes
workflow.add_node("parse_query", parse_initial_query)
workflow.add_node("generate_plan", planner_agent)
workflow.add_node("execute_step", execute_agent_step)
workflow.add_node("evaluate_results", evaluator_agent)
workflow.add_node("reformulate", reformulate_query)
workflow.add_node("synthesize", synthesize_report)

# Conditional Edges (Reflexions-Schleife!)
workflow.add_conditional_edges(
    "evaluate_results",
    decide_next_step,  # Router function
    {
        "refine": "reformulate",     # Schlecht ‚Üí Neu formulieren
        "continue": "execute_step",  # OK ‚Üí N√§chster Schritt
        "complete": "synthesize"     # Gut ‚Üí Abschluss
    }
)

# Compile
app = workflow.compile(checkpointer=postgres_checkpointer)
```

**Ist-Zustand:** üü° **Teilweise - SupervisorAgent**

```python
# veritas_supervisor_agent.py (Lines 916+)
class SupervisorAgent:
    async def process_query(self, query, context):
        # 1. Agent Selection
        selected_agents = await self.selector.select_agents(query)
        
        # 2. Agent Execution (parallel)
        agent_results = await self.execute_agents(selected_agents, query)
        
        # 3. Synthesis
        synthesized = await self.synthesize_results(agent_results, query)
        
        return synthesized
```

**Gap:**
- ‚úÖ Hat: Agent Selection, Parallel Execution, Synthesis
- ‚ùå Fehlt: 
  - Keine explizite StateGraph (LangGraph)
  - Keine Reflexions-Schleife (evaluate ‚Üí refine ‚Üí retry)
  - Keine bedingten Verzweigungen
  - Keine persistente Zustandsverwaltung
  - Nicht wiederaufsetzbar

**Auswirkungen:**
- ‚ùå Schlechte Agenten-Antworten werden NICHT erkannt
- ‚ùå Keine automatische Neuformulierung bei schlechten Ergebnissen
- ‚ùå Kein iteratives Verfeinern
- ‚ùå Bei Crash ‚Üí gesamter Progress verloren

**Empfehlung:** üî¥ **P0 - Kritisch**

**Implementierungsplan:**
1. LangGraph StateGraph einf√ºhren
2. Evaluator-Agent implementieren (LLM-as-a-Judge)
3. Reflexions-Schleife bauen (evaluate ‚Üí decide ‚Üí refine/continue)
4. PostgreSQL Checkpointer f√ºr Persistenz

---

### 3. Spezialisierte Agenten

**Konzept vs. Ist:**

| Agent-Typ | Konzept | Ist-Zustand | Gap |
|-----------|---------|-------------|-----|
| **Graph DB (Neo4j)** | ‚úÖ Erforderlich | ‚ùå Fehlt | üî¥ Kritisch f√ºr Beziehungsanalysen |
| **Vector DB (ChromaDB)** | ‚úÖ Erforderlich | ‚úÖ Vorhanden | ‚úÖ OK |
| **SQL DB (PostgreSQL)** | ‚úÖ Erforderlich | ‚úÖ Vorhanden | ‚úÖ OK |
| **Web Search (SearxNG)** | ‚úÖ Erforderlich | ‚ùå Fehlt | üü° Wichtig f√ºr externe Recherche |
| **Evaluator (LLM-as-Judge)** | ‚úÖ Erforderlich | ‚ùå Fehlt | üî¥ Kritisch f√ºr Qualit√§t |
| **Planner (CoT)** | ‚úÖ Erforderlich | üü° SupervisorAgent.selector | üü° Erweitern |
| **Environmental** | ‚ùå Nicht im Konzept | ‚úÖ Implementiert | ‚úÖ Bonus! |
| **Financial** | ‚ùå Nicht im Konzept | ‚úÖ Implementiert | ‚úÖ Bonus! |
| **Social** | ‚ùå Nicht im Konzept | ‚úÖ Implementiert | ‚úÖ Bonus! |
| **Traffic** | ‚ùå Nicht im Konzept | ‚úÖ Implementiert | ‚úÖ Bonus! |
| **Wikipedia** | ‚ùå Nicht im Konzept | ‚úÖ Implementiert | ‚úÖ Bonus! |
| **Building** | ‚ùå Nicht im Konzept | ‚úÖ Implementiert | ‚úÖ Bonus! |
| **Atmospheric Flow** | ‚ùå Nicht im Konzept | ‚úÖ Implementiert | ‚úÖ Bonus! |

**Bewertung:**
- ‚úÖ **Hervorragend:** 7 Domain-spezifische Agenten (√ºber Konzept hinaus!)
- ‚ùå **Fehlt:** Neo4j, SearxNG, Evaluator (kritisch)
- üéØ **Strategie:** Vorhandene Agenten behalten, fehlende hinzuf√ºgen

---

### 4. Persistente Zustandsverwaltung (Progressive JSON Framework)

**Konzept: Rechtssicheres Saga-Log**

```json
{
  "research_id": "uuid-v4-...",
  "initial_query": "Analyse der Auswirkungen von KI...",
  "status": "IN_PROGRESS",
  "global_state": {
    "known_entities": ["KI", "Lieferkette", "Europa"],
    "hypotheses": ["KI erh√∂ht Effizienz um 10-15%"],
    "rejected_paths": ["Personalplanung out of scope"]
  },
  "execution_trace": [
    {
      "task_id": 1,
      "timestamp": "2024-10-27T10:00:00Z",
      "agent": "PlannerAgent",
      "action": "GENERATE_PLAN",
      "input": {...},
      "output": {...},
      "evaluation": {
        "metrics": {
          "context_relevance": 0.9,
          "groundedness": 0.85,
          "answer_relevance": 0.88
        }
      }
    },
    {
      "task_id": 2,
      "timestamp": "2024-10-27T10:15:00Z",
      "agent": "WebSearchAgent",
      "action": "SEARCH",
      ...
    }
  ],
  "integrity": {
    "currentStateHash": "sha256-abc123...",
    "previousStateHash": "sha256-def456...",
    "stateSignature": "RSA-signature...",
    "qualifiedTimestampToken": "RFC3161-token..."
  }
}
```

**Ist-Zustand:** ‚ùå **NICHT vorhanden**

Current response format (from Rich Media JSON):
```json
{
  "direct_answer": "...",
  "details": [...],
  "citations": [...],
  "sources": [...],
  "tables": [...],
  "maps": [...],
  "charts": [...]
}
```

**Gap:**
- ‚ùå Keine `execution_trace` ‚Üí Kein Audit-Trail
- ‚ùå Keine `global_state` ‚Üí Kein kumulatives Wissen
- ‚ùå Keine `integrity` ‚Üí Keine Rechtssicherheit
- ‚ùå Nicht persistent ‚Üí Bei Crash alles weg
- ‚ùå Kein `research_id` ‚Üí Keine Wiederaufsetzbarkeit

**Auswirkungen:**
- ‚ùå **Keine Nachvollziehbarkeit:** Warum wurde Entscheidung X getroffen?
- ‚ùå **Keine Wiederaufsetzbarkeit:** Crash ‚Üí Start von vorn
- ‚ùå **Keine Rechtssicherheit:** Kein gerichtsfester Beweis
- ‚ùå **Kein Debugging:** Wie kam das System zu diesem Ergebnis?
- ‚ùå **Keine Auditierung:** DSGVO/Compliance unm√∂glich

**Empfehlung:** üî¥ **P0 - Absolut kritisch!**

---

### 5. Reflexion & Selbstkorrektur (RAG-Triade)

**Konzept: Evaluator-Agent mit LLM-as-a-Judge**

```python
class EvaluatorAgent:
    async def evaluate(self, query: str, context: str, answer: str):
        """
        Bewertet Antwort-Qualit√§t nach RAG-Triade
        
        Returns:
            {
                "context_relevance": 0.0-1.0,
                "groundedness": 0.0-1.0,
                "answer_relevance": 0.0-1.0,
                "feedback": "Text-Begr√ºndung",
                "refinement_needed": True/False
            }
        """
        
        evaluation_prompt = f"""
Du bist ein kritischer Evaluator. Bewerte die Qualit√§t der Antwort:

**Frage:** {query}
**Kontext (Quellen):** {context}
**Antwort:** {answer}

Bewerte nach diesen Kriterien (0.0-1.0):

1. **Context Relevance:** Ist der Kontext relevant f√ºr die Frage?
2. **Groundedness:** Basiert die Antwort NUR auf dem Kontext (keine Halluzinationen)?
3. **Answer Relevance:** Beantwortet die Antwort die Frage direkt?

Gib JSON zur√ºck:
{{
  "context_relevance": 0.X,
  "groundedness": 0.X,
  "answer_relevance": 0.X,
  "feedback": "Begr√ºndung...",
  "refinement_needed": true/false
}}
"""
        
        evaluation = await self.llm.generate(evaluation_prompt)
        return json.loads(evaluation)
```

**Ist-Zustand:** ‚ùå **NICHT vorhanden**

SupervisorAgent macht:
```python
# veritas_supervisor_agent.py
async def synthesize_results(self, agent_results, query):
    # 1. Deduplizierung
    deduplicated = self._deduplicate_information(agent_results)
    
    # 2. Konflikt-Detektion (basic)
    conflicts = self._detect_contradictions(agent_results)
    
    # 3. LLM Synthesis (JSON ‚Üí IEEE)
    synthesized_text = await self.llm.generate(...)
    
    # ‚ùå KEINE Evaluation der Qualit√§t!
    # ‚ùå KEINE Reflexion!
    # ‚ùå KEIN Feedback-Loop!
    
    return SynthesizedResult(response_text=synthesized_text)
```

**Gap:**
- ‚ùå Keine Qualit√§tsbewertung nach Synthesis
- ‚ùå Keine Halluzinations-Detektion
- ‚ùå Keine Neuformulierung bei schlechten Ergebnissen
- ‚ùå Keine iterative Verbesserung

**Auswirkungen:**
- ‚ùå Schlechte Antworten werden nicht erkannt
- ‚ùå Halluzinationen bleiben unentdeckt
- ‚ùå Irrelevante Ergebnisse nicht gefiltert
- ‚ùå Keine automatische Qualit√§tsverbesserung

**Empfehlung:** üî¥ **P0 - Kritisch f√ºr Qualit√§t**

---

### 6. Kryptographische Integrit√§t

**Konzept: 3-Layer Security**

1. **Hash-Kette (Blockchain-√§hnlich):**
   ```python
   integrity = {
       "currentStateHash": sha256(execution_trace[-1]),
       "previousStateHash": sha256(execution_trace[-2]),
       # Jeder State versiegelt den vorherigen
   }
   ```

2. **Digitale Signatur (intern):**
   ```python
   # VCC Certificate Authority
   private_key = load_private_key("vcc_system.pem")
   signature = private_key.sign(current_hash)
   ```

3. **Qualifizierter Zeitstempel (extern):**
   ```python
   # eIDAS-zertifizierter TSP
   timestamp_token = tsp_client.get_timestamp(current_hash)
   # ‚Üí Rechtlich verbindlich (EU-weit)
   ```

**Ist-Zustand:** ‚ùå **NICHT vorhanden**

**Gap:**
- ‚ùå Keine Hash-Kette ‚Üí Manipulationen nicht erkennbar
- ‚ùå Keine Signaturen ‚Üí Keine Authentizit√§t
- ‚ùå Keine Zeitstempel ‚Üí Keine rechtliche Beweiskraft

**Empfehlung:** üü° **P2 - Wichtig f√ºr Compliance, nicht kritisch f√ºr MVP**

---

## üéØ Implementierungskonzept

### Phase 1: Foundation (4-6 Wochen) üî¥ KRITISCH

**Ziel:** Persistentes JSON Framework + LangGraph StateGraph

#### Sprint 1.1: Persistentes JSON Framework (2 Wochen)

**Tasks:**
1. **Schema Design**
   ```python
   # backend/agents/veritas_research_state.py
   
   from typing import TypedDict, List, Dict, Any
   from datetime import datetime
   
   class ExecutionTraceEntry(TypedDict):
       task_id: int
       timestamp: str
       agent: str
       action: str
       input: Dict[str, Any]
       output: Dict[str, Any]
       evaluation: Dict[str, Any]  # RAG-Triade Scores
   
   class ResearchState(TypedDict):
       research_id: str
       initial_query: str
       status: str  # "IN_PROGRESS", "COMPLETED", "FAILED"
       global_state: Dict[str, Any]
       execution_trace: List[ExecutionTraceEntry]
       current_task: Dict[str, Any]
       results_summary: Dict[str, Any]
       timestamps: Dict[str, str]
   ```

2. **PostgreSQL Persistence**
   ```python
   # backend/agents/veritas_state_persister.py
   
   class ResearchStatePersister:
       async def save_state(self, research_id: str, state: ResearchState):
           """Speichert Zustand in PostgreSQL"""
           await self.db.execute(
               "INSERT INTO research_states (id, state_json, updated_at) "
               "VALUES ($1, $2, $3) "
               "ON CONFLICT (id) DO UPDATE SET state_json = $2, updated_at = $3",
               research_id, json.dumps(state), datetime.utcnow()
           )
       
       async def load_state(self, research_id: str) -> ResearchState:
           """L√§dt Zustand aus PostgreSQL"""
           row = await self.db.fetchrow(
               "SELECT state_json FROM research_states WHERE id = $1",
               research_id
           )
           return json.loads(row['state_json'])
   ```

3. **Integration in SupervisorAgent**
   ```python
   # backend/agents/veritas_supervisor_agent.py
   
   class SupervisorAgent:
       def __init__(self):
           self.persister = ResearchStatePersister()
       
       async def process_query(self, query: str, research_id: str = None):
           # Load or create state
           if research_id:
               state = await self.persister.load_state(research_id)
           else:
               state = self._create_initial_state(query)
           
           # Process with state tracking
           while state['status'] == 'IN_PROGRESS':
               result = await self._execute_next_step(state)
               state['execution_trace'].append(result)
               await self.persister.save_state(state['research_id'], state)
           
           return state
   ```

**Deliverables:**
- ‚úÖ `veritas_research_state.py` - State Schema
- ‚úÖ `veritas_state_persister.py` - PostgreSQL Persistence
- ‚úÖ Migration: `CREATE TABLE research_states`
- ‚úÖ Integration in SupervisorAgent
- ‚úÖ Unit Tests

---

#### Sprint 1.2: LangGraph StateGraph (2 Wochen)

**Tasks:**
1. **LangGraph Installation**
   ```bash
   pip install langgraph langchain
   ```

2. **StateGraph Definition**
   ```python
   # backend/agents/veritas_langgraph_workflow.py
   
   from langgraph.graph import StateGraph
   from langgraph.checkpoint.postgres import PostgresSaver
   
   # State Schema
   class VeritasAgentState(TypedDict):
       query: str
       plan: Dict[str, Any]
       agent_results: List[AgentResult]
       evaluation: Dict[str, Any]
       refinement_count: int
       final_answer: str
   
   # Workflow Definition
   def create_veritas_workflow():
       workflow = StateGraph(VeritasAgentState)
       
       # Nodes
       workflow.add_node("parse_query", parse_initial_query)
       workflow.add_node("generate_plan", planner_agent)
       workflow.add_node("select_agents", agent_selector)
       workflow.add_node("execute_agents", execute_parallel_agents)
       workflow.add_node("evaluate", evaluator_agent)
       workflow.add_node("synthesize", synthesize_results)
       
       # Entry Point
       workflow.set_entry_point("parse_query")
       
       # Edges
       workflow.add_edge("parse_query", "generate_plan")
       workflow.add_edge("generate_plan", "select_agents")
       workflow.add_edge("select_agents", "execute_agents")
       workflow.add_edge("execute_agents", "evaluate")
       
       # Conditional Edge (Reflexions-Schleife!)
       workflow.add_conditional_edges(
           "evaluate",
           decide_next_action,
           {
               "refine": "generate_plan",  # Schlecht ‚Üí Neu planen
               "retry": "execute_agents",  # Mittel ‚Üí Retry
               "complete": "synthesize"    # Gut ‚Üí Fertig
           }
       )
       
       workflow.add_edge("synthesize", END)
       
       # PostgreSQL Checkpointer
       checkpointer = PostgresSaver.from_conn_string(
           "postgresql://user:pass@localhost/veritas"
       )
       
       return workflow.compile(checkpointer=checkpointer)
   ```

3. **Router Function (Entscheidungslogik)**
   ```python
   def decide_next_action(state: VeritasAgentState) -> str:
       """
       Entscheidet basierend auf Evaluation, was als n√§chstes passiert
       """
       eval = state['evaluation']
       
       # Check RAG-Triade Scores
       avg_score = (
           eval['context_relevance'] +
           eval['groundedness'] +
           eval['answer_relevance']
       ) / 3
       
       # Check refinement limit
       if state['refinement_count'] >= 3:
           return "complete"  # Max. 3 Versuche
       
       # Decision based on quality
       if avg_score >= 0.8:
           return "complete"  # Gut genug!
       elif avg_score >= 0.5:
           return "retry"     # Retry mit gleicher Strategie
       else:
           return "refine"    # Neu planen mit anderer Strategie
   ```

**Deliverables:**
- ‚úÖ `veritas_langgraph_workflow.py` - StateGraph Definition
- ‚úÖ PostgreSQL Checkpointer Setup
- ‚úÖ Conditional Edges f√ºr Reflexion
- ‚úÖ Integration mit SupervisorAgent
- ‚úÖ Integration Tests

---

#### Sprint 1.3: Evaluator-Agent (2 Wochen)

**Tasks:**
1. **Evaluator Implementation**
   ```python
   # backend/agents/veritas_evaluator_agent.py
   
   class EvaluatorAgent:
       def __init__(self, ollama_client):
           self.ollama = ollama_client
       
       async def evaluate_rag_triade(
           self, 
           query: str, 
           context: str, 
           answer: str
       ) -> Dict[str, Any]:
           """
           Bewertet Antwort nach RAG-Triade
           
           Returns:
               {
                   "context_relevance": 0.0-1.0,
                   "groundedness": 0.0-1.0,
                   "answer_relevance": 0.0-1.0,
                   "feedback": "Begr√ºndung",
                   "refinement_needed": True/False
               }
           """
           
           prompt = self._build_evaluation_prompt(query, context, answer)
           
           response = await self.ollama.generate(
               model="llama3.2:latest",
               prompt=prompt,
               temperature=0.2  # Niedrig f√ºr konsistente Bewertung
           )
           
           evaluation = json.loads(response)
           
           # Add refinement_needed flag
           avg_score = (
               evaluation['context_relevance'] +
               evaluation['groundedness'] +
               evaluation['answer_relevance']
           ) / 3
           
           evaluation['refinement_needed'] = avg_score < 0.7
           
           return evaluation
       
       def _build_evaluation_prompt(self, query, context, answer):
           return f"""
Du bist ein kritischer Qualit√§ts-Evaluator f√ºr RAG-Systeme.

Bewerte die folgende Antwort nach drei Kriterien (0.0-1.0):

**Frage:** {query}

**Kontext (Quellen):**
{context}

**Antwort:**
{answer}

**Bewertungskriterien:**

1. **Context Relevance (0.0-1.0):**
   - Ist der bereitgestellte Kontext relevant f√ºr die Frage?
   - Sind die Quellen hilfreich oder irrelevant?

2. **Groundedness / Faithfulness (0.0-1.0):**
   - Basiert die Antwort NUR auf dem Kontext?
   - Gibt es Halluzinationen (erfundene Fakten)?

3. **Answer Relevance (0.0-1.0):**
   - Beantwortet die Antwort die Frage direkt?
   - Ist sie fokussiert oder schweift sie ab?

**WICHTIG:** Antworte NUR mit valid JSON (kein Text davor/danach):

{{
  "context_relevance": 0.X,
  "groundedness": 0.X,
  "answer_relevance": 0.X,
  "feedback": "Kurze Begr√ºndung (2-3 S√§tze)",
  "halluzination_detected": true/false,
  "suggested_improvement": "Optional: Was k√∂nnte verbessert werden?"
}}
"""
   ```

2. **Integration in Workflow**
   ```python
   # Im LangGraph Workflow
   
   async def evaluator_agent(state: VeritasAgentState):
       """Node: Evaluiert die Agent-Ergebnisse"""
       
       evaluator = EvaluatorAgent(ollama_client)
       
       # Kombiniere alle Agent-Antworten
       context = "\n\n".join([
           f"[Agent {r.agent_type}]: {r.response_text}"
           for r in state['agent_results']
       ])
       
       # Letzte Antwort (Synthesis)
       answer = state['agent_results'][-1].response_text
       
       # Evaluate
       evaluation = await evaluator.evaluate_rag_triade(
           query=state['query'],
           context=context,
           answer=answer
       )
       
       # Update State
       return {
           "evaluation": evaluation,
           "refinement_count": state['refinement_count'] + 1
       }
   ```

**Deliverables:**
- ‚úÖ `veritas_evaluator_agent.py` - Evaluator Implementation
- ‚úÖ RAG-Triade Prompts (Few-Shot Examples)
- ‚úÖ Integration in LangGraph Workflow
- ‚úÖ Evaluation Metrics Logging
- ‚úÖ Unit Tests

---

### Phase 2: Datenquellen-Erweiterung (4-6 Wochen) üü° WICHTIG

#### Sprint 2.1: Neo4j Graph Database Agent (2 Wochen)

**Tasks:**
1. **Neo4j Setup (Docker)**
   ```yaml
   # docker-compose.yml
   services:
     neo4j:
       image: neo4j:5.13
       ports:
         - "7474:7474"  # Browser
         - "7687:7687"  # Bolt
       environment:
         NEO4J_AUTH: neo4j/veritas123
       volumes:
         - neo4j_data:/data
   ```

2. **Graph Agent Implementation**
   ```python
   # backend/agents/veritas_neo4j_agent.py
   
   from langchain.chains.graph_qa.cypher import GraphCypherQAChain
   from langchain_community.graphs import Neo4jGraph
   
   class Neo4jAgent:
       def __init__(self):
           self.graph = Neo4jGraph(
               url="bolt://localhost:7687",
               username="neo4j",
               password="veritas123"
           )
           
           self.qa_chain = GraphCypherQAChain.from_llm(
               llm=ollama_llm,
               graph=self.graph,
               verbose=True
           )
       
       async def query(self, question: str) -> Dict[str, Any]:
           """
           Beantwortet Fragen √ºber Beziehungen/Netzwerke
           
           Beispiele:
           - "Welche Abteilungen arbeiten an Projekt X?"
           - "Wer sind die Experten f√ºr Thema Y?"
           - "Welche Projekte sind mit Technologie Z verbunden?"
           """
           
           result = await self.qa_chain.arun(question)
           
           return {
               "agent": "Neo4jAgent",
               "answer": result,
               "sources": ["Neo4j Graph Database"],
               "confidence": 0.9
           }
   ```

3. **Integration in SupervisorAgent**
   ```python
   # Registriere Neo4j Agent
   self.agents['neo4j'] = Neo4jAgent()
   
   # Agent Selector erkennt Graph-Queries
   if self._is_relationship_query(query):
       selected_agents.append('neo4j')
   ```

**Deliverables:**
- ‚úÖ Neo4j Docker Setup
- ‚úÖ `veritas_neo4j_agent.py`
- ‚úÖ Sample Graph Data (Testdaten)
- ‚úÖ Integration in SupervisorAgent
- ‚úÖ Tests

---

#### Sprint 2.2: SearxNG Web Search Agent (2 Wochen)

**Tasks:**
1. **SearxNG Setup (Docker)**
   ```yaml
   # docker-compose.yml
   services:
     searxng:
       image: searxng/searxng:latest
       ports:
         - "8080:8080"
       volumes:
         - ./searxng:/etc/searxng
       environment:
         - SEARXNG_BASE_URL=http://localhost:8080
   ```

2. **Web Search Agent**
   ```python
   # backend/agents/veritas_web_search_agent.py
   
   import aiohttp
   
   class SearxNGAgent:
       def __init__(self):
           self.base_url = "http://localhost:8080"
       
       async def search(self, query: str, num_results: int = 5):
           """
           Sucht im Web √ºber SearxNG (On-Premise!)
           
           Vorteile:
           - Keine Weitergabe von Queries an Google/Bing
           - Aggregiert Ergebnisse von 100+ Suchmaschinen
           - Datenschutzkonform
           """
           
           async with aiohttp.ClientSession() as session:
               async with session.get(
                   f"{self.base_url}/search",
                   params={
                       "q": query,
                       "format": "json",
                       "engines": "google,bing,duckduckgo"
                   }
               ) as resp:
                   data = await resp.json()
           
           results = []
           for item in data.get('results', [])[:num_results]:
               results.append({
                   "title": item['title'],
                   "url": item['url'],
                   "snippet": item['content']
               })
           
           return {
               "agent": "SearxNGAgent",
               "results": results,
               "sources": [r['url'] for r in results]
           }
   ```

**Deliverables:**
- ‚úÖ SearxNG Docker Setup
- ‚úÖ `veritas_web_search_agent.py`
- ‚úÖ Privacy-Config (keine Logs)
- ‚úÖ Integration in SupervisorAgent
- ‚úÖ Tests

---

### Phase 3: Kryptographische Integrit√§t (2-4 Wochen) üü° COMPLIANCE

#### Sprint 3.1: Hash-Kette + Signaturen (2 Wochen)

**Tasks:**
1. **Hash-Kette Implementation**
   ```python
   # backend/agents/veritas_integrity_manager.py
   
   import hashlib
   import json
   from cryptography.hazmat.primitives import hashes, serialization
   from cryptography.hazmat.primitives.asymmetric import rsa, padding
   
   class IntegrityManager:
       def __init__(self):
           self.private_key = self._load_or_generate_key()
       
       def compute_state_hash(self, execution_trace: List[Dict]) -> str:
           """
           Berechnet SHA-256 Hash √ºber execution_trace
           """
           trace_json = json.dumps(execution_trace, sort_keys=True)
           hash_obj = hashlib.sha256(trace_json.encode('utf-8'))
           return hash_obj.hexdigest()
       
       def sign_state(self, state_hash: str) -> str:
           """
           Signiert Hash mit privatem Schl√ºssel
           """
           signature = self.private_key.sign(
               state_hash.encode('utf-8'),
               padding.PSS(
                   mgf=padding.MGF1(hashes.SHA256()),
                   salt_length=padding.PSS.MAX_LENGTH
               ),
               hashes.SHA256()
           )
           return signature.hex()
       
       def verify_integrity(self, state: ResearchState) -> bool:
           """
           Verifiziert Hash-Kette + Signatur
           """
           # 1. Check hash chain
           for i in range(1, len(state['execution_trace'])):
               prev_hash = self.compute_state_hash(
                   state['execution_trace'][:i]
               )
               
               if state['integrity_chain'][i-1] != prev_hash:
                   return False  # Manipulation detected!
           
           # 2. Verify signature
           current_hash = self.compute_state_hash(state['execution_trace'])
           return self._verify_signature(
               current_hash, 
               state['integrity']['stateSignature']
           )
   ```

2. **Integration in State Persister**
   ```python
   async def save_state(self, research_id, state):
       # Compute hash
       current_hash = self.integrity.compute_state_hash(
           state['execution_trace']
       )
       
       # Update integrity block
       state['integrity'] = {
           "currentStateHash": current_hash,
           "previousStateHash": state['integrity'].get('currentStateHash'),
           "stateSignature": self.integrity.sign_state(current_hash)
       }
       
       # Save
       await self.db.execute(...)
   ```

**Deliverables:**
- ‚úÖ `veritas_integrity_manager.py`
- ‚úÖ RSA Key Generation
- ‚úÖ Hash-Kette Validation
- ‚úÖ Integration in Persister
- ‚úÖ Tests

---

#### Sprint 3.2: Qualifizierte Zeitstempel (2 Wochen) - OPTIONAL

**Tasks:**
1. **TSP Client Implementation**
   ```python
   # backend/agents/veritas_timestamp_client.py
   
   import requests
   from rfc3161ng import RemoteTimestamper
   
   class QualifiedTimestampClient:
       def __init__(self):
           # eIDAS-zertifizierter TSP (Beispiel: Deutsche Telekom)
           self.tsp_url = "https://tsp.telekom.de/timestamp"
           self.timestamper = RemoteTimestamper(
               self.tsp_url,
               certificate="telekom_tsp.crt"
           )
       
       async def get_timestamp(self, data_hash: str) -> str:
           """
           Holt qualifizierten Zeitstempel (QET)
           
           Rechtliche Wirkung (eIDAS):
           - EU-weite Beweiskraft
           - Vermutung der Richtigkeit
           - Gerichtlich verwertbar
           """
           
           timestamp_token = self.timestamper(
               data=data_hash.encode('utf-8'),
               hashname='sha256'
           )
           
           return timestamp_token.hex()
   ```

2. **Integration f√ºr finale States**
   ```python
   async def finalize_research(self, research_id):
       state = await self.load_state(research_id)
       
       # Sign
       final_hash = self.integrity.compute_state_hash(
           state['execution_trace']
       )
       signature = self.integrity.sign_state(final_hash)
       
       # Timestamp
       timestamp_token = await self.tsp.get_timestamp(final_hash)
       
       state['integrity']['qualifiedTimestampToken'] = timestamp_token
       state['status'] = 'COMPLETED_AND_SEALED'
       
       await self.save_state(research_id, state)
   ```

**Deliverables:**
- ‚úÖ `veritas_timestamp_client.py`
- ‚úÖ TSP Provider Integration
- ‚úÖ Certificate Management
- ‚úÖ Tests

---

### Phase 4: Prefect Macro-Orchestrierung (4-6 Wochen) üü¢ OPTIONAL

**Nur wenn Multi-Stunden-Workflows ben√∂tigt werden!**

#### Sprint 4.1: Prefect Setup (2 Wochen)

**Tasks:**
1. **Prefect Installation**
   ```bash
   pip install prefect
   prefect server start
   ```

2. **Workflow Definition**
   ```python
   # backend/workflows/deep_research_workflow.py
   
   from prefect import flow, task
   from prefect.task_runners import ConcurrentTaskRunner
   
   @task(retries=3, retry_delay_seconds=60)
   async def execute_research_phase(research_id: str, phase: str):
       """
       Eine Phase der Recherche (mit Auto-Retry!)
       """
       response = await requests.post(
           "http://localhost:5000/api/research/execute",
           json={"research_id": research_id, "phase": phase}
       )
       return response.json()
   
   @flow(name="Deep Research", task_runner=ConcurrentTaskRunner())
   async def deep_research_flow(query: str):
       """
       Langlebiger Deep Research Workflow
       
       Vorteile:
       - L√§uft √ºber Stunden/Tage
       - Automatische Retries bei Fehlern
       - Human-in-the-Loop Checkpoints
       - Zentrale √úberwachung
       """
       
       # Phase 1: Initial Research
       research_id = await init_research(query)
       
       # Phase 2: Data Collection (parallelisiert)
       results = await execute_research_phase.map([
           (research_id, "web_search"),
           (research_id, "database_query"),
           (research_id, "graph_analysis")
       ])
       
       # Phase 3: Human Review (pausiert Workflow!)
       await human_review_checkpoint(research_id)
       
       # Phase 4: Synthesis
       final_result = await synthesize_results(research_id)
       
       return final_result
   ```

**Deliverables:**
- ‚úÖ Prefect Server Setup
- ‚úÖ `deep_research_workflow.py`
- ‚úÖ Retry-Strategien
- ‚úÖ Human-Checkpoints
- ‚úÖ Monitoring Dashboard

---

## üìã Zusammenfassung: Implementierungs-Roadmap

| Phase | Dauer | Priorit√§t | Status | Deliverables |
|-------|-------|-----------|--------|--------------|
| **Phase 1: Foundation** | 4-6 Wochen | üî¥ P0 | ‚è≥ Pending | Persistentes JSON, LangGraph, Evaluator |
| **Phase 2: Datenquellen** | 4-6 Wochen | üü° P1 | ‚è≥ Pending | Neo4j, SearxNG |
| **Phase 3: Integrit√§t** | 2-4 Wochen | üü° P2 | ‚è≥ Pending | Hash-Kette, Signaturen, Zeitstempel |
| **Phase 4: Prefect** | 4-6 Wochen | üü¢ P3 | ‚è≥ Optional | Macro-Orchestrierung |

**Gesamt-Zeitrahmen:**
- **Minimum (Phase 1+2):** 8-12 Wochen (2-3 Monate)
- **Empfohlen (Phase 1+2+3):** 10-16 Wochen (2.5-4 Monate)
- **Komplett (alle Phasen):** 14-22 Wochen (3.5-5.5 Monate)

---

## üéØ Erfolgs-Kriterien

### MVP (Minimum Viable Product)

Nach **Phase 1** (4-6 Wochen):

‚úÖ **Funktional:**
- Persistente Recherchen (wiederaufsetzbar)
- LangGraph StateGraph (zustandsbehaftet)
- Evaluator-Agent (Qualit√§tssicherung)
- Reflexions-Schleife (iterative Verbesserung)

‚úÖ **Technisch:**
- PostgreSQL State Persistence
- LangGraph Checkpointer
- RAG-Triade Evaluation
- Execution Trace Logging

‚úÖ **Messbar:**
- Erfolgsrate: 80%+ (mit Reflexion vs. 60% ohne)
- Durchschnittliche Refinements: 1-2 pro Recherche
- Crash-Wiederaufsetzbarkeit: 100%

### Production-Ready

Nach **Phase 1+2+3** (10-16 Wochen):

‚úÖ **Enterprise-Grade:**
- Neo4j Graph Queries
- SearxNG Web Search (privacy-compliant)
- Kryptographische Integrit√§t
- Audit-Trail (rechtssicher)

‚úÖ **Compliance:**
- DSGVO-konform
- Nachvollziehbar
- Manipulationssicher
- Optional: eIDAS-QET

---

**Ende des Implementierungskonzepts**
