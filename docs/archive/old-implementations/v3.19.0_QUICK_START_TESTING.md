# v3.19.0 Quick Start Testing Guide

**Version:** 3.19.0  
**Ziel:** Manuelle Validierung der IEEE-Zitationen + Klickbare Vorschläge  
**Dauer:** ~15 Minuten  

---

## 🚀 Setup

### 1. Backend starten
```powershell
cd c:\VCC\veritas
python backend.py
```

**Erwartung:**
```
✅ RAG-Backend gestartet
✅ Ollama-Connection established
✅ ChromaDB connected
```

### 2. Frontend starten (neues Terminal)
```powershell
cd c:\VCC\veritas
python start_frontend.py
```

**Erwartung:**
```
✅ UI-Module initialisiert (Markdown, SourceLinks, ChatFormatter, DialogManager)
✅ Chat-Fenster öffnet sich
```

---

## ✅ Test-Checkliste

### Test 1: IEEE-Zitationen (5 Min)

#### Schritt 1.1: Query senden
**Input:**
```
Welche Bauvorschriften gelten in Baden-Württemberg?
```

**Erwartung:**
- Antwort erscheint mit `[1]`, `[2]`, `[3]` als **hochgestellte, blaue Zahlen**
- Beispiel: "Nach § 58 LBO BW[¹] ist eine Baugenehmigung erforderlich[²]."

**✅ Pass wenn:**
- [ ] Zitationen hochgestellt (Superscript)
- [ ] Zitationen blau + unterstrichen
- [ ] Mindestens 2 Zitationen vorhanden

#### Schritt 1.2: Quellen-Section prüfen
**Aktion:** Klicke auf "📚 Quellen (N)" um zu expandieren

**Erwartung:**
```
⚖️ [1] "Landesbauordnung Baden-Württemberg", Gesetz, 2023, [Online]. Verfügbar: LBO_BW_2023.pdf (Confidence: XX%)
📜 [2] "Verwaltungsvorschrift LBO", Verordnung, 2023, [Online]. Verfügbar: ...
```

**✅ Pass wenn:**
- [ ] IEEE-Format: `[N] "Title", Type, Year, [Online]. Verfügbar: ...`
- [ ] Icons korrekt (⚖️ Gesetz, 📜 Verordnung, 🔨 Urteil)
- [ ] Confidence-Score angezeigt

#### Schritt 1.3: Citation-Click testen
**Aktion:** Klicke auf `[1]` in der Antwort

**Erwartung:**
- Scrollt automatisch zur Quelle `[1]` in Quellen-Section
- Quelle wird **2 Sekunden gelb** hervorgehoben (#FFFFCC)
- Highlight verschwindet nach 2s

**✅ Pass wenn:**
- [ ] Scrolling funktioniert
- [ ] Gelbes Highlight erscheint
- [ ] Highlight verschwindet nach 2s

#### Schritt 1.4: Hover-Tooltip testen
**Aktion:** Bewege Maus über Quelle `[1]` (ohne zu klicken)

**Erwartung:**
```
📖 Landesbauordnung Baden-Württemberg
🎯 Confidence: 87%

💬 Vorschau:
§ 58 regelt die Baugenehmigungspflicht für Bauvorhaben...
```

**✅ Pass wenn:**
- [ ] Tooltip erscheint
- [ ] Enthält Title + Confidence + Preview
- [ ] Verschwindet bei Mouse-Leave

---

### Test 2: Klickbare Vorschläge (5 Min)

#### Schritt 2.1: Vorschläge-Section prüfen
**Aktion:** Klicke auf "💡 Weitere Schritte (N)" um zu expandieren

**Erwartung:**
```
🔗 1. Welche Kosten fallen für eine Baugenehmigung in Baden-Württemberg an?
🔗 2. Welche Fristen muss ich bei der Baugenehmigung beachten?
🔗 3. Kann ich eine vereinfachte Baugenehmigung beantragen?
🔗 4. Welche Unterlagen benötige ich für den Bauantrag?
🔗 5. Gibt es Ausnahmen von der Baugenehmigungspflicht?
```

**✅ Pass wenn:**
- [ ] 3-5 Vorschläge angezeigt
- [ ] 🔗 Icon vor jedem Vorschlag
- [ ] Text ist blau

#### Schritt 2.2: Hover-Effect testen
**Aktion:** Bewege Maus über Vorschlag (ohne zu klicken)

**Erwartung:**
- Text wird **unterstrichen**
- Hintergrund wird **hellblau** (#E8F4F8)
- Cursor ändert sich zu **Hand**

**✅ Pass wenn:**
- [ ] Underline erscheint
- [ ] Hellblauer Hintergrund erscheint
- [ ] Hand-Cursor erscheint
- [ ] Alle Effects verschwinden bei Mouse-Leave

#### Schritt 2.3: Suggestion-Click testen
**Aktion:** Klicke auf Vorschlag "Welche Kosten fallen..."

**Erwartung:**
1. Query-Input wird **automatisch gefüllt** mit "Welche Kosten fallen..."
2. Nach kurzer Verzögerung (~100ms): Query wird **automatisch gesendet**
3. Neue Antwort erscheint im Chat

**✅ Pass wenn:**
- [ ] Query-Input korrekt gefüllt
- [ ] Auto-Send funktioniert (keine manuelle Enter-Taste nötig)
- [ ] Neue Antwort erscheint
- [ ] Neue Antwort hat ebenfalls Zitationen + Vorschläge

---

### Test 3: End-to-End Workflow (5 Min)

#### Schritt 3.1: Kompletter Zyklus
**Szenario:**
```
1. Query: "Welche Bauvorschriften gelten in Baden-Württemberg?"
   → Antwort mit [1], [2], [3] + 5 Vorschläge

2. Click auf [2] in Antwort
   → Scrollt zu Quelle [2], gelbes Highlight 2s

3. Click auf Vorschlag "Welche Fristen...?"
   → Query-Input gefüllt, Auto-Send

4. Neue Antwort erscheint
   → Wieder mit [1], [2], [3] + Vorschläge

5. Click auf [1] in neuer Antwort
   → Scrollt zu Quelle [1] der NEUEN Antwort (nicht alte!)
```

**✅ Pass wenn:**
- [ ] Kompletter Zyklus funktioniert
- [ ] Keine Fehler in Console
- [ ] UI bleibt responsiv
- [ ] Citation-Scrolling funktioniert für beide Antworten getrennt

---

## 🐛 Troubleshooting

### Problem 1: Keine Zitationen in Antwort
**Mögliche Ursachen:**
- LLM ignoriert Prompt-Instruktionen
- Zu niedrige Temperature (zu deterministisch)

**Lösung:**
```python
# In backend/api/veritas_api_module.py
# Prüfe Logging:
[PROMPT] Source-List:
[1] Title (file)
[2] Title (file)

# Falls Source-List leer → Keine Chunks retrieved
```

### Problem 2: Citation-Click scrollt nicht
**Mögliche Ursachen:**
- Tag `source_entry_1` nicht gesetzt
- Quellen-Section noch nicht gerendert

**Lösung:**
```python
# Prüfe Console-Logging:
[CITATION-SCROLL] Scrolled to source [1]

# Oder Warnung:
[CITATION-SCROLL] Quelle [1] nicht gefunden (Tag: source_entry_1)
```

### Problem 3: Suggestion-Click sendet nicht
**Mögliche Ursachen:**
- `suggestion_click_callback` nicht gesetzt
- `send_query()` Methode nicht verfügbar

**Lösung:**
```python
# Prüfe Console-Logging:
[SUGGESTION-CLICK] User clicked suggestion: Welche Kosten...
[SUGGESTION] Query-Input gefüllt: Welche Kosten...
[SUGGESTION] Query erfolgreich gesendet

# Oder Warnung:
[SUGGESTION] suggestion_click_callback nicht gesetzt - Links nicht funktional!
```

### Problem 4: Keine Vorschläge generiert
**Mögliche Ursachen:**
- LLM generiert nicht im erwarteten Format
- Regex-Pattern matcht nicht

**Lösung:**
```python
# Backend-Response loggen:
# In veritas_api_module.py nach LLM-Call:
logging.info(f"[LLM-RAW] {answer}")

# Prüfe ob "💡 Vorschläge:" oder "Vorschläge:" enthalten ist
# Falls nein: LLM-Prompt verstärken
```

---

## 📊 Erfolgs-Metriken

Nach Testing ausfüllen:

| Test | Status | Bemerkungen |
|------|--------|-------------|
| IEEE-Zitationen vorhanden | ☐ Pass ☐ Fail | |
| Quellen im IEEE-Format | ☐ Pass ☐ Fail | |
| Citation-Click → Scroll | ☐ Pass ☐ Fail | |
| Citation Highlight 2s | ☐ Pass ☐ Fail | |
| Source-Tooltip erscheint | ☐ Pass ☐ Fail | |
| 3-5 Vorschläge generiert | ☐ Pass ☐ Fail | |
| Suggestion Hover-Effects | ☐ Pass ☐ Fail | |
| Suggestion-Click → Send | ☐ Pass ☐ Fail | |
| End-to-End Workflow | ☐ Pass ☐ Fail | |

**Gesamtstatus:** ☐ Pass ☐ Fail

---

## 📝 Notizen

Platz für Beobachtungen während Testing:

```
[Hier Notizen einfügen]

Beispiel:
- LLM generiert manchmal nur [1], [2] statt [1], [2], [3]
- Suggestion-Hover-Background könnte dunkler sein
- Scroll-Animation könnte langsamer sein (aktuell sehr schnell)
```

---

## ✅ Abschluss

Nach erfolgreichem Testing:

1. **Test-Protokoll** ausfüllen (`docs/v3.19.0_TESTING_VALIDATION_PLAN.md`)
2. **Issues** dokumentieren (falls gefunden)
3. **Erfolgs-Metriken** in Tabelle oben eintragen
4. **Status** auf "✅ Tested" setzen

---

**Happy Testing! 🚀**
