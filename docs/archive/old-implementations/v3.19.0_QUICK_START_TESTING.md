# v3.19.0 Quick Start Testing Guide

**Version:** 3.19.0  
**Ziel:** Manuelle Validierung der IEEE-Zitationen + Klickbare VorschlÃ¤ge  
**Dauer:** ~15 Minuten  

---

## ğŸš€ Setup

### 1. Backend starten
```powershell
cd c:\VCC\veritas
python backend.py
```

**Erwartung:**
```
âœ… RAG-Backend gestartet
âœ… Ollama-Connection established
âœ… ChromaDB connected
```

### 2. Frontend starten (neues Terminal)
```powershell
cd c:\VCC\veritas
python start_frontend.py
```

**Erwartung:**
```
âœ… UI-Module initialisiert (Markdown, SourceLinks, ChatFormatter, DialogManager)
âœ… Chat-Fenster Ã¶ffnet sich
```

---

## âœ… Test-Checkliste

### Test 1: IEEE-Zitationen (5 Min)

#### Schritt 1.1: Query senden
**Input:**
```
Welche Bauvorschriften gelten in Baden-WÃ¼rttemberg?
```

**Erwartung:**
- Antwort erscheint mit `[1]`, `[2]`, `[3]` als **hochgestellte, blaue Zahlen**
- Beispiel: "Nach Â§ 58 LBO BW[Â¹] ist eine Baugenehmigung erforderlich[Â²]."

**âœ… Pass wenn:**
- [ ] Zitationen hochgestellt (Superscript)
- [ ] Zitationen blau + unterstrichen
- [ ] Mindestens 2 Zitationen vorhanden

#### Schritt 1.2: Quellen-Section prÃ¼fen
**Aktion:** Klicke auf "ğŸ“š Quellen (N)" um zu expandieren

**Erwartung:**
```
âš–ï¸ [1] "Landesbauordnung Baden-WÃ¼rttemberg", Gesetz, 2023, [Online]. VerfÃ¼gbar: LBO_BW_2023.pdf (Confidence: XX%)
ğŸ“œ [2] "Verwaltungsvorschrift LBO", Verordnung, 2023, [Online]. VerfÃ¼gbar: ...
```

**âœ… Pass wenn:**
- [ ] IEEE-Format: `[N] "Title", Type, Year, [Online]. VerfÃ¼gbar: ...`
- [ ] Icons korrekt (âš–ï¸ Gesetz, ğŸ“œ Verordnung, ğŸ”¨ Urteil)
- [ ] Confidence-Score angezeigt

#### Schritt 1.3: Citation-Click testen
**Aktion:** Klicke auf `[1]` in der Antwort

**Erwartung:**
- Scrollt automatisch zur Quelle `[1]` in Quellen-Section
- Quelle wird **2 Sekunden gelb** hervorgehoben (#FFFFCC)
- Highlight verschwindet nach 2s

**âœ… Pass wenn:**
- [ ] Scrolling funktioniert
- [ ] Gelbes Highlight erscheint
- [ ] Highlight verschwindet nach 2s

#### Schritt 1.4: Hover-Tooltip testen
**Aktion:** Bewege Maus Ã¼ber Quelle `[1]` (ohne zu klicken)

**Erwartung:**
```
ğŸ“– Landesbauordnung Baden-WÃ¼rttemberg
ğŸ¯ Confidence: 87%

ğŸ’¬ Vorschau:
Â§ 58 regelt die Baugenehmigungspflicht fÃ¼r Bauvorhaben...
```

**âœ… Pass wenn:**
- [ ] Tooltip erscheint
- [ ] EnthÃ¤lt Title + Confidence + Preview
- [ ] Verschwindet bei Mouse-Leave

---

### Test 2: Klickbare VorschlÃ¤ge (5 Min)

#### Schritt 2.1: VorschlÃ¤ge-Section prÃ¼fen
**Aktion:** Klicke auf "ğŸ’¡ Weitere Schritte (N)" um zu expandieren

**Erwartung:**
```
ğŸ”— 1. Welche Kosten fallen fÃ¼r eine Baugenehmigung in Baden-WÃ¼rttemberg an?
ğŸ”— 2. Welche Fristen muss ich bei der Baugenehmigung beachten?
ğŸ”— 3. Kann ich eine vereinfachte Baugenehmigung beantragen?
ğŸ”— 4. Welche Unterlagen benÃ¶tige ich fÃ¼r den Bauantrag?
ğŸ”— 5. Gibt es Ausnahmen von der Baugenehmigungspflicht?
```

**âœ… Pass wenn:**
- [ ] 3-5 VorschlÃ¤ge angezeigt
- [ ] ğŸ”— Icon vor jedem Vorschlag
- [ ] Text ist blau

#### Schritt 2.2: Hover-Effect testen
**Aktion:** Bewege Maus Ã¼ber Vorschlag (ohne zu klicken)

**Erwartung:**
- Text wird **unterstrichen**
- Hintergrund wird **hellblau** (#E8F4F8)
- Cursor Ã¤ndert sich zu **Hand**

**âœ… Pass wenn:**
- [ ] Underline erscheint
- [ ] Hellblauer Hintergrund erscheint
- [ ] Hand-Cursor erscheint
- [ ] Alle Effects verschwinden bei Mouse-Leave

#### Schritt 2.3: Suggestion-Click testen
**Aktion:** Klicke auf Vorschlag "Welche Kosten fallen..."

**Erwartung:**
1. Query-Input wird **automatisch gefÃ¼llt** mit "Welche Kosten fallen..."
2. Nach kurzer VerzÃ¶gerung (~100ms): Query wird **automatisch gesendet**
3. Neue Antwort erscheint im Chat

**âœ… Pass wenn:**
- [ ] Query-Input korrekt gefÃ¼llt
- [ ] Auto-Send funktioniert (keine manuelle Enter-Taste nÃ¶tig)
- [ ] Neue Antwort erscheint
- [ ] Neue Antwort hat ebenfalls Zitationen + VorschlÃ¤ge

---

### Test 3: End-to-End Workflow (5 Min)

#### Schritt 3.1: Kompletter Zyklus
**Szenario:**
```
1. Query: "Welche Bauvorschriften gelten in Baden-WÃ¼rttemberg?"
   â†’ Antwort mit [1], [2], [3] + 5 VorschlÃ¤ge

2. Click auf [2] in Antwort
   â†’ Scrollt zu Quelle [2], gelbes Highlight 2s

3. Click auf Vorschlag "Welche Fristen...?"
   â†’ Query-Input gefÃ¼llt, Auto-Send

4. Neue Antwort erscheint
   â†’ Wieder mit [1], [2], [3] + VorschlÃ¤ge

5. Click auf [1] in neuer Antwort
   â†’ Scrollt zu Quelle [1] der NEUEN Antwort (nicht alte!)
```

**âœ… Pass wenn:**
- [ ] Kompletter Zyklus funktioniert
- [ ] Keine Fehler in Console
- [ ] UI bleibt responsiv
- [ ] Citation-Scrolling funktioniert fÃ¼r beide Antworten getrennt

---

## ğŸ› Troubleshooting

### Problem 1: Keine Zitationen in Antwort
**MÃ¶gliche Ursachen:**
- LLM ignoriert Prompt-Instruktionen
- Zu niedrige Temperature (zu deterministisch)

**LÃ¶sung:**
```python
# In backend/api/veritas_api_module.py
# PrÃ¼fe Logging:
[PROMPT] Source-List:
[1] Title (file)
[2] Title (file)

# Falls Source-List leer â†’ Keine Chunks retrieved
```

### Problem 2: Citation-Click scrollt nicht
**MÃ¶gliche Ursachen:**
- Tag `source_entry_1` nicht gesetzt
- Quellen-Section noch nicht gerendert

**LÃ¶sung:**
```python
# PrÃ¼fe Console-Logging:
[CITATION-SCROLL] Scrolled to source [1]

# Oder Warnung:
[CITATION-SCROLL] Quelle [1] nicht gefunden (Tag: source_entry_1)
```

### Problem 3: Suggestion-Click sendet nicht
**MÃ¶gliche Ursachen:**
- `suggestion_click_callback` nicht gesetzt
- `send_query()` Methode nicht verfÃ¼gbar

**LÃ¶sung:**
```python
# PrÃ¼fe Console-Logging:
[SUGGESTION-CLICK] User clicked suggestion: Welche Kosten...
[SUGGESTION] Query-Input gefÃ¼llt: Welche Kosten...
[SUGGESTION] Query erfolgreich gesendet

# Oder Warnung:
[SUGGESTION] suggestion_click_callback nicht gesetzt - Links nicht funktional!
```

### Problem 4: Keine VorschlÃ¤ge generiert
**MÃ¶gliche Ursachen:**
- LLM generiert nicht im erwarteten Format
- Regex-Pattern matcht nicht

**LÃ¶sung:**
```python
# Backend-Response loggen:
# In veritas_api_module.py nach LLM-Call:
logging.info(f"[LLM-RAW] {answer}")

# PrÃ¼fe ob "ğŸ’¡ VorschlÃ¤ge:" oder "VorschlÃ¤ge:" enthalten ist
# Falls nein: LLM-Prompt verstÃ¤rken
```

---

## ğŸ“Š Erfolgs-Metriken

Nach Testing ausfÃ¼llen:

| Test | Status | Bemerkungen |
|------|--------|-------------|
| IEEE-Zitationen vorhanden | â˜ Pass â˜ Fail | |
| Quellen im IEEE-Format | â˜ Pass â˜ Fail | |
| Citation-Click â†’ Scroll | â˜ Pass â˜ Fail | |
| Citation Highlight 2s | â˜ Pass â˜ Fail | |
| Source-Tooltip erscheint | â˜ Pass â˜ Fail | |
| 3-5 VorschlÃ¤ge generiert | â˜ Pass â˜ Fail | |
| Suggestion Hover-Effects | â˜ Pass â˜ Fail | |
| Suggestion-Click â†’ Send | â˜ Pass â˜ Fail | |
| End-to-End Workflow | â˜ Pass â˜ Fail | |

**Gesamtstatus:** â˜ Pass â˜ Fail

---

## ğŸ“ Notizen

Platz fÃ¼r Beobachtungen wÃ¤hrend Testing:

```
[Hier Notizen einfÃ¼gen]

Beispiel:
- LLM generiert manchmal nur [1], [2] statt [1], [2], [3]
- Suggestion-Hover-Background kÃ¶nnte dunkler sein
- Scroll-Animation kÃ¶nnte langsamer sein (aktuell sehr schnell)
```

---

## âœ… Abschluss

Nach erfolgreichem Testing:

1. **Test-Protokoll** ausfÃ¼llen (`docs/v3.19.0_TESTING_VALIDATION_PLAN.md`)
2. **Issues** dokumentieren (falls gefunden)
3. **Erfolgs-Metriken** in Tabelle oben eintragen
4. **Status** auf "âœ… Tested" setzen

---

**Happy Testing! ğŸš€**
