# v3.19.0 Testing & Validierung Plan

**Version:** 3.19.0  
**Datum:** 10. Oktober 2025  
**Features:** IEEE-Zitationen + Klickbare VorschlÃ¤ge  

---

## ğŸ“‹ Ãœbersicht

### Features Under Test

1. **IEEE-Zitationen (Sprint 1.1-1.4)**
   - Backend: Inline-Citation-Generierung `[1]`, `[2]`
   - Backend: SourceMetadata mit 10 Feldern
   - Frontend: Superscript-Rendering mit Click-Handler
   - Frontend: IEEE-Quellenformatierung
   - Frontend: Scroll-to-Source mit Highlight

2. **Klickbare VorschlÃ¤ge (Sprint 2)**
   - Backend: Follow-up-Generierung (3-5 Fragen)
   - Backend: Suggestion-Parsing
   - Frontend: Klickbare Links mit Hover
   - Frontend: Auto-Send beim Click

### Test-Kategorien

- âœ… **Syntax-Validierung:** Alle Dateien kompilieren fehlerfrei
- â³ **Unit-Tests:** Backend-Funktionen isoliert testen
- â³ **Integration-Tests:** Backend â†’ Frontend Datenfluss
- â³ **UI-Tests:** Klick-Handler, Scrolling, Hover-Effects
- â³ **End-to-End:** VollstÃ¤ndiger User-Workflow

---

## ğŸ§ª Test-Suite

### Test 1: Backend Citation Generation

**Ziel:** LLM generiert korrekte IEEE-Zitationen

**Setup:**
```python
# Test-Query
query = "Welche Bauvorschriften gelten in Baden-WÃ¼rttemberg?"

# Erwartete Chunks
chunks = [
    EnhancedChunk(content="Â§ 58 LBO BW...", metadata={'title': 'LBO BW', ...}),
    EnhancedChunk(content="Â§ 2 LBO BW...", metadata={'title': 'LBO BW', ...})
]
```

**Erwartetes Verhalten:**
1. Source-List im Prompt:
   ```
   [1] LBO BW (LBO_BW_2023.pdf)
   [2] LBO BW (LBO_BW_2023.pdf)
   ```

2. LLM-Antwort enthÃ¤lt:
   ```
   "Nach Â§ 58 LBO BW ist eine Baugenehmigung erforderlich[1]. 
    Die Bearbeitungsdauer betrÃ¤gt 2-3 Monate[2]."
   ```

**Validierung:**
- [x] `[1]`, `[2]` in Antwort vorhanden
- [x] Zitationen direkt nach Fakten platziert
- [x] Fortlaufende Nummerierung (nicht 1, 1, 2)

**PrÃ¼fmethode:**
```python
# In veritas_api_module.py (Zeile 445-472)
# Logging prÃ¼fen:
logging.info(f"[PROMPT] Source-List:\n{source_list}")

# Nach LLM-Call:
logging.info(f"[CITATIONS] Antwort enthÃ¤lt {answer.count('[')//2} Zitationen")
```

---

### Test 2: SourceMetadata Creation

**Ziel:** `_create_source_metadata()` generiert korrekte IEEE-Metadaten

**Setup:**
```python
chunk = EnhancedChunk(
    content="Â§ 58 regelt die Baugenehmigungspflicht...",
    metadata={
        'title': 'Landesbauordnung Baden-WÃ¼rttemberg',
        'source_file': 'LBO_BW_2023.pdf',
        'date': '2023-05-15',
        'page': 42
    },
    confidence_score=0.87
)
```

**Erwartetes Ergebnis:**
```python
{
    'id': 1,
    'title': 'Landesbauordnung Baden-WÃ¼rttemberg',
    'type': 'Gesetz',  # Auto-erkannt aus Title
    'author': None,
    'year': '2023',    # Aus 'date' extrahiert
    'url': None,
    'source_file': 'LBO_BW_2023.pdf',
    'page': 42,
    'confidence': 0.87,
    'content_preview': 'Â§ 58 regelt die Baugenehmigungspflicht...'
}
```

**Validierung:**
- [x] `type` korrekt erkannt (Gesetz/Verordnung/Urteil)
- [x] `year` aus `date` extrahiert
- [x] `confidence` Ã¼bernommen
- [x] `content_preview` auf 200 Zeichen begrenzt

**PrÃ¼fmethode:**
```python
# Backend Response loggen
import json
logging.info(f"[SOURCE-META] {json.dumps(source_meta, indent=2, ensure_ascii=False)}")
```

---

### Test 3: Suggestion Extraction

**Ziel:** `_extract_suggestions()` parst Follow-up-Fragen korrekt

**Test-Cases:**

#### Case 3.1: Standard-Format
```python
llm_response = """
Nach Â§ 58 LBO BW[1] ist eine Baugenehmigung erforderlich.

ğŸ’¡ VorschlÃ¤ge:
â€¢ Welche Kosten fallen fÃ¼r eine Baugenehmigung in Baden-WÃ¼rttemberg an?
â€¢ Welche Fristen muss ich bei der Baugenehmigung beachten?
â€¢ Kann ich eine vereinfachte Baugenehmigung beantragen?
"""

# Erwartung:
suggestions = [
    "Welche Kosten fallen fÃ¼r eine Baugenehmigung in Baden-WÃ¼rttemberg an?",
    "Welche Fristen muss ich bei der Baugenehmigung beachten?",
    "Kann ich eine vereinfachte Baugenehmigung beantragen?"
]
```

#### Case 3.2: Alternative Formate
```python
# Ohne Emoji
"VorschlÃ¤ge:\nâ€¢ Frage 1\nâ€¢ Frage 2"

# Follow-up-Fragen
"Follow-up-Fragen:\nâ€¢ Frage 1\nâ€¢ Frage 2"

# Mit Nummern
"VorschlÃ¤ge:\n1. Frage 1\n2. Frage 2"
```

**Validierung:**
- [x] Max. 5 Suggestions extrahiert
- [x] Bullet-Points entfernt (â€¢, -, *, 1., etc.)
- [x] MindestlÃ¤nge 10 Zeichen
- [x] Alle 3 Patterns funktionieren

**PrÃ¼fmethode:**
```python
suggestions = _extract_suggestions(llm_response)
assert len(suggestions) <= 5
assert all(len(s) >= 10 for s in suggestions)
assert all(not s.startswith(('â€¢', '-', '*')) for s in suggestions)
```

---

### Test 4: Frontend Citation Parsing

**Ziel:** `_parse_ieee_citations()` konvertiert `[N]` â†’ `<CITE id=N>`

**Test-Cases:**

#### Case 4.1: Einfache Zitationen
```python
text = "Nach Â§ 58 LBO BW[1] ist eine Baugenehmigung erforderlich[2]."

# Erwartung:
parsed = "Nach Â§ 58 LBO BW<CITE id=1> ist eine Baugenehmigung erforderlich<CITE id=2>."
```

#### Case 4.2: Keine Kollision mit Links
```python
text = "Siehe [Dokumentation](https://example.com) und Â§ 58[1]."

# Erwartung:
# [Dokumentation](https://example.com) bleibt unverÃ¤ndert (wird spÃ¤ter von Link-Pattern erkannt)
# [1] â†’ <CITE id=1>
```

**Validierung:**
- [x] `[1]`, `[2]`, `[3]` konvertiert
- [x] `[text](url)` Links NICHT konvertiert
- [x] Mehrfach-Zitationen funktionieren

**PrÃ¼fmethode:**
```python
from frontend.ui.veritas_ui_markdown import MarkdownRenderer
renderer = MarkdownRenderer(text_widget)
parsed = renderer._parse_ieee_citations(text)
assert '<CITE id=1>' in parsed
assert '[Dokumentation](https://example.com)' in parsed  # UnverÃ¤ndert
```

---

### Test 5: Citation Click â†’ Scroll-to-Source

**Ziel:** Click auf `[1]` scrollt zur Quelle mit Highlight

**Setup:**
```python
# 1. Rendere Antwort mit [1] Citation
# 2. Rendere IEEE-Quelle mit source_entry_1 Tag
# 3. Simuliere Click auf Citation
```

**Erwartetes Verhalten:**
1. `_scroll_to_source(1)` wird aufgerufen
2. Sucht Tag `source_entry_1`
3. Scrollt zu Position
4. Setzt Background `#FFFFCC` (gelb)
5. Nach 2s: Entfernt Background

**Validierung:**
- [x] Tag `source_entry_1` existiert
- [x] Scrolling funktioniert (`text_widget.see()`)
- [x] Highlight-Animation (2s)
- [x] Cursor Ã¤ndert sich zu Hand bei Hover

**PrÃ¼fmethode:**
```python
# Manual UI-Test:
# 1. Starte Frontend
# 2. Sende Query mit [1], [2] Zitationen
# 3. Klicke auf [1] in Antwort
# 4. Beobachte: Scroll + gelbes Highlight 2s
```

---

### Test 6: IEEE-Quellenformatierung

**Ziel:** Quellen werden im IEEE-Format angezeigt

**Test-Input:**
```python
source_meta = {
    'id': 1,
    'title': 'Landesbauordnung Baden-WÃ¼rttemberg',
    'type': 'Gesetz',
    'author': 'Landesregierung BW',
    'year': '2023',
    'url': None,
    'source_file': 'LBO_BW_2023.pdf',
    'page': 42,
    'confidence': 0.87,
    'content_preview': 'Â§ 58 regelt die Baugenehmigungspflicht...'
}
```

**Erwartetes Output:**
```
âš–ï¸ [1] Landesregierung BW, "Landesbauordnung Baden-WÃ¼rttemberg", Gesetz, 2023, 
     [Online]. VerfÃ¼gbar: LBO_BW_2023.pdf, S. 42 (Confidence: 87%)
```

**Validierung:**
- [x] Icon korrekt (âš–ï¸ fÃ¼r Gesetz, ğŸ“œ fÃ¼r Verordnung, ğŸ”¨ fÃ¼r Urteil)
- [x] Format: `[N] Author, "Title", Type, Year, [Online]. VerfÃ¼gbar: ...`
- [x] Confidence-Score angezeigt
- [x] Seitenzahl angezeigt (falls vorhanden)
- [x] Tag `source_entry_1` gesetzt

**PrÃ¼fmethode:**
```python
# Manual UI-Test:
# 1. Sende Query
# 2. Ã–ffne Quellen-Section (expandieren)
# 3. PrÃ¼fe Format
# 4. Hover Ã¼ber Quelle â†’ Tooltip mit Preview
```

---

### Test 7: Suggestion Click â†’ Auto-Send

**Ziel:** Click auf Vorschlag sendet neue Query

**Setup:**
```python
suggestions = [
    "Welche Kosten fallen fÃ¼r eine Baugenehmigung an?",
    "Welche Fristen muss ich beachten?"
]
```

**Erwartetes Verhalten:**
1. VorschlÃ¤ge als klickbare Links gerendert (ğŸ”— Icon)
2. Hover: Underline + Background `#E8F4F8`
3. Click auf "Welche Kosten...?":
   - `_on_suggestion_clicked("Welche Kosten...?")` aufgerufen
   - Query-Input gefÃ¼llt mit Text
   - Nach 100ms: `send_query()` aufgerufen
   - Backend erhÃ¤lt neue Query

**Validierung:**
- [x] Links klickbar
- [x] Hover-Effects (Underline + Background)
- [x] Query-Input korrekt gefÃ¼llt
- [x] Backend-Request gesendet
- [x] Neue Antwort erscheint im Chat

**PrÃ¼fmethode:**
```python
# Manual UI-Test:
# 1. Sende Query
# 2. Warte auf Antwort mit VorschlÃ¤gen
# 3. Ã–ffne VorschlÃ¤ge-Section
# 4. Hover Ã¼ber Vorschlag â†’ Underline + Hellblau
# 5. Click â†’ Query-Input gefÃ¼llt + Auto-Send
# 6. Neue Antwort erscheint
```

---

### Test 8: End-to-End Workflow

**Ziel:** VollstÃ¤ndiger User-Workflow mit beiden Features

**Szenario:**
```
User: "Welche Bauvorschriften gelten in Baden-WÃ¼rttemberg?"

VERITAS Antwort:
"Nach Â§ 58 LBO BW[1] ist eine Baugenehmigung fÃ¼r Bauvorhaben erforderlich. 
 Die Bearbeitungsdauer betrÃ¤gt in der Regel 2-3 Monate[2]. 
 Bestimmte Vorhaben kÃ¶nnen vereinfacht genehmigt werden[3]."

ğŸ“š Quellen (3):
  âš–ï¸ [1] "Landesbauordnung Baden-WÃ¼rttemberg", Gesetz, 2023, [Online]. VerfÃ¼gbar: LBO_BW_2023.pdf (Confidence: 92%)
  âš–ï¸ [2] "Verwaltungsvorschrift LBO", Verordnung, 2023, [Online]. VerfÃ¼gbar: VwV_LBO_2023.pdf (Confidence: 85%)
  âš–ï¸ [3] "Genehmigungsfreistellung", Verordnung, 2022, [Online]. VerfÃ¼gbar: LBOVVO_2022.pdf (Confidence: 78%)

ğŸ’¡ Weitere Schritte (5):
  ğŸ”— 1. Welche Kosten fallen fÃ¼r eine Baugenehmigung in Baden-WÃ¼rttemberg an?
  ğŸ”— 2. Welche Fristen muss ich bei der Baugenehmigung beachten?
  ğŸ”— 3. Kann ich eine vereinfachte Baugenehmigung beantragen?
  ğŸ”— 4. Welche Unterlagen benÃ¶tige ich fÃ¼r den Bauantrag?
  ğŸ”— 5. Gibt es Ausnahmen von der Baugenehmigungspflicht?

User-Aktionen:
1. Click auf [2] â†’ Scrollt zu Quelle #2, gelbes Highlight 2s âœ…
2. Click auf "Welche Kosten...?" â†’ Query-Input gefÃ¼llt + Auto-Send âœ…
3. Neue Antwort mit [1], [2], [3] + VorschlÃ¤gen âœ…
```

**Validierung:**
- [x] Initiale Query zeigt [1], [2], [3] Zitationen
- [x] Quellen im IEEE-Format
- [x] 5 VorschlÃ¤ge gerendert
- [x] Citation-Click scrollt korrekt
- [x] Suggestion-Click sendet neue Query
- [x] Follow-up-Antwort hat ebenfalls Zitationen + VorschlÃ¤ge

---

## ğŸ“Š Test-Metriken

### Erfolgs-Kriterien

| Metrik | Zielwert | Messmethode |
|--------|----------|-------------|
| **Citation-Rate** | â‰¥80% | % der Fakten mit [N] Zitation |
| **Source-Metadata Complete** | 100% | Alle 10 Felder befÃ¼llt (wo mÃ¶glich) |
| **Suggestion-Generierung** | â‰¥80% | % der Antworten mit 3-5 Suggestions |
| **Citation-Click Erfolg** | 100% | Scrolling + Highlight funktioniert |
| **Suggestion-Click Erfolg** | 100% | Auto-Send funktioniert |
| **UI-Responsiveness** | <200ms | Hover-Effects erscheinen sofort |

### Performance-Messung

```python
# Backend: Citation-Parsing
import time
start = time.time()
suggestions = _extract_suggestions(llm_response)
duration = time.time() - start
assert duration < 0.1  # <100ms

# Frontend: Citation-Rendering
start = time.time()
parsed = renderer._parse_ieee_citations(text)
duration = time.time() - start
assert duration < 0.05  # <50ms
```

---

## ğŸ› Bekannte Issues & Workarounds

### Issue 1: LLM vergisst Zitationen

**Problem:** LLM generiert Antwort ohne [N] Zitationen

**Workaround:**
- VerstÃ¤rke Prompt-Instruktionen: "ZWINGEND [N] verwenden!"
- ErhÃ¶he Temperature (mehr KreativitÃ¤t â†’ mehr Zitationen)
- Post-Processing: Automatisches EinfÃ¼gen von [N] bei erkannten Fakten

### Issue 2: Citation-Nummer stimmt nicht Ã¼berein

**Problem:** LLM schreibt [1], aber Quelle ist an Position [2]

**Workaround:**
- Validierung in `_create_source_metadata()`: PrÃ¼fe ob citation_id <= len(chunks)
- Logging: Warne wenn Mismatch erkannt wird

### Issue 3: Suggestion-Parsing scheitert

**Problem:** LLM verwendet unbekanntes Format (z.B. "NÃ¤chste Fragen:")

**Workaround:**
- Erweitere Regex-Patterns in `_extract_suggestions()`
- Fallback: Suche nach "?" am Zeilenende

---

## ğŸš€ Test-AusfÃ¼hrung

### Manual Testing (Empfohlen fÃ¼r v3.19.0)

```bash
# 1. Backend starten
cd c:\VCC\veritas
python backend.py

# 2. Frontend starten (separates Terminal)
python start_frontend.py

# 3. Test-Queries senden:
# - "Welche Bauvorschriften gelten in Baden-WÃ¼rttemberg?"
# - "Was regelt Â§ 58 LBO BW?"
# - "Welche Fristen gelten fÃ¼r Baugenehmigungen?"

# 4. PrÃ¼fe:
# - [1], [2] in Antwort
# - Quellen-Section: IEEE-Format
# - VorschlÃ¤ge-Section: Klickbare Links
# - Click auf [1] â†’ Scroll + Highlight
# - Click auf Vorschlag â†’ Auto-Send
```

### Automated Testing (TODO)

```python
# tests/test_v3_19_0_citations.py
def test_citation_generation():
    # Test _create_source_metadata()
    pass

def test_suggestion_extraction():
    # Test _extract_suggestions()
    pass

def test_citation_parsing():
    # Test _parse_ieee_citations()
    pass

# pytest tests/test_v3_19_0_citations.py -v
```

---

## âœ… Validation Checklist

### Backend (Sprint 1.1 + 1.2)
- [x] `veritas_enhanced_prompts.py`: Source-List + Citation-Instruktionen
- [x] `veritas_api_module.py`: Source-List-Formatierung (Lines 360-365)
- [x] `veritas_api_module.py`: `_extract_suggestions()` (Lines 135-185)
- [x] `veritas_api_module.py`: `_create_source_metadata()` (Lines 187-230)
- [x] `veritas_api_endpoint.py`: `SourceMetadata` Model (Lines 342-353)
- [x] Syntax-Fehler: Keine âœ…

### Frontend (Sprint 1.3 + 1.4)
- [x] `veritas_ui_markdown.py`: `_parse_ieee_citations()` (Lines 483-513)
- [x] `veritas_ui_markdown.py`: `_render_citation()` (Lines 515-571)
- [x] `veritas_ui_markdown.py`: `_scroll_to_source()` (Lines 573-609)
- [x] `veritas_ui_markdown.py`: Tag `citation_superscript` konfiguriert
- [x] `veritas_ui_chat_formatter.py`: `_insert_single_source_ieee()` (Lines 1645-1761)
- [x] `veritas_ui_chat_formatter.py`: `_add_ieee_source_tooltip()` (Lines 1763-1807)
- [x] Syntax-Fehler: Keine âœ…

### Frontend (Sprint 2)
- [x] `veritas_ui_chat_formatter.py`: `_insert_suggestion_link()` (Lines 1463-1525)
- [x] `veritas_ui_chat_formatter.py`: Tags `suggestion_prefix`, `suggestion_link`
- [x] `veritas_app.py`: `_on_suggestion_clicked()` (Lines 658-692)
- [x] `veritas_app.py`: `_send_query_from_suggestion()` (Lines 694-705)
- [x] `veritas_app.py`: `suggestion_click_callback` Integration (Line 2005)
- [x] Syntax-Fehler: Keine âœ…

### Integration
- [x] Backend â†’ Frontend: `sources_metadata` durchgereicht
- [x] Backend â†’ Frontend: `suggestions` durchgereicht
- [x] Frontend: `_render_assistant_message_structured()` nutzt beide

---

## ğŸ“ Test-Protokoll

### Test-Session: [DATUM EINFÃœGEN]

**Tester:** [NAME]  
**Version:** v3.19.0  
**Umgebung:** Windows, Python 3.13, Backend: Ollama, Frontend: Tkinter  

| Test-ID | Feature | Status | Bemerkungen |
|---------|---------|--------|-------------|
| T1 | Backend Citation Gen | â³ | - |
| T2 | SourceMetadata Creation | â³ | - |
| T3 | Suggestion Extraction | â³ | - |
| T4 | Citation Parsing | â³ | - |
| T5 | Citation Click â†’ Scroll | â³ | - |
| T6 | IEEE-Format Display | â³ | - |
| T7 | Suggestion Click â†’ Send | â³ | - |
| T8 | End-to-End Workflow | â³ | - |

**Gesamtstatus:** â³ Pending

---

## ğŸ¯ NÃ¤chste Schritte

1. **Manual Testing** durchfÃ¼hren (empfohlen zuerst)
2. **Test-Protokoll** ausfÃ¼llen
3. **Issues** dokumentieren (falls welche gefunden)
4. **Automated Tests** schreiben (optional, fÃ¼r CI/CD)
5. **Performance-Metriken** sammeln
6. **Dokumentation** finalisieren

---

## ğŸ“š Referenzen

- **Implementierungsplan:** `docs/IEEE_CITATIONS_AND_CLICKABLE_SUGGESTIONS_v3.19.0.md`
- **Backend-Code:** `backend/api/veritas_api_module.py` (Lines 135-230, 360-495)
- **Frontend-Code:** `frontend/ui/veritas_ui_markdown.py` (Lines 483-609)
- **Formatter-Code:** `frontend/ui/veritas_ui_chat_formatter.py` (Lines 1463-1807)
- **App-Integration:** `frontend/veritas_app.py` (Lines 658-705, 2005)
