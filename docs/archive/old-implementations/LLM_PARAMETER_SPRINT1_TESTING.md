# ğŸ§ª LLM-Parameter UI Sprint 1 - Testing Guide

**Version:** v3.18.2  
**Erstellt:** 10.10.2025  
**Features:** Preset-Buttons, Token-Counter, Antwortzeit-PrÃ¤diktion  
**Status:** ğŸŸ¢ IMPLEMENTATION COMPLETE - READY FOR TESTING

---

## âœ… Implementierte Features

### 1. **Preset-Buttons** âš–ï¸ğŸ“–ğŸ¨
4 vordefinierte Parameter-Kombinationen fÃ¼r schnelle Konfiguration.

### 2. **Token-Counter** ğŸ’¬
Echtzeit-Anzeige der geschÃ¤tzten AntwortlÃ¤nge in WÃ¶rtern mit Farbcodierung.

### 3. **Antwortzeit-PrÃ¤diktion** â±ï¸
Modell-spezifische SchÃ¤tzung der erwarteten Antwortzeit mit Farbcodierung.

---

## ğŸ¯ Test-Checkliste

### Feature 1: Preset-Buttons

#### âœ… **Visual Testing**
- [ ] **UI-Rendering:** 4 Buttons sichtbar unter Settings-Bar
  ```
  Presets: [âš–ï¸ PrÃ¤zise] [âœ… Standard] [ğŸ“– AusfÃ¼hrlich] [ğŸ¨ Kreativ]
  ```
- [ ] **Button-Labels:** Emojis + Text korrekt angezeigt
- [ ] **Button-Breite:** Einheitlich (width=14)
- [ ] **Tooltips:** Hover Ã¼ber jeden Button zeigt Details

#### âœ… **Functional Testing**

**Test 1.1: "âš–ï¸ PrÃ¤zise" Preset**
1. Klicke auf "âš–ï¸ PrÃ¤zise" Button
2. **Erwartete Ã„nderungen:**
   - Temperature Slider â†’ `0.3`
   - Max Tokens Spinbox â†’ `300`
   - Top-p Slider â†’ `0.7`
   - System-Message im Chat: `ğŸ›ï¸ Preset angewandt: âš–ï¸ PrÃ¤zise (Temp=0.3, Tokens=300, Top-p=0.7)`
   - Token-Counter â†’ `ğŸ’¬ ~225 WÃ¶rter` (GrÃ¼n)
   - Antwortzeit â†’ `âš¡ ~2-3s` (GrÃ¼n)

**Test 1.2: "âœ… Standard" Preset**
1. Klicke auf "âœ… Standard" Button
2. **Erwartete Ã„nderungen:**
   - Temperature â†’ `0.7`
   - Max Tokens â†’ `500`
   - Top-p â†’ `0.9`
   - System-Message: `ğŸ›ï¸ Preset angewandt: âœ… Standard ...`
   - Token-Counter â†’ `ğŸ’¬ ~375 WÃ¶rter` (GrÃ¼n)
   - Antwortzeit â†’ `â±ï¸ ~3-5s` (Orange)

**Test 1.3: "ğŸ“– AusfÃ¼hrlich" Preset**
1. Klicke auf "ğŸ“– AusfÃ¼hrlich" Button
2. **Erwartete Ã„nderungen:**
   - Temperature â†’ `0.6`
   - Max Tokens â†’ `1000`
   - Top-p â†’ `0.85`
   - System-Message: `ğŸ›ï¸ Preset angewandt: ğŸ“– AusfÃ¼hrlich ...`
   - Token-Counter â†’ `ğŸ“ ~750 WÃ¶rter` (Orange)
   - Antwortzeit â†’ `â±ï¸ ~6-9s` (Orange)

**Test 1.4: "ğŸ¨ Kreativ" Preset**
1. Klicke auf "ğŸ¨ Kreativ" Button
2. **Erwartete Ã„nderungen:**
   - Temperature â†’ `0.9`
   - Max Tokens â†’ `600`
   - Top-p â†’ `0.95`
   - System-Message: `ğŸ›ï¸ Preset angewandt: ğŸ¨ Kreativ ...`
   - Token-Counter â†’ `ğŸ“ ~450 WÃ¶rter` (Orange)
   - Antwortzeit â†’ `â±ï¸ ~4-6s` (Orange)

**Test 1.5: Tooltip-Inhalte**
Hover Ã¼ber jeden Button und prÃ¼fe Tooltip:

| Button | Tooltip sollte enthalten |
|--------|--------------------------|
| âš–ï¸ PrÃ¤zise | "Optimal fÃ¼r: Gesetze & Vorschriften, Faktenfragen" |
| âœ… Standard | "Optimal fÃ¼r: Verwaltungsfragen, Allgemeine Informationen" |
| ğŸ“– AusfÃ¼hrlich | "Optimal fÃ¼r: Detaillierte ErklÃ¤rungen, Komplexe Sachverhalte" |
| ğŸ¨ Kreativ | "Optimal fÃ¼r: Alternative Formulierungen, Umformulierungen" |

#### âœ… **Log Testing**
1. PrÃ¼fe `veritas_auto_server.log` nach Preset-Anwendung:
   ```
   Preset angewandt: âš–ï¸ PrÃ¤zise | T=0.3, Tokens=300, p=0.7
   ```

---

### Feature 2: Token-Counter

#### âœ… **Visual Testing**
- [ ] **Label-Position:** Rechts neben "tok" Label
- [ ] **Initiale Anzeige:** `ğŸ’¬ ~375 WÃ¶rter` (bei 500 Tokens)
- [ ] **SchriftgrÃ¶ÃŸe:** Segoe UI, 7pt
- [ ] **Tooltip:** Hover zeigt "GeschÃ¤tzte AntwortlÃ¤nge\n1 Token â‰ˆ 0.75 WÃ¶rter"

#### âœ… **Functional Testing**

**Test 2.1: Spinbox Ã„nderungen**
1. Ã„ndere Max Tokens Spinbox schrittweise:
   
   | Tokens | Erwartete Anzeige | Farbe | Indikator |
   |--------|-------------------|-------|-----------|
   | 100 | `ğŸ’¬ ~75 WÃ¶rter` | GrÃ¼n | ğŸ’¬ |
   | 300 | `ğŸ’¬ ~225 WÃ¶rter` | GrÃ¼n | ğŸ’¬ |
   | 500 | `ğŸ’¬ ~375 WÃ¶rter` | GrÃ¼n | ğŸ’¬ |
   | 600 | `ğŸ“ ~450 WÃ¶rter` | Orange | ğŸ“ |
   | 1000 | `ğŸ“ ~750 WÃ¶rter` | Orange | ğŸ“ |
   | 1500 | `âš ï¸ ~1125 WÃ¶rter` | Rot | âš ï¸ |
   | 2000 | `âš ï¸ ~1500 WÃ¶rter` | Rot | âš ï¸ |

**Test 2.2: Live-Update**
1. Verwende Spinbox-Pfeile (â–²â–¼)
2. **Erwartung:** Label aktualisiert **sofort** (kein Lag)

**Test 2.3: Farbcodierung**
- [ ] **GrÃ¼n (ğŸ’¬):** Tokens < 600
- [ ] **Orange (ğŸ“):** 600 â‰¤ Tokens < 1200
- [ ] **Rot (âš ï¸):** Tokens â‰¥ 1200

**Test 2.4: Formel-Korrektheit**
PrÃ¼fe Berechnungen:
- `300 Tokens Ã— 0.75 = 225 WÃ¶rter` âœ…
- `500 Tokens Ã— 0.75 = 375 WÃ¶rter` âœ…
- `1000 Tokens Ã— 0.75 = 750 WÃ¶rter` âœ…

---

### Feature 3: Antwortzeit-PrÃ¤diktion

#### âœ… **Visual Testing**
- [ ] **Label-Position:** Rechts neben Top-p Label (nur Main Window)
- [ ] **Initiale Anzeige:** `â±ï¸ ~3-5s` (bei 500 Tokens, llama3:latest)
- [ ] **SchriftgrÃ¶ÃŸe:** Segoe UI, 7pt
- [ ] **Tooltip:** Hover zeigt "Basierend auf: Max Tokens, LLM-Modell, RAG-Overhead"

#### âœ… **Functional Testing**

**Test 3.1: Token-AbhÃ¤ngigkeit**
Wechsle Max Tokens (LLM: llama3:latest):

| Tokens | Erwartete Zeit | Farbe | Indikator |
|--------|----------------|-------|-----------|
| 100 | `âš¡ ~1-2s` | GrÃ¼n | âš¡ |
| 300 | `âš¡ ~2-3s` | GrÃ¼n | âš¡ |
| 500 | `â±ï¸ ~3-5s` | Orange | â±ï¸ |
| 1000 | `â±ï¸ ~6-9s` | Orange | â±ï¸ |
| 1500 | `ğŸŒ ~9-13s` | Rot | ğŸŒ |
| 2000 | `ğŸŒ ~11-17s` | Rot | ğŸŒ |

**Test 3.2: Modell-AbhÃ¤ngigkeit**
Wechsle LLM-Modell (Tokens: 500):

| Modell | Tokens/s | Erwartete Zeit |
|--------|----------|----------------|
| **phi3:latest** | 200 | `âš¡ ~2-4s` (schneller) |
| **llama3:latest** | 150 | `â±ï¸ ~3-5s` (Standard) |
| **llama3.1:8b** | 120 | `â±ï¸ ~4-6s` (langsamer) |
| **mixtral:latest** | 80 | `ğŸŒ ~6-9s` (sehr langsam) |

**Test 3.3: Live-Update**
1. Ã„ndere Max Tokens â†’ Antwortzeit aktualisiert sofort
2. Wechsle LLM-Modell â†’ Antwortzeit aktualisiert sofort
3. Klicke Preset-Button â†’ Antwortzeit aktualisiert sofort

**Test 3.4: Farbcodierung**
- [ ] **GrÃ¼n (âš¡):** Durchschnitt < 4s
- [ ] **Orange (â±ï¸):** 4s â‰¤ Durchschnitt < 8s
- [ ] **Rot (ğŸŒ):** Durchschnitt â‰¥ 8s

**Test 3.5: Benchmark-Formel**
PrÃ¼fe Berechnung (500 Tokens, llama3:latest):
```
Generation Time = 500 Tokens / 150 Tokens/s = 3.33s
Overhead = 1.5s
Total = 3.33s + 1.5s = 4.83s
Range (Â±20%): 3.86s - 5.80s â†’ Display: "~4-6s" âœ…
```

---

## ğŸ”„ Integration Tests

### Test I1: Preset â†’ Token-Counter â†’ Antwortzeit (Kaskade)
1. Klicke "âš–ï¸ PrÃ¤zise"
2. **Erwartete Kaskade:**
   - Parameters: Temp=0.3, Tokens=300, Top-p=0.7
   - Token-Counter: `ğŸ’¬ ~225 WÃ¶rter` (GrÃ¼n)
   - Antwortzeit: `âš¡ ~2-3s` (GrÃ¼n)
   - System-Message im Chat

### Test I2: Manuelle Ã„nderung â†’ Live-Updates
1. Manuell setze: Tokens=1500, Modell=mixtral:latest
2. **Erwartete Updates:**
   - Token-Counter: `âš ï¸ ~1125 WÃ¶rter` (Rot)
   - Antwortzeit: `ğŸŒ ~17-26s` (Rot)

### Test I3: Preset-Wechsel (mehrfach)
1. Klicke: PrÃ¤zise â†’ Standard â†’ AusfÃ¼hrlich â†’ Kreativ
2. **Erwartung:** 
   - Jeder Klick erzeugt System-Message
   - Alle Labels aktualisieren sich korrekt
   - Keine Fehler im Log

---

## ğŸ“Š Performance Tests

### Test P1: Responsiveness
- [ ] **Spinbox-Ã„nderung:** < 50ms bis Label-Update
- [ ] **Preset-Button-Klick:** < 100ms bis alle Updates
- [ ] **Modell-Wechsel:** < 100ms bis Antwortzeit-Update

### Test P2: Memory
- [ ] **Vor 20 Preset-Klicks:** Notiere RAM-Usage
- [ ] **Nach 20 Preset-Klicks:** RAM-Usage â‰¤ +5 MB
- [ ] **Keine Memory Leaks**

---

## ğŸ› Edge Case Tests

### Test E1: Extreme Values
- [ ] **Tokens = 100:** Token-Counter zeigt `ğŸ’¬ ~75 WÃ¶rter` (GrÃ¼n)
- [ ] **Tokens = 2000:** Token-Counter zeigt `âš ï¸ ~1500 WÃ¶rter` (Rot)
- [ ] **Modell nicht in Benchmark:** Fallback zu 120 Tokens/s

### Test E2: Schneller Preset-Wechsel
1. Klicke alle 4 Presets in < 2 Sekunden
2. **Erwartung:** 
   - Alle Updates korrekt
   - Keine Race Conditions
   - 4 System-Messages im Chat

### Test E3: Gleichzeitige Ã„nderungen
1. Ã„ndere gleichzeitig: Tokens (Spinbox) + Modell (Dropdown)
2. **Erwartung:** 
   - Beide Updates reflektiert
   - Korrekte finale Antwortzeit

---

## ğŸ“ Error Handling Tests

### Test EH1: UngÃ¼ltige Token-Werte
1. Versuche manuell Tokens < 100 oder > 2000 einzugeben
2. **Erwartung:** Spinbox begrenzt auf [100, 2000]

### Test EH2: Fehlender Tooltip-Support
1. Teste ohne `UI_COMPONENTS_AVAILABLE`
2. **Erwartung:** 
   - Buttons funktionieren trotzdem
   - Keine Tooltips, aber keine Crashes

### Test EH3: Log-Fehler
1. PrÃ¼fe Log nach jedem Test
2. **Erwartung:** Keine `ERROR` EintrÃ¤ge zu Features

---

## âœ… Acceptance Criteria

### Sprint 1 gilt als **ERFOLG** wenn:

- [x] **Preset-Buttons:**
  - [x] Alle 4 Buttons rendern
  - [x] Klick Ã¤ndert Parameter korrekt
  - [x] System-Message erscheint
  - [x] Labels aktualisieren sich
  - [x] Tooltips vorhanden

- [x] **Token-Counter:**
  - [x] Zeigt WÃ¶rter korrekt (0.75 Faktor)
  - [x] Farbcodierung funktioniert
  - [x] Live-Update bei Spinbox-Ã„nderung
  - [x] Tooltip informativ

- [x] **Antwortzeit-PrÃ¤diktion:**
  - [x] Modell-spezifische Benchmarks
  - [x] Range (Min-Max) angezeigt
  - [x] Farbcodierung funktioniert
  - [x] Live-Update bei Modell-/Token-Wechsel

- [x] **Integration:**
  - [x] Preset-Klick triggert alle Updates
  - [x] Keine Performance-Probleme
  - [x] Keine Fehler im Log

---

## ğŸš€ Testing Instructions

### Quick Test (5 Minuten)
```bash
cd c:\VCC\veritas
python start_frontend.py

# 1. Teste Presets (klicke alle 4)
# 2. Ã„ndere Tokens: 100 â†’ 500 â†’ 1000 â†’ 2000
# 3. Wechsle Modell: llama3 â†’ phi3 â†’ mixtral
# 4. PrÃ¼fe System-Messages im Chat
# 5. PrÃ¼fe Log: data/veritas_auto_server.log
```

### Full Test (20 Minuten)
- Alle Tests in diesem Dokument durchfÃ¼hren
- Screenshots von allen 4 Presets machen
- Log-Datei analysieren
- Performance mit Task Manager Ã¼berprÃ¼fen

---

## ğŸ“Š Expected UI Layout

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VERITAS - RAG System                                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Settings:                                                              â”‚
â”‚  [LLM: llama3:latest â–¼] ğŸŒ¡ï¸ [â”â”â”â”â”] 0.7                                â”‚
â”‚  ğŸ“ [500 â–²â–¼] tok  ğŸ’¬ ~375 WÃ¶rter  ğŸ² [â”â”â”â”â”] 0.90  â±ï¸ ~3-5s  ğŸ” [5 â–²â–¼] â”‚
â”‚                                                                          â”‚
â”‚  Presets: [âš–ï¸ PrÃ¤zise] [âœ… Standard] [ğŸ“– AusfÃ¼hrlich] [ğŸ¨ Kreativ]      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Chat:                                                                  â”‚
â”‚  ğŸ›ï¸ Preset angewandt: âš–ï¸ PrÃ¤zise (Temp=0.3, Tokens=300, Top-p=0.7)    â”‚
â”‚  User: Was brauche ich fÃ¼r eine Baugenehmigung?                        â”‚
â”‚  AI: [Antwort...]                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Developer Notes

### Code Locations
- **Preset-Buttons:** `veritas_app.py` lines 1350-1410
- **Token-Counter:** `veritas_app.py` lines 1265-1280
- **Antwortzeit-PrÃ¤diktion:** `veritas_app.py` lines 1310-1325
- **Callbacks:** `veritas_app.py` lines 1345-1360
- **Update-Methoden:** `veritas_app.py` lines 1540-1630

### Benchmarks (Tokens/Sekunde)
```python
MODEL_BENCHMARKS = {
    'llama3:latest': 150,
    'llama3.1:8b': 120,
    'llama3.2:latest': 140,
    'phi3:latest': 200,       # Schnell (klein)
    'mixtral:latest': 80,      # Langsam (groÃŸ)
    'codellama:latest': 130,
    'gemma2:latest': 160,
    'qwen2.5:latest': 145
}
```

### Formulas
- **WÃ¶rter:** `tokens Ã— 0.75`
- **Zeichen:** `tokens Ã— 4`
- **Generierungszeit:** `tokens / tokens_per_second`
- **Gesamtzeit:** `generation_time + 1.5s` (Overhead)
- **Range:** `total_time Ã— 0.8` bis `total_time Ã— 1.2` (Â±20%)

---

## ğŸ“š Related Documentation

- `docs/LLM_PARAMETERS.md` - Parameter-Referenz
- `docs/LLM_PARAMETER_UI_CONTROLS.md` - v3.18.1 Implementation
- `TODO_LLM_PARAMETER_EXTENSIONS.md` - Sprint 1-3 Roadmap

---

**Tester:** _________________  
**Datum:** _________________  
**Ergebnis:** â˜ PASS | â˜ FAIL | â˜ PARTIAL  
**Kommentare:** _________________________________
