# ğŸš€ VERITAS v3.20.0 - Chat Persistence Quick Start Guide

**Version:** v3.20.0  
**Datum:** 12. Oktober 2025  
**Zielgruppe:** Entwickler & Benutzer

---

## ğŸ“‹ Ãœberblick

VERITAS v3.20.0 bringt **vollstÃ¤ndige Chat-Persistierung** und **kontextuelle LLM-Konversationen**. Dieses Guide erklÃ¤rt, wie die neuen Features genutzt werden.

---

## ğŸ¯ Features auf einen Blick

### 1. Auto-Save âœ…
- **Jede Nachricht** wird automatisch gespeichert
- **JSON-Format:** `data/chat_sessions/{session_id}.json`
- **Kein manuelles Speichern** erforderlich

### 2. Session-Restore âœ…
- **Dialog beim App-Start:** "Letzte Session wiederherstellen?"
- **Auto-Restore-Option:** Checkbox "Immer letzte Session automatisch laden"
- **Letzte 10 Sessions** angezeigt

### 3. Session-Manager âœ…
- **MenÃ¼:** Hamburger â†’ "ğŸ“ Sessions verwalten"
- **Funktionen:** Suchen, Umbenennen, Exportieren, LÃ¶schen
- **Sortierung:** Nach Titel, Datum, Nachrichten

### 4. Kontextuelle LLM-Antworten âœ…
- **LLM erhÃ¤lt Chat-History** (letzte 10 Messages)
- **Bezieht sich auf frÃ¼here Fragen/Antworten**
- **Intelligent:** Sliding Window / Relevance-Based

---

## ğŸš€ Getting Started

### 1. Installation

**Keine zusÃ¤tzlichen Pakete erforderlich!**

Alle Dependencies sind bereits in `requirements.txt`:
```
pydantic>=2.0.0
```

### 2. App starten

```bash
# Backend (optional, falls nicht bereits lÃ¤uft)
python -m uvicorn backend.api.veritas_api_backend:app --reload

# Frontend
python frontend/veritas_app.py
```

### 3. Erste Session

1. **App startet** â†’ Session-Restore-Dialog erscheint
2. **"ğŸ†• Neuer Chat"** klicken
3. **Frage eingeben:** z.B. "Was ist das BImSchG?"
4. **Antwort erhalten** â†’ Automatisch gespeichert! âœ…

### 4. Session wiederherstellen

1. **App neu starten** â†’ Dialog erscheint
2. **Session auswÃ¤hlen** aus Liste
3. **"âœ… Wiederherstellen"** klicken
4. **Chat-History geladen** â†’ Konversation fortsetzen!

---

## ğŸ“ Dateistruktur

### Session-Storage

```
data/
â”œâ”€â”€ chat_sessions/              # Aktive Sessions
â”‚   â”œâ”€â”€ {uuid-1}.json          # Session 1
â”‚   â”œâ”€â”€ {uuid-2}.json          # Session 2
â”‚   â””â”€â”€ ...
â”œâ”€â”€ chat_backups/               # Auto-Backups (tÃ¤glich)
â”‚   â””â”€â”€ 2025-10-12_10-30-00/   # Backup-Timestamp
â”‚       â”œâ”€â”€ {uuid-1}.json
â”‚       â””â”€â”€ ...
â””â”€â”€ session_restore_settings.json  # Auto-Restore-Setting
```

### Session-JSON-Format

```json
{
  "session_id": "550e8400-e29b-41d4-a716-446655440000",
  "created_at": "2025-10-12T14:30:00",
  "updated_at": "2025-10-12T15:45:00",
  "title": "Konversation Ã¼ber BImSchG",
  "llm_model": "llama3.1:8b",
  "messages": [
    {
      "id": "msg-uuid-1",
      "role": "user",
      "content": "Was ist das BImSchG?",
      "timestamp": "2025-10-12T14:30:00",
      "attachments": [],
      "metadata": {}
    },
    {
      "id": "msg-uuid-2",
      "role": "assistant",
      "content": "Das Bundes-Immissionsschutzgesetz...",
      "timestamp": "2025-10-12T14:30:15",
      "attachments": [],
      "metadata": {
        "confidence_score": 0.92,
        "sources": [...]
      }
    }
  ],
  "metadata": {}
}
```

---

## ğŸ¨ UI-Features

### Session-Restore-Dialog

**Erscheint:** Beim App-Start (falls Sessions vorhanden)

**Aufbau:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Letzte Session wiederherstellen?         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Titel              Datum      Nachrichten â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  BImSchG-Diskussion Heute 14:30    12      â”‚
â”‚  Windkraft-Planung  Gestern 10:15  8       â”‚
â”‚  Baurecht-Fragen    Mo 09:30       5       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â˜‘ Immer letzte Session automatisch laden  â”‚
â”‚  [ğŸ†• Neuer Chat]  [âœ… Wiederherstellen]    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Aktionen:**
- **Doppelklick:** Session sofort wiederherstellen
- **"âœ… Wiederherstellen":** AusgewÃ¤hlte Session laden
- **"ğŸ†• Neuer Chat":** Neue Session starten
- **Checkbox:** Auto-Restore aktivieren/deaktivieren

### Session-Manager

**Ã–ffnen:** Hamburger-MenÃ¼ â†’ "ğŸ“ Sessions verwalten"

**Features:**
- **Suche:** Echtzeit-Filter nach Titel
- **Sortierung:** Click auf Spalten-Header
- **Aktionen:**
  - **ğŸ“‚ Ã–ffnen:** Session laden
  - **âœï¸ Umbenennen:** Titel Ã¤ndern
  - **ğŸ’¾ Exportieren:** Als JSON speichern
  - **ğŸ—‘ï¸ LÃ¶schen:** Session lÃ¶schen (mit Backup)
- **Rechtsklick:** Kontext-MenÃ¼ mit allen Aktionen

---

## ğŸ’¡ LLM-Context-Integration

### Wie funktioniert es?

**1. Chat-History wird gesammelt:**
```python
# Frontend sammelt Messages
messages = [
  {"role": "user", "content": "Was ist das BImSchG?"},
  {"role": "assistant", "content": "Das Bundes-Immissionsschutzgesetz..."},
  {"role": "user", "content": "Welche Grenzwerte gelten?"}
]
```

**2. Backend erstellt Context:**
```python
# ConversationContextManager
context = """
Benutzer: Was ist das BImSchG?
Assistent: Das Bundes-Immissionsschutzgesetz...
Benutzer: Welche Grenzwerte gelten?
"""
```

**3. LLM erhÃ¤lt erweiterten Prompt:**
```
System: Du bist VERITAS...

Bisherige Konversation:
Benutzer: Was ist das BImSchG?
Assistent: Das Bundes-Immissionsschutzgesetz...
Benutzer: Welche Grenzwerte gelten?

Aktuelle Frage:
Gibt es Ausnahmen?
```

**4. LLM antwortet kontextuell:**
```
Ja, es gibt Ausnahmen von den zuvor genannten Grenzwerten...
```
(Bezieht sich auf "zuvor genannte Grenzwerte")

### Context-Strategien

**Sliding Window (Default):**
- Neueste 10 Messages
- Schnell & einfach
- Vorhersagbare Token-Anzahl

**Relevance-Based:**
- TF-IDF-Similarity zur Frage
- Intelligente Auswahl
- Optimal fÃ¼r lange Konversationen

**All:**
- Alle Messages (falls <2000 Tokens)
- VollstÃ¤ndiger Kontext
- Auto-KÃ¼rzung bei Ãœberschreitung

### Token-Management

**Limits:**
- Max Context: **2000 Tokens** (~8000 Zeichen)
- SchÃ¤tzung: **~4 Zeichen pro Token**
- Auto-KÃ¼rzung bei Ãœberschreitung

**Hinweis bei KÃ¼rzung:**
```
[... (gekÃ¼rzt aufgrund Token-Limit)]
```

---

## ğŸ”§ Entwickler-API

### Chat-Persistence Service

```python
from backend.services.chat_persistence_service import ChatPersistenceService
from shared.chat_schema import ChatSession

# Service initialisieren
service = ChatPersistenceService()

# Session erstellen
session = ChatSession(llm_model="llama3.1:8b")
session.add_message("user", "Hallo!")
session.add_message("assistant", "Hallo! Wie kann ich helfen?")

# Session speichern
service.save_chat_session(session)

# Session laden
loaded_session = service.load_chat_session(session.session_id)

# Alle Sessions auflisten
sessions = service.list_chat_sessions(limit=10, sort_by="updated_at")

# Session lÃ¶schen (mit Backup)
service.delete_chat_session(session.session_id, create_backup=True)

# Statistiken
stats = service.get_session_statistics()
print(f"Total Sessions: {stats['total_sessions']}")
print(f"Total Messages: {stats['total_messages']}")
```

### ConversationContextManager

```python
from backend.agents.context_manager import ConversationContextManager
from shared.chat_schema import ChatSession

# Manager initialisieren
manager = ConversationContextManager(max_tokens=2000)

# Session mit Messages
session = ChatSession()
session.add_message("user", "Was ist das BImSchG?")
session.add_message("assistant", "Das Bundes-Immissionsschutzgesetz...")
session.add_message("user", "Welche Grenzwerte gelten?")

# Context erstellen
result = manager.build_conversation_context(
    chat_session=session,
    current_query="Gibt es Ausnahmen?",
    strategy="sliding_window",  # oder "relevance" / "all"
    max_messages=10
)

print(f"Context: {result['context']}")
print(f"Tokens: {result['token_count']}")
print(f"Messages: {result['message_count']}")

# VollstÃ¤ndigen Prompt erstellen
prompt = manager.format_prompt_with_context(
    current_query="Gibt es Ausnahmen?",
    context=result['context'],
    system_prompt="Du bist VERITAS..."
)

# Statistiken
stats = manager.get_context_statistics(session)
print(f"Can fit all: {stats['can_fit_all']}")
print(f"Requires truncation: {stats['requires_truncation']}")
```

### Ollama Context-Integration

```python
from backend.agents.veritas_ollama_client import VeritasOllamaClient
from shared.chat_schema import ChatSession

# Client initialisieren
async with VeritasOllamaClient() as client:
    await client.initialize()
    
    # Session mit History
    session = ChatSession()
    session.add_message("user", "Was ist das BImSchG?")
    session.add_message("assistant", "Das Bundes-Immissionsschutzgesetz...")
    
    # Query mit Context
    response = await client.query_with_context(
        query="Welche Grenzwerte gelten?",
        chat_session=session,
        context_strategy="sliding_window",
        max_context_messages=10
    )
    
    print(f"Response: {response.response}")
    print(f"Confidence: {response.confidence_score}")
```

---

## ğŸ§ª Testing

### Unit Tests ausfÃ¼hren

```bash
# ConversationContextManager Tests
python tests/test_context_manager.py

# Output:
# âœ… 12/12 Tests PASSED
```

### Test-Szenarien

**1. Session-Persistierung:**
```bash
python test_chat_persistence.py

# Output:
# âœ… 10/10 Tests PASSED
```

**2. UI-Tests (Manual):**
```bash
python test_chat_persistence_ui.py

# FÃ¼hrt GUI-Tests aus mit Checklist
```

---

## ğŸ“Š Performance

### Benchmarks

| Operation | Time | Status |
|-----------|------|--------|
| Save Session | ~50ms | âœ… |
| Load Session | ~30ms | âœ… |
| List Sessions (10) | ~150ms | âœ… |
| Dialog Open | ~150ms | âœ… |
| Manager Refresh | ~250ms | âœ… |
| Search Filter | ~20ms | âœ… |
| Context-Building | <50ms | âœ… |
| API Overhead | <100ms | âœ… |

**Memory Impact:** <30 KB (negligible)

---

## â“ FAQ

### Q: Wo werden Sessions gespeichert?
**A:** In `data/chat_sessions/{session_id}.json` (JSON-Format)

### Q: Werden Backups erstellt?
**A:** Ja, tÃ¤glich in `data/chat_backups/{timestamp}/`

### Q: Wie viele Messages kann eine Session haben?
**A:** Unbegrenzt (Warnung ab 10 MB File-Size)

### Q: Wie funktioniert Auto-Restore?
**A:** Checkbox im Session-Restore-Dialog aktivieren â†’ Setting wird gespeichert

### Q: Wie viel Context erhÃ¤lt das LLM?
**A:** Letzte 10 Messages (max 2000 Tokens)

### Q: Was passiert bei Token-Ãœberschreitung?
**A:** Auto-KÃ¼rzung mit Hinweis "[... (gekÃ¼rzt aufgrund Token-Limit)]"

### Q: Kann ich Sessions exportieren?
**A:** Ja, via Session-Manager â†’ Rechtsklick â†’ "ğŸ’¾ Exportieren"

### Q: Werden gelÃ¶schte Sessions backuped?
**A:** Ja, automatisch bei LÃ¶schung (falls create_backup=True)

---

## ğŸ› Troubleshooting

### Problem: Session-Restore-Dialog erscheint nicht

**LÃ¶sung:**
1. PrÃ¼fe ob Sessions vorhanden: `ls data/chat_sessions/`
2. PrÃ¼fe Logs: `logger.info` in `veritas_app.py`
3. PrÃ¼fe Berechtigung: Lese-Zugriff auf `data/`

### Problem: Auto-Save funktioniert nicht

**LÃ¶sung:**
1. PrÃ¼fe ob `chat_persistence_service` initialisiert: `hasattr(self, 'chat_persistence')`
2. PrÃ¼fe Schreib-Berechtigung: `data/chat_sessions/` existiert?
3. PrÃ¼fe Logs: `logger.error` in `chat_persistence_service.py`

### Problem: Context wird nicht Ã¼bergeben

**LÃ¶sung:**
1. PrÃ¼fe ob `chat_history` in API-Payload: `payload.get('chat_history')`
2. PrÃ¼fe Backend-Logs: `Context-Integration` Log-Meldungen
3. PrÃ¼fe ob Messages vorhanden: `len(self.chat_session.messages) > 0`

---

## ğŸ“š Weitere Dokumentation

### Detaillierte Dokumentation:
- `docs/CHAT_PERSISTENCE_PHASE1_COMPLETE.md` - Persistierung
- `docs/CHAT_PERSISTENCE_PHASE2_COMPLETE.md` - UI
- `docs/CHAT_PERSISTENCE_PHASE3_COMPLETE.md` - Context-Integration
- `docs/CHAT_PERSISTENCE_TESTING_REPORT.md` - Tests
- `docs/CHAT_PERSISTENCE_PROJECT_SUMMARY.md` - Projekt-Ãœbersicht

### Code-Referenz:
- `shared/chat_schema.py` - Data Models
- `backend/services/chat_persistence_service.py` - Persistierung
- `backend/agents/context_manager.py` - Context-Building
- `backend/agents/veritas_ollama_client.py` - LLM-Integration
- `frontend/ui/veritas_ui_session_dialog.py` - Session-Restore-Dialog
- `frontend/ui/veritas_ui_session_manager.py` - Session-Manager

---

## ğŸ¯ Next Steps

### FÃ¼r Benutzer:
1. âœ… App starten
2. âœ… Erste Session erstellen
3. âœ… Auto-Restore aktivieren
4. âœ… Konversation fÃ¼hren (kontextuell!)

### FÃ¼r Entwickler:
1. âœ… Tests ausfÃ¼hren (`python tests/test_context_manager.py`)
2. âœ… API ausprobieren (siehe Entwickler-API)
3. âœ… Integration testen (Multi-Turn Conversation)
4. ğŸ“ Feedback geben

---

**VERITAS v3.20.0 - Chat Persistence ist Production-Ready!** ğŸš€

Bei Fragen: Siehe Dokumentation oder kontaktiere das Team.
