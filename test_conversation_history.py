"""
Test: Chat-Verlauf Integration
================================
Testet ob Chat-Verlauf korrekt an Backend √ºbergeben und in der Antwort ber√ºcksichtigt wird

EXPECTED:
- Backend empf√§ngt conversation_history
- Finale Antwort enth√§lt Gespr√§chskontext
- LLM nutzt Kontext f√ºr bessere Antworten
"""

import requests
import json
import time

BASE_URL = "http://localhost:5000"

def test_conversation_history():
    print("=" * 80)
    print("üß™ TEST: Chat-Verlauf Integration")
    print("=" * 80)
    
    # 1. Health Check
    print("\n1Ô∏è‚É£ Backend Health Check...")
    try:
        health = requests.get(f"{BASE_URL}/health", timeout=5).json()
        print(f"‚úÖ Backend: {health.get('status')}")
    except Exception as e:
        print(f"‚ùå Backend nicht erreichbar: {e}")
        return
    
    # 2. Simuliere Chat-Verlauf
    conversation_history = [
        {
            "role": "user",
            "content": "Wie funktioniert das Baugenehmigungsverfahren in M√ºnchen?"
        },
        {
            "role": "assistant",
            "content": "Das Baugenehmigungsverfahren in M√ºnchen umfasst mehrere Schritte: 1. Bauantrag stellen, 2. Pr√ºfung durch Bauaufsicht, 3. Genehmigung erteilen."
        },
        {
            "role": "user",
            "content": "Welche Unterlagen ben√∂tige ich daf√ºr?"
        }
    ]
    
    print(f"\n2Ô∏è‚É£ Sende Query mit {len(conversation_history)} Nachrichten Kontext...")
    
    # 3. Sende Streaming Query mit conversation_history
    query = "Welche Unterlagen ben√∂tige ich daf√ºr?"
    
    response = requests.post(
        f"{BASE_URL}/v2/query/stream",
        json={
            "query": query,
            "session_id": f"test_conv_{int(time.time())}",
            "enable_streaming": True,
            "enable_intermediate_results": True,
            "enable_llm_thinking": True,
            "conversation_history": conversation_history  # üÜï Chat-Verlauf
        },
        timeout=10
    )
    
    if response.status_code != 200:
        print(f"‚ùå Query fehlgeschlagen: {response.status_code}")
        print(response.text)
        return
    
    stream_info = response.json()
    stream_session_id = stream_info["session_id"]
    
    print(f"‚úÖ Stream gestartet: {stream_session_id}")
    
    # 4. Listen to Stream
    print("\n3Ô∏è‚É£ Warte auf finale Antwort...")
    
    stream_response = requests.get(
        f"{BASE_URL}/progress/{stream_session_id}",
        stream=True,
        headers={'Accept': 'text/event-stream'},
        timeout=120
    )
    
    final_result = None
    
    for line in stream_response.iter_lines(decode_unicode=True):
        if line.startswith('data: '):
            try:
                event_data = json.loads(line[6:])
                event_type = event_data.get('type', '')
                stage = event_data.get('stage', '')
                
                if event_type == 'stage_complete' and stage == 'completed':
                    final_result = event_data.get('details', {})
                    break
                    
            except json.JSONDecodeError:
                continue
    
    # 5. Analysiere Antwort
    if final_result:
        response_text = final_result.get('response_text', '')
        
        print("\n" + "=" * 80)
        print("üìÑ FINALE ANTWORT:")
        print("=" * 80)
        print(response_text[:500])  # Erste 500 Zeichen
        print("...")
        
        # 6. Pr√ºfe ob Kontext ber√ºcksichtigt wurde
        print("\n" + "=" * 80)
        print("üîç KONTEXT-ANALYSE:")
        print("=" * 80)
        
        has_conversation_context = "**Gespr√§chskontext**" in response_text
        
        print(f"   Gespr√§chskontext-Abschnitt: {'‚úÖ Vorhanden' if has_conversation_context else '‚ùå Fehlt'}")
        
        if has_conversation_context:
            # Extrahiere Kontext-Abschnitt
            start = response_text.find("**Gespr√§chskontext**")
            end = response_text.find("**Zusammenfassung", start)
            context_section = response_text[start:end] if end > start else response_text[start:start+300]
            
            print("\n   üìö Kontext-Abschnitt:")
            print("   " + "-" * 76)
            for line in context_section.split('\n')[:10]:  # Erste 10 Zeilen
                print(f"   {line}")
            print("   " + "-" * 76)
        
        # Pr√ºfe ob fr√ºhere Frage erw√§hnt wird
        mentions_previous = any(keyword in response_text.lower() for keyword in [
            'baugenehmigung',
            'm√ºnchen',
            'vorherige frage',
            'gespr√§chskontext'
        ])
        
        print(f"\n   Bezug zu vorherigen Nachrichten: {'‚úÖ Ja' if mentions_previous else '‚ö†Ô∏è Unklar'}")
        
        # Zusammenfassung
        print("\n" + "=" * 80)
        if has_conversation_context and mentions_previous:
            print("‚úÖ TEST ERFOLGREICH!")
            print("   - Chat-Verlauf wurde korrekt √ºbermittelt")
            print("   - Kontext wird in Antwort angezeigt")
            print("   - Bezug zu vorherigen Nachrichten erkennbar")
        elif has_conversation_context:
            print("‚ö†Ô∏è TEST TEILWEISE ERFOLGREICH")
            print("   - Kontext-Abschnitt vorhanden")
            print("   - Aber Bezug zu Kontext unklar")
        else:
            print("‚ùå TEST FEHLGESCHLAGEN")
            print("   - Kontext-Abschnitt fehlt in Antwort")
        print("=" * 80)
    else:
        print("\n‚ùå Keine finale Antwort erhalten")

if __name__ == "__main__":
    print("üöÄ Starte Chat-Verlauf Integration Test...\n")
    print("‚ö†Ô∏è  Stelle sicher, dass Backend l√§uft")
    print("")
    
    test_conversation_history()
